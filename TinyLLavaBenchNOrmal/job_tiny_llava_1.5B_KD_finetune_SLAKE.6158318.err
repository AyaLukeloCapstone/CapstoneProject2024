Unloading module 'code-server/4.9.1'
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:23<00:23, 23.50s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:23<00:23, 23.42s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:23<00:23, 23.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 10.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.54s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench_1/checkpoints/tiny-llava-KD-pretrain/checkpoint-6594 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.50s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench_1/checkpoints/tiny-llava-KD-pretrain/checkpoint-6594 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 10.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.63s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench_1/checkpoints/tiny-llava-KD-pretrain/checkpoint-6594 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
wandb: Currently logged in as: ltl2113 (llavamed). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/wandb/run-20240327_132039-d1cxdv5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tiny-llava-base-pretrain-scratch/ltl2113/LLaVA-Med/TinyLLaVABench_1/checkpoints/tiny-llava-KD-pretrain/checkpoint-6594-siglip-so400m-patch14-384
wandb: ⭐️ View project at https://wandb.ai/llavamed/huggingface
wandb: 🚀 View run at https://wandb.ai/llavamed/huggingface/runs/d1cxdv5d
  0%|          | 0/615 [00:00<?, ?it/s]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/615 [00:14<2:24:43, 14.14s/it]                                                   0%|          | 1/615 [00:14<2:24:43, 14.14s/it]  0%|          | 2/615 [00:17<1:20:32,  7.88s/it]                                                   0%|          | 2/615 [00:17<1:20:32,  7.88s/it]  0%|          | 3/615 [00:20<58:32,  5.74s/it]                                                   0%|          | 3/615 [00:20<58:32,  5.74s/it]  1%|          | 4/615 [00:23<47:52,  4.70s/it]                                                 1%|          | 4/615 [00:23<47:52,  4.70s/it]  1%|          | 5/615 [00:27<43:07,  4.24s/it]                                                 1%|          | 5/615 [00:27<43:07,  4.24s/it]  1%|          | 6/615 [00:30<39:57,  3.94s/it]                                                 1%|          | 6/615 [00:30<39:57,  3.94s/it]  1%|          | 7/615 [00:33<36:29,  3.60s/it]                                                 1%|          | 7/615 [00:33<36:29,  3.60s/it]  1%|▏         | 8/615 [00:36<33:43,  3.33s/it]                                                 1%|▏         | 8/615 [00:36<33:43,  3.33s/it]  1%|▏         | 9/615 [00:39<31:41,  3.14s/it]                                                 1%|▏         | 9/615 [00:39<31:41,  3.14s/it]  2%|▏         | 10/615 [00:42<31:44,  3.15s/it]                                                  2%|▏         | 10/615 [00:42<31:44,  3.15s/it]  2%|▏         | 11/615 [00:45<32:42,  3.25s/it]                                                  2%|▏         | 11/615 [00:45<32:42,  3.25s/it]  2%|▏         | 12/615 [00:49<32:51,  3.27s/it]                                                  2%|▏         | 12/615 [00:49<32:51,  3.27s/it]  2%|▏         | 13/615 [00:51<31:46,  3.17s/it]                                                  2%|▏         | 13/615 [00:51<31:46,  3.17s/it]  2%|▏         | 14/615 [00:54<30:27,  3.04s/it]                                                  2%|▏         | 14/615 [00:54<30:27,  3.04s/it]  2%|▏         | 15/615 [00:58<31:44,  3.17s/it]                                                  2%|▏         | 15/615 [00:58<31:44,  3.17s/it]  3%|▎         | 16/615 [01:01<32:15,  3.23s/it]                                                  3%|▎         | 16/615 [01:01<32:15,  3.23s/it]  3%|▎         | 17/615 [01:04<30:38,  3.07s/it]                                                  3%|▎         | 17/615 [01:04<30:38,  3.07s/it]  3%|▎         | 18/615 [01:07<29:47,  2.99s/it]                                                  3%|▎         | 18/615 [01:07<29:47,  2.99s/it]  3%|▎         | 19/615 [01:09<29:02,  2.92s/it]                                                  3%|▎         | 19/615 [01:09<29:02,  2.92s/it]  3%|▎         | 20/615 [01:13<29:56,  3.02s/it]                                                  3%|▎         | 20/615 [01:13<29:56,  3.02s/it]  3%|▎         | 21/615 [01:16<29:35,  2.99s/it]                                                  3%|▎         | 21/615 [01:16<29:35,  2.99s/it]  4%|▎         | 22/615 [01:18<28:21,  2.87s/it]                                                  4%|▎         | 22/615 [01:18<28:21,  2.87s/it]  4%|▎         | 23/615 [01:21<28:01,  2.84s/it]                                                  4%|▎         | 23/615 [01:21<28:01,  2.84s/it]  4%|▍         | 24/615 [01:24<27:24,  2.78s/it]                                                  4%|▍         | 24/615 [01:24<27:24,  2.78s/it]  4%|▍         | 25/615 [01:26<27:07,  2.76s/it]                                                  4%|▍         | 25/615 [01:26<27:07,  2.76s/it]  4%|▍         | 26/615 [01:29<26:55,  2.74s/it]                                                  4%|▍         | 26/615 [01:29<26:55,  2.74s/it]  4%|▍         | 27/615 [01:32<28:11,  2.88s/it]                                                  4%|▍         | 27/615 [01:32<28:11,  2.88s/it]  5%|▍         | 28/615 [01:35<28:22,  2.90s/it]                                                  5%|▍         | 28/615 [01:35<28:22,  2.90s/it]  5%|▍         | 29/615 [01:38<27:36,  2.83s/it]                                                  5%|▍         | 29/615 [01:38<27:36,  2.83s/it]  5%|▍         | 30/615 [01:40<26:59,  2.77s/it]                                                  5%|▍         | 30/615 [01:40<26:59,  2.77s/it]  5%|▌         | 31/615 [01:43<26:27,  2.72s/it]                                                  5%|▌         | 31/615 [01:43<26:27,  2.72s/it]  5%|▌         | 32/615 [01:46<27:47,  2.86s/it]                                                  5%|▌         | 32/615 [01:46<27:47,  2.86s/it]  5%|▌         | 33/615 [01:50<29:19,  3.02s/it]                                                  5%|▌         | 33/615 [01:50<29:19,  3.02s/it]  6%|▌         | 34/615 [01:52<28:46,  2.97s/it]                                                  6%|▌         | 34/615 [01:52<28:46,  2.97s/it]  6%|▌         | 35/615 [01:55<28:25,  2.94s/it]                                                  6%|▌         | 35/615 [01:55<28:25,  2.94s/it]  6%|▌         | 36/615 [01:59<29:25,  3.05s/it]                                                  6%|▌         | 36/615 [01:59<29:25,  3.05s/it]  6%|▌         | 37/615 [02:02<29:41,  3.08s/it]                                                  6%|▌         | 37/615 [02:02<29:41,  3.08s/it]  6%|▌         | 38/615 [02:05<30:44,  3.20s/it]                                                  6%|▌         | 38/615 [02:05<30:44,  3.20s/it]  6%|▋         | 39/615 [02:08<30:40,  3.19s/it]                                                  6%|▋         | 39/615 [02:08<30:40,  3.19s/it]  7%|▋         | 40/615 [02:12<30:22,  3.17s/it]                                                  7%|▋         | 40/615 [02:12<30:22,  3.17s/it]  7%|▋         | 41/615 [02:14<28:55,  3.02s/it]                                                  7%|▋         | 41/615 [02:14<28:55,  3.02s/it]  7%|▋         | 42/615 [02:17<27:55,  2.92s/it]                                                  7%|▋         | 42/615 [02:17<27:55,  2.92s/it]  7%|▋         | 43/615 [02:20<28:03,  2.94s/it]                                                  7%|▋         | 43/615 [02:20<28:03,  2.94s/it]  7%|▋         | 44/615 [02:23<27:09,  2.85s/it]                                                  7%|▋         | 44/615 [02:23<27:09,  2.85s/it]  7%|▋         | 45/615 [02:25<26:46,  2.82s/it]                                                  7%|▋         | 45/615 [02:25<26:46,  2.82s/it]  7%|▋         | 46/615 [02:28<27:47,  2.93s/it]                                                  7%|▋         | 46/615 [02:28<27:47,  2.93s/it]  8%|▊         | 47/615 [02:31<27:15,  2.88s/it]                                                  8%|▊         | 47/615 [02:31<27:15,  2.88s/it]  8%|▊         | 48/615 [02:34<26:44,  2.83s/it]                                                  8%|▊         | 48/615 [02:34<26:44,  2.83s/it]  8%|▊         | 49/615 [02:37<28:43,  3.05s/it]                                                  8%|▊         | 49/615 [02:37<28:43,  3.05s/it]  8%|▊         | 50/615 [02:41<30:05,  3.20s/it]                                                  8%|▊         | 50/615 [02:41<30:05,  3.20s/it]  8%|▊         | 51/615 [02:44<29:25,  3.13s/it]                                                  8%|▊         | 51/615 [02:44<29:25,  3.13s/it]  8%|▊         | 52/615 [02:47<28:12,  3.01s/it]                                                  8%|▊         | 52/615 [02:47<28:12,  3.01s/it]  9%|▊         | 53/615 [02:49<27:19,  2.92s/it]                                                  9%|▊         | 53/615 [02:49<27:19,  2.92s/it]  9%|▉         | 54/615 [02:52<27:06,  2.90s/it]                                                  9%|▉         | 54/615 [02:52<27:06,  2.90s/it]  9%|▉         | 55/615 [02:55<27:52,  2.99s/it]                                                  9%|▉         | 55/615 [02:56<27:52,  2.99s/it]  9%|▉         | 56/615 [02:59<28:41,  3.08s/it]                                                  9%|▉         | 56/615 [02:59<28:41,  3.08s/it]  9%|▉         | 57/615 [03:02<27:51,  3.00s/it]                                                  9%|▉         | 57/615 [03:02<27:51,  3.00s/it]  9%|▉         | 58/615 [03:04<27:11,  2.93s/it]                                                  9%|▉         | 58/615 [03:04<27:11,  2.93s/it] 10%|▉         | 59/615 [03:07<26:43,  2.88s/it]                                                 10%|▉         | 59/615 [03:07<26:43,  2.88s/it] 10%|▉         | 60/615 [03:11<28:03,  3.03s/it]                                                 10%|▉         | 60/615 [03:11<28:03,  3.03s/it] 10%|▉         | 61/615 [03:13<26:58,  2.92s/it]                                                 10%|▉         | 61/615 [03:13<26:58,  2.92s/it] 10%|█         | 62/615 [03:16<26:20,  2.86s/it]                                                 10%|█         | 62/615 [03:16<26:20,  2.86s/it] 10%|█         | 63/615 [03:19<25:39,  2.79s/it]                                                 10%|█         | 63/615 [03:19<25:39,  2.79s/it] 10%|█         | 64/615 [03:21<25:32,  2.78s/it]                                                 10%|█         | 64/615 [03:21<25:32,  2.78s/it] 11%|█         | 65/615 [03:24<25:10,  2.75s/it]                                                 11%|█         | 65/615 [03:24<25:10,  2.75s/it] 11%|█         | 66/615 [03:27<24:54,  2.72s/it]                                                 11%|█         | 66/615 [03:27<24:54,  2.72s/it] 11%|█         | 67/615 [03:29<25:05,  2.75s/it]                                                 11%|█         | 67/615 [03:29<25:05,  2.75s/it] 11%|█         | 68/615 [03:32<25:21,  2.78s/it]                                                 11%|█         | 68/615 [03:32<25:21,  2.78s/it] 11%|█         | 69/615 [03:35<25:16,  2.78s/it]                                                 11%|█         | 69/615 [03:35<25:16,  2.78s/it] 11%|█▏        | 70/615 [03:38<25:04,  2.76s/it]                                                 11%|█▏        | 70/615 [03:38<25:04,  2.76s/it] 12%|█▏        | 71/615 [03:41<26:30,  2.92s/it]                                                 12%|█▏        | 71/615 [03:41<26:30,  2.92s/it] 12%|█▏        | 72/615 [03:44<25:40,  2.84s/it]                                                 12%|█▏        | 72/615 [03:44<25:40,  2.84s/it] 12%|█▏        | 73/615 [03:46<25:17,  2.80s/it]                                                 12%|█▏        | 73/615 [03:46<25:17,  2.80s/it] 12%|█▏        | 74/615 [03:49<24:36,  2.73s/it]                                                 12%|█▏        | 74/615 [03:49<24:36,  2.73s/it] 12%|█▏        | 75/615 [03:52<24:22,  2.71s/it]                                                 12%|█▏        | 75/615 [03:52<24:22,  2.71s/it] 12%|█▏        | 76/615 [03:54<23:49,  2.65s/it]                                                 12%|█▏        | 76/615 [03:54<23:49,  2.65s/it] 13%|█▎        | 77/615 [03:57<23:46,  2.65s/it]                                                 13%|█▎        | 77/615 [03:57<23:46,  2.65s/it] 13%|█▎        | 78/615 [03:59<23:44,  2.65s/it]                                                 13%|█▎        | 78/615 [03:59<23:44,  2.65s/it] 13%|█▎        | 79/615 [04:02<24:03,  2.69s/it]                                                 13%|█▎        | 79/615 [04:02<24:03,  2.69s/it] 13%|█▎        | 80/615 [04:05<23:50,  2.67s/it]                                                 13%|█▎        | 80/615 [04:05<23:50,  2.67s/it] 13%|█▎        | 81/615 [04:07<23:30,  2.64s/it]                                                 13%|█▎        | 81/615 [04:07<23:30,  2.64s/it] 13%|█▎        | 82/615 [04:10<23:39,  2.66s/it]                                                 13%|█▎        | 82/615 [04:10<23:39,  2.66s/it] 13%|█▎        | 83/615 [04:13<25:03,  2.83s/it]                                                 13%|█▎        | 83/615 [04:13<25:03,  2.83s/it] 14%|█▎        | 84/615 [04:16<24:56,  2.82s/it]                                                 14%|█▎        | 84/615 [04:16<24:56,  2.82s/it] 14%|█▍        | 85/615 [04:19<24:48,  2.81s/it]                                                 14%|█▍        | 85/615 [04:19<24:48,  2.81s/it] 14%|█▍        | 86/615 [04:22<24:09,  2.74s/it]                                                 14%|█▍        | 86/615 [04:22<24:09,  2.74s/it] 14%|█▍        | 87/615 [04:24<23:48,  2.71s/it]                                                 14%|█▍        | 87/615 [04:24<23:48,  2.71s/it] 14%|█▍        | 88/615 [04:27<23:28,  2.67s/it]                                                 14%|█▍        | 88/615 [04:27<23:28,  2.67s/it] 14%|█▍        | 89/615 [04:29<23:12,  2.65s/it]                                                 14%|█▍        | 89/615 [04:29<23:12,  2.65s/it] 15%|█▍        | 90/615 [04:32<23:08,  2.64s/it]                                                 15%|█▍        | 90/615 [04:32<23:08,  2.64s/it] 15%|█▍        | 91/615 [04:35<23:07,  2.65s/it]                                                 15%|█▍        | 91/615 [04:35<23:07,  2.65s/it] 15%|█▍        | 92/615 [04:37<22:59,  2.64s/it]                                                 15%|█▍        | 92/615 [04:37<22:59,  2.64s/it] 15%|█▌        | 93/615 [04:40<22:46,  2.62s/it]                                                 15%|█▌        | 93/615 [04:40<22:46,  2.62s/it] 15%|█▌        | 94/615 [04:42<22:50,  2.63s/it]                                                 15%|█▌        | 94/615 [04:42<22:50,  2.63s/it] 15%|█▌        | 95/615 [04:45<23:47,  2.74s/it]                                                 15%|█▌        | 95/615 [04:45<23:47,  2.74s/it] 16%|█▌        | 96/615 [04:48<24:23,  2.82s/it]                                                 16%|█▌        | 96/615 [04:48<24:23,  2.82s/it] 16%|█▌        | 97/615 [04:51<23:46,  2.75s/it]                                                 16%|█▌        | 97/615 [04:51<23:46,  2.75s/it] 16%|█▌        | 98/615 [04:54<24:23,  2.83s/it]                                                 16%|█▌        | 98/615 [04:54<24:23,  2.83s/it] 16%|█▌        | 99/615 [04:58<26:37,  3.10s/it]                                                 16%|█▌        | 99/615 [04:58<26:37,  3.10s/it] 16%|█▋        | 100/615 [05:01<26:37,  3.10s/it]                                                  16%|█▋        | 100/615 [05:01<26:37,  3.10s/it] 16%|█▋        | 101/615 [05:04<25:30,  2.98s/it]                                                  16%|█▋        | 101/615 [05:04<25:30,  2.98s/it] 17%|█▋        | 102/615 [05:06<24:42,  2.89s/it]                                                  17%|█▋        | 102/615 [05:06<24:42,  2.89s/it] 17%|█▋        | 103/615 [05:09<24:11,  2.84s/it]                                                  17%|█▋        | 103/615 [05:09<24:11,  2.84s/it] 17%|█▋        | 104/615 [05:12<23:55,  2.81s/it]                                                  17%|█▋        | 104/615 [05:12<23:55,  2.81s/it] 17%|█▋        | 105/615 [05:15<23:43,  2.79s/it]                                                  17%|█▋        | 105/615 [05:15<23:43,  2.79s/it] 17%|█▋        | 106/615 [05:17<23:40,  2.79s/it]                                                  17%|█▋        | 106/615 [05:17<23:40,  2.79s/it] 17%|█▋        | 107/615 [05:21<24:42,  2.92s/it]                                                  17%|█▋        | 107/615 [05:21<24:42,  2.92s/it] 18%|█▊        | 108/615 [05:23<23:52,  2.83s/it]                                                  18%|█▊        | 108/615 [05:23<23:52,  2.83s/it] 18%|█▊        | 109/615 [05:26<23:35,  2.80s/it]                                                  18%|█▊        | 109/615 [05:26<23:35,  2.80s/it] 18%|█▊        | 110/615 [05:29<23:40,  2.81s/it]                                                  18%|█▊        | 110/615 [05:29<23:40,  2.81s/it] 18%|█▊        | 111/615 [05:32<24:41,  2.94s/it]                                                  18%|█▊        | 111/615 [05:32<24:41,  2.94s/it] 18%|█▊        | 112/615 [05:35<25:48,  3.08s/it]                                                  18%|█▊        | 112/615 [05:35<25:48,  3.08s/it] 18%|█▊        | 113/615 [05:38<25:27,  3.04s/it]                                                  18%|█▊        | 113/615 [05:38<25:27,  3.04s/it] 19%|█▊        | 114/615 [05:41<24:50,  2.97s/it]                                                  19%|█▊        | 114/615 [05:41<24:50,  2.97s/it] 19%|█▊        | 115/615 [05:44<24:21,  2.92s/it]                                                  19%|█▊        | 115/615 [05:44<24:21,  2.92s/it] 19%|█▉        | 116/615 [05:47<23:59,  2.89s/it]                                                  19%|█▉        | 116/615 [05:47<23:59,  2.89s/it] 19%|█▉        | 117/615 [05:50<23:58,  2.89s/it]                                                  19%|█▉        | 117/615 [05:50<23:58,  2.89s/it] 19%|█▉        | 118/615 [05:53<23:57,  2.89s/it]                                                  19%|█▉        | 118/615 [05:53<23:57,  2.89s/it] 19%|█▉        | 119/615 [05:55<23:31,  2.84s/it]                                                  19%|█▉        | 119/615 [05:55<23:31,  2.84s/it] 20%|█▉        | 120/615 [05:58<22:47,  2.76s/it]                                                  20%|█▉        | 120/615 [05:58<22:47,  2.76s/it] 20%|█▉        | 121/615 [06:01<22:37,  2.75s/it]                                                  20%|█▉        | 121/615 [06:01<22:37,  2.75s/it] 20%|█▉        | 122/615 [06:03<22:24,  2.73s/it]                                                  20%|█▉        | 122/615 [06:03<22:24,  2.73s/it] 20%|██        | 123/615 [06:06<22:21,  2.73s/it]                                                  20%|██        | 123/615 [06:06<22:21,  2.73s/it] 20%|██        | 124/615 [06:09<23:49,  2.91s/it]                                                  20%|██        | 124/615 [06:09<23:49,  2.91s/it] 20%|██        | 125/615 [06:13<24:42,  3.02s/it]                                                  20%|██        | 125/615 [06:13<24:42,  3.02s/it] 20%|██        | 126/615 [06:15<24:04,  2.95s/it]                                                  20%|██        | 126/615 [06:15<24:04,  2.95s/it] 21%|██        | 127/615 [06:18<23:44,  2.92s/it]                                                  21%|██        | 127/615 [06:18<23:44,  2.92s/it] 21%|██        | 128/615 [06:21<23:12,  2.86s/it]                                                  21%|██        | 128/615 [06:21<23:12,  2.86s/it] 21%|██        | 129/615 [06:24<24:34,  3.03s/it]                                                  21%|██        | 129/615 [06:24<24:34,  3.03s/it] 21%|██        | 130/615 [06:28<24:53,  3.08s/it]                                                  21%|██        | 130/615 [06:28<24:53,  3.08s/it] 21%|██▏       | 131/615 [06:31<24:43,  3.06s/it]                                                  21%|██▏       | 131/615 [06:31<24:43,  3.06s/it] 21%|██▏       | 132/615 [06:33<23:57,  2.98s/it]                                                  21%|██▏       | 132/615 [06:33<23:57,  2.98s/it] 22%|██▏       | 133/615 [06:36<23:33,  2.93s/it]                                                  22%|██▏       | 133/615 [06:36<23:33,  2.93s/it] 22%|██▏       | 134/615 [06:39<22:55,  2.86s/it]                                                  22%|██▏       | 134/615 [06:39<22:55,  2.86s/it] 22%|██▏       | 135/615 [06:42<23:21,  2.92s/it]                                                  22%|██▏       | 135/615 [06:42<23:21,  2.92s/it] 22%|██▏       | 136/615 [06:45<23:37,  2.96s/it]                                                  22%|██▏       | 136/615 [06:45<23:37,  2.96s/it] 22%|██▏       | 137/615 [06:48<24:35,  3.09s/it]                                                  22%|██▏       | 137/615 [06:48<24:35,  3.09s/it] 22%|██▏       | 138/615 [06:52<25:48,  3.25s/it]                                                  22%|██▏       | 138/615 [06:52<25:48,  3.25s/it] 23%|██▎       | 139/615 [06:56<26:50,  3.38s/it]                                                  23%|██▎       | 139/615 [06:56<26:50,  3.38s/it] 23%|██▎       | 140/615 [06:59<26:22,  3.33s/it]                                                  23%|██▎       | 140/615 [06:59<26:22,  3.33s/it] 23%|██▎       | 141/615 [07:02<25:59,  3.29s/it]                                                  23%|██▎       | 141/615 [07:02<25:59,  3.29s/it] 23%|██▎       | 142/615 [07:06<26:39,  3.38s/it]                                                  23%|██▎       | 142/615 [07:06<26:39,  3.38s/it] 23%|██▎       | 143/615 [07:09<26:11,  3.33s/it]                                                  23%|██▎       | 143/615 [07:09<26:11,  3.33s/it] 23%|██▎       | 144/615 [07:12<26:24,  3.36s/it]                                                  23%|██▎       | 144/615 [07:12<26:24,  3.36s/it] 24%|██▎       | 145/615 [07:15<25:24,  3.24s/it]                                                  24%|██▎       | 145/615 [07:15<25:24,  3.24s/it] 24%|██▎       | 146/615 [07:18<24:05,  3.08s/it]                                                  24%|██▎       | 146/615 [07:18<24:05,  3.08s/it] 24%|██▍       | 147/615 [07:21<23:13,  2.98s/it]                                                  24%|██▍       | 147/615 [07:21<23:13,  2.98s/it] 24%|██▍       | 148/615 [07:24<22:48,  2.93s/it]                                                  24%|██▍       | 148/615 [07:24<22:48,  2.93s/it] 24%|██▍       | 149/615 [07:27<23:04,  2.97s/it]                                                  24%|██▍       | 149/615 [07:27<23:04,  2.97s/it] 24%|██▍       | 150/615 [07:30<22:51,  2.95s/it]                                                  24%|██▍       | 150/615 [07:30<22:51,  2.95s/it] 25%|██▍       | 151/615 [07:32<22:17,  2.88s/it]                                                  25%|██▍       | 151/615 [07:32<22:17,  2.88s/it] 25%|██▍       | 152/615 [07:35<21:51,  2.83s/it]                                                  25%|██▍       | 152/615 [07:35<21:51,  2.83s/it] 25%|██▍       | 153/615 [07:38<21:34,  2.80s/it]                                                  25%|██▍       | 153/615 [07:38<21:34,  2.80s/it] 25%|██▌       | 154/615 [07:40<21:24,  2.79s/it]                                                  25%|██▌       | 154/615 [07:40<21:24,  2.79s/it] 25%|██▌       | 155/615 [07:43<21:05,  2.75s/it]                                                  25%|██▌       | 155/615 [07:43<21:05,  2.75s/it] 25%|██▌       | 156/615 [07:46<20:48,  2.72s/it]                                                  25%|██▌       | 156/615 [07:46<20:48,  2.72s/it] 26%|██▌       | 157/615 [07:49<20:52,  2.73s/it]                                                  26%|██▌       | 157/615 [07:49<20:52,  2.73s/it] 26%|██▌       | 158/615 [07:51<20:53,  2.74s/it]                                                  26%|██▌       | 158/615 [07:51<20:53,  2.74s/it] 26%|██▌       | 159/615 [07:54<20:53,  2.75s/it]                                                  26%|██▌       | 159/615 [07:54<20:53,  2.75s/it] 26%|██▌       | 160/615 [07:57<20:32,  2.71s/it]                                                  26%|██▌       | 160/615 [07:57<20:32,  2.71s/it] 26%|██▌       | 161/615 [08:00<22:02,  2.91s/it]                                                  26%|██▌       | 161/615 [08:00<22:02,  2.91s/it] 26%|██▋       | 162/615 [08:03<21:19,  2.82s/it]                                                  26%|██▋       | 162/615 [08:03<21:19,  2.82s/it] 27%|██▋       | 163/615 [08:05<20:39,  2.74s/it]                                                  27%|██▋       | 163/615 [08:05<20:39,  2.74s/it] 27%|██▋       | 164/615 [08:08<20:17,  2.70s/it]                                                  27%|██▋       | 164/615 [08:08<20:17,  2.70s/it] 27%|██▋       | 165/615 [08:11<20:20,  2.71s/it]                                                  27%|██▋       | 165/615 [08:11<20:20,  2.71s/it] 27%|██▋       | 166/615 [08:13<20:14,  2.71s/it]                                                  27%|██▋       | 166/615 [08:13<20:14,  2.71s/it] 27%|██▋       | 167/615 [08:16<20:15,  2.71s/it]                                                  27%|██▋       | 167/615 [08:16<20:15,  2.71s/it] 27%|██▋       | 168/615 [08:19<19:58,  2.68s/it]                                                  27%|██▋       | 168/615 [08:19<19:58,  2.68s/it] 27%|██▋       | 169/615 [08:21<19:44,  2.66s/it]                                                  27%|██▋       | 169/615 [08:21<19:44,  2.66s/it] 28%|██▊       | 170/615 [08:24<19:43,  2.66s/it]                                                  28%|██▊       | 170/615 [08:24<19:43,  2.66s/it] 28%|██▊       | 171/615 [08:26<19:34,  2.65s/it]                                                  28%|██▊       | 171/615 [08:26<19:34,  2.65s/it] 28%|██▊       | 172/615 [08:29<19:29,  2.64s/it]                                                  28%|██▊       | 172/615 [08:29<19:29,  2.64s/it] 28%|██▊       | 173/615 [08:32<20:50,  2.83s/it]                                                  28%|██▊       | 173/615 [08:32<20:50,  2.83s/it] 28%|██▊       | 174/615 [08:35<20:17,  2.76s/it]                                                  28%|██▊       | 174/615 [08:35<20:17,  2.76s/it] 28%|██▊       | 175/615 [08:37<19:43,  2.69s/it]                                                  28%|██▊       | 175/615 [08:37<19:43,  2.69s/it] 29%|██▊       | 176/615 [08:40<20:00,  2.73s/it]                                                  29%|██▊       | 176/615 [08:40<20:00,  2.73s/it] 29%|██▉       | 177/615 [08:43<19:42,  2.70s/it]                                                  29%|██▉       | 177/615 [08:43<19:42,  2.70s/it] 29%|██▉       | 178/615 [08:46<19:31,  2.68s/it]                                                  29%|██▉       | 178/615 [08:46<19:31,  2.68s/it] 29%|██▉       | 179/615 [08:48<19:39,  2.70s/it]                                                  29%|██▉       | 179/615 [08:48<19:39,  2.70s/it] 29%|██▉       | 180/615 [08:51<19:29,  2.69s/it]                                                  29%|██▉       | 180/615 [08:51<19:29,  2.69s/it] 29%|██▉       | 181/615 [08:54<19:12,  2.66s/it]                                                  29%|██▉       | 181/615 [08:54<19:12,  2.66s/it] 30%|██▉       | 182/615 [08:57<21:37,  3.00s/it]                                                  30%|██▉       | 182/615 [08:57<21:37,  3.00s/it] 30%|██▉       | 183/615 [09:00<20:47,  2.89s/it]                                                  30%|██▉       | 183/615 [09:00<20:47,  2.89s/it] 30%|██▉       | 184/615 [09:03<20:14,  2.82s/it]                                                  30%|██▉       | 184/615 [09:03<20:14,  2.82s/it] 30%|███       | 185/615 [09:06<21:17,  2.97s/it]                                                  30%|███       | 185/615 [09:06<21:17,  2.97s/it] 30%|███       | 186/615 [09:09<20:26,  2.86s/it]                                                  30%|███       | 186/615 [09:09<20:26,  2.86s/it] 30%|███       | 187/615 [09:11<19:50,  2.78s/it]                                                  30%|███       | 187/615 [09:11<19:50,  2.78s/it] 31%|███       | 188/615 [09:14<19:30,  2.74s/it]                                                  31%|███       | 188/615 [09:14<19:30,  2.74s/it] 31%|███       | 189/615 [09:16<19:08,  2.70s/it]                                                  31%|███       | 189/615 [09:16<19:08,  2.70s/it] 31%|███       | 190/615 [09:19<18:54,  2.67s/it]                                                  31%|███       | 190/615 [09:19<18:54,  2.67s/it] 31%|███       | 191/615 [09:21<18:25,  2.61s/it]                                                  31%|███       | 191/615 [09:22<18:25,  2.61s/it] 31%|███       | 192/615 [09:24<18:17,  2.60s/it]                                                  31%|███       | 192/615 [09:24<18:17,  2.60s/it] 31%|███▏      | 193/615 [09:27<18:08,  2.58s/it]                                                  31%|███▏      | 193/615 [09:27<18:08,  2.58s/it] 32%|███▏      | 194/615 [09:29<18:05,  2.58s/it]                                                  32%|███▏      | 194/615 [09:29<18:05,  2.58s/it] 32%|███▏      | 195/615 [09:32<18:00,  2.57s/it]                                                  32%|███▏      | 195/615 [09:32<18:00,  2.57s/it] 32%|███▏      | 196/615 [09:34<17:57,  2.57s/it]                                                  32%|███▏      | 196/615 [09:34<17:57,  2.57s/it] 32%|███▏      | 197/615 [09:38<19:23,  2.78s/it]                                                  32%|███▏      | 197/615 [09:38<19:23,  2.78s/it] 32%|███▏      | 198/615 [09:40<19:20,  2.78s/it]                                                  32%|███▏      | 198/615 [09:40<19:20,  2.78s/it] 32%|███▏      | 199/615 [09:43<18:49,  2.72s/it]                                                  32%|███▏      | 199/615 [09:43<18:49,  2.72s/it] 33%|███▎      | 200/615 [09:46<18:33,  2.68s/it]                                                  33%|███▎      | 200/615 [09:46<18:33,  2.68s/it] 33%|███▎      | 201/615 [09:48<18:10,  2.63s/it]                                                  33%|███▎      | 201/615 [09:48<18:10,  2.63s/it] 33%|███▎      | 202/615 [09:50<16:57,  2.46s/it]                                                  33%|███▎      | 202/615 [09:50<16:57,  2.46s/it] 33%|███▎      | 203/615 [09:52<15:54,  2.32s/it]                                                  33%|███▎      | 203/615 [09:52<15:54,  2.32s/it] 33%|███▎      | 204/615 [09:54<15:09,  2.21s/it]                                                  33%|███▎      | 204/615 [09:54<15:09,  2.21s/it] 33%|███▎      | 205/615 [09:57<15:40,  2.29s/it]                                                  33%|███▎      | 205/615 [09:57<15:40,  2.29s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 33%|███▎      | 206/615 [10:29<1:17:55, 11.43s/it]                                                    33%|███▎      | 206/615 [10:29<1:17:55, 11.43s/it] 34%|███▎      | 207/615 [10:32<1:00:24,  8.88s/it]                                                    34%|███▎      | 207/615 [10:32<1:00:24,  8.88s/it] 34%|███▍      | 208/615 [10:35<47:50,  7.05s/it]                                                    34%|███▍      | 208/615 [10:35<47:50,  7.05s/it] 34%|███▍      | 209/615 [10:38<39:13,  5.80s/it]                                                  34%|███▍      | 209/615 [10:38<39:13,  5.80s/it] 34%|███▍      | 210/615 [10:41<32:48,  4.86s/it]                                                  34%|███▍      | 210/615 [10:41<32:48,  4.86s/it] 34%|███▍      | 211/615 [10:44<29:29,  4.38s/it]                                                  34%|███▍      | 211/615 [10:44<29:29,  4.38s/it] 34%|███▍      | 212/615 [10:46<25:59,  3.87s/it]                                                  34%|███▍      | 212/615 [10:46<25:59,  3.87s/it] 35%|███▍      | 213/615 [10:50<24:38,  3.68s/it]                                                  35%|███▍      | 213/615 [10:50<24:38,  3.68s/it] 35%|███▍      | 214/615 [10:52<22:35,  3.38s/it]                                                  35%|███▍      | 214/615 [10:52<22:35,  3.38s/it] 35%|███▍      | 215/615 [10:56<22:20,  3.35s/it]                                                  35%|███▍      | 215/615 [10:56<22:20,  3.35s/it] 35%|███▌      | 216/615 [10:59<22:42,  3.42s/it]                                                  35%|███▌      | 216/615 [10:59<22:42,  3.42s/it] 35%|███▌      | 217/615 [11:02<21:37,  3.26s/it]                                                  35%|███▌      | 217/615 [11:02<21:37,  3.26s/it] 35%|███▌      | 218/615 [11:05<20:47,  3.14s/it]                                                  35%|███▌      | 218/615 [11:05<20:47,  3.14s/it] 36%|███▌      | 219/615 [11:08<20:04,  3.04s/it]                                                  36%|███▌      | 219/615 [11:08<20:04,  3.04s/it] 36%|███▌      | 220/615 [11:11<19:25,  2.95s/it]                                                  36%|███▌      | 220/615 [11:11<19:25,  2.95s/it] 36%|███▌      | 221/615 [11:13<19:14,  2.93s/it]                                                  36%|███▌      | 221/615 [11:13<19:14,  2.93s/it] 36%|███▌      | 222/615 [11:17<19:37,  3.00s/it]                                                  36%|███▌      | 222/615 [11:17<19:37,  3.00s/it] 36%|███▋      | 223/615 [11:19<19:14,  2.95s/it]                                                  36%|███▋      | 223/615 [11:19<19:14,  2.95s/it] 36%|███▋      | 224/615 [11:22<18:42,  2.87s/it]                                                  36%|███▋      | 224/615 [11:22<18:42,  2.87s/it] 37%|███▋      | 225/615 [11:25<18:18,  2.82s/it]                                                  37%|███▋      | 225/615 [11:25<18:18,  2.82s/it] 37%|███▋      | 226/615 [11:28<18:04,  2.79s/it]                                                  37%|███▋      | 226/615 [11:28<18:04,  2.79s/it] 37%|███▋      | 227/615 [11:30<17:44,  2.74s/it]                                                  37%|███▋      | 227/615 [11:30<17:44,  2.74s/it] 37%|███▋      | 228/615 [11:33<17:18,  2.68s/it]                                                  37%|███▋      | 228/615 [11:33<17:18,  2.68s/it] 37%|███▋      | 229/615 [11:35<17:24,  2.71s/it]                                                  37%|███▋      | 229/615 [11:35<17:24,  2.71s/it] 37%|███▋      | 230/615 [11:38<17:20,  2.70s/it]                                                  37%|███▋      | 230/615 [11:38<17:20,  2.70s/it] 38%|███▊      | 231/615 [11:41<17:06,  2.67s/it]                                                  38%|███▊      | 231/615 [11:41<17:06,  2.67s/it] 38%|███▊      | 232/615 [11:43<16:59,  2.66s/it]                                                  38%|███▊      | 232/615 [11:43<16:59,  2.66s/it] 38%|███▊      | 233/615 [11:46<17:43,  2.78s/it]                                                  38%|███▊      | 233/615 [11:46<17:43,  2.78s/it] 38%|███▊      | 234/615 [11:49<18:00,  2.84s/it]                                                  38%|███▊      | 234/615 [11:49<18:00,  2.84s/it] 38%|███▊      | 235/615 [11:52<17:30,  2.76s/it]                                                  38%|███▊      | 235/615 [11:52<17:30,  2.76s/it] 38%|███▊      | 236/615 [11:55<17:06,  2.71s/it]                                                  38%|███▊      | 236/615 [11:55<17:06,  2.71s/it] 39%|███▊      | 237/615 [11:57<16:53,  2.68s/it]                                                  39%|███▊      | 237/615 [11:57<16:53,  2.68s/it] 39%|███▊      | 238/615 [12:00<16:45,  2.67s/it]                                                  39%|███▊      | 238/615 [12:00<16:45,  2.67s/it] 39%|███▉      | 239/615 [12:03<16:42,  2.67s/it]                                                  39%|███▉      | 239/615 [12:03<16:42,  2.67s/it] 39%|███▉      | 240/615 [12:05<16:43,  2.68s/it]                                                  39%|███▉      | 240/615 [12:05<16:43,  2.68s/it] 39%|███▉      | 241/615 [12:08<16:51,  2.71s/it]                                                  39%|███▉      | 241/615 [12:08<16:51,  2.71s/it] 39%|███▉      | 242/615 [12:11<16:46,  2.70s/it]                                                  39%|███▉      | 242/615 [12:11<16:46,  2.70s/it] 40%|███▉      | 243/615 [12:13<16:46,  2.71s/it]                                                  40%|███▉      | 243/615 [12:13<16:46,  2.71s/it] 40%|███▉      | 244/615 [12:16<16:51,  2.73s/it]                                                  40%|███▉      | 244/615 [12:16<16:51,  2.73s/it] 40%|███▉      | 245/615 [12:19<17:33,  2.85s/it]                                                  40%|███▉      | 245/615 [12:19<17:33,  2.85s/it] 40%|████      | 246/615 [12:22<17:42,  2.88s/it]                                                  40%|████      | 246/615 [12:22<17:42,  2.88s/it] 40%|████      | 247/615 [12:25<17:09,  2.80s/it]                                                  40%|████      | 247/615 [12:25<17:09,  2.80s/it] 40%|████      | 248/615 [12:28<16:51,  2.76s/it]                                                  40%|████      | 248/615 [12:28<16:51,  2.76s/it] 40%|████      | 249/615 [12:30<16:35,  2.72s/it]                                                  40%|████      | 249/615 [12:30<16:35,  2.72s/it] 41%|████      | 250/615 [12:33<16:37,  2.73s/it]                                                  41%|████      | 250/615 [12:33<16:37,  2.73s/it] 41%|████      | 251/615 [12:36<16:18,  2.69s/it]                                                  41%|████      | 251/615 [12:36<16:18,  2.69s/it] 41%|████      | 252/615 [12:38<16:07,  2.66s/it]                                                  41%|████      | 252/615 [12:38<16:07,  2.66s/it] 41%|████      | 253/615 [12:41<16:04,  2.67s/it]                                                  41%|████      | 253/615 [12:41<16:04,  2.67s/it] 41%|████▏     | 254/615 [12:43<15:47,  2.62s/it]                                                  41%|████▏     | 254/615 [12:43<15:47,  2.62s/it] 41%|████▏     | 255/615 [12:46<15:51,  2.64s/it]                                                  41%|████▏     | 255/615 [12:46<15:51,  2.64s/it] 42%|████▏     | 256/615 [12:49<15:41,  2.62s/it]                                                  42%|████▏     | 256/615 [12:49<15:41,  2.62s/it] 42%|████▏     | 257/615 [12:52<16:29,  2.76s/it]                                                  42%|████▏     | 257/615 [12:52<16:29,  2.76s/it] 42%|████▏     | 258/615 [12:55<17:00,  2.86s/it]                                                  42%|████▏     | 258/615 [12:55<17:00,  2.86s/it] 42%|████▏     | 259/615 [12:59<19:14,  3.24s/it]                                                  42%|████▏     | 259/615 [12:59<19:14,  3.24s/it] 42%|████▏     | 260/615 [13:02<19:10,  3.24s/it]                                                  42%|████▏     | 260/615 [13:02<19:10,  3.24s/it] 42%|████▏     | 261/615 [13:05<18:16,  3.10s/it]                                                  42%|████▏     | 261/615 [13:05<18:16,  3.10s/it] 43%|████▎     | 262/615 [13:08<17:32,  2.98s/it]                                                  43%|████▎     | 262/615 [13:08<17:32,  2.98s/it] 43%|████▎     | 263/615 [13:10<16:55,  2.88s/it]                                                  43%|████▎     | 263/615 [13:10<16:55,  2.88s/it] 43%|████▎     | 264/615 [13:13<16:42,  2.86s/it]                                                  43%|████▎     | 264/615 [13:13<16:42,  2.86s/it] 43%|████▎     | 265/615 [13:16<16:16,  2.79s/it]                                                  43%|████▎     | 265/615 [13:16<16:16,  2.79s/it] 43%|████▎     | 266/615 [13:18<16:04,  2.76s/it]                                                  43%|████▎     | 266/615 [13:18<16:04,  2.76s/it] 43%|████▎     | 267/615 [13:21<15:47,  2.72s/it]                                                  43%|████▎     | 267/615 [13:21<15:47,  2.72s/it] 44%|████▎     | 268/615 [13:24<16:11,  2.80s/it]                                                  44%|████▎     | 268/615 [13:24<16:11,  2.80s/it] 44%|████▎     | 269/615 [13:27<16:28,  2.86s/it]                                                  44%|████▎     | 269/615 [13:27<16:28,  2.86s/it] 44%|████▍     | 270/615 [13:30<16:08,  2.81s/it]                                                  44%|████▍     | 270/615 [13:30<16:08,  2.81s/it] 44%|████▍     | 271/615 [13:32<15:44,  2.74s/it]                                                  44%|████▍     | 271/615 [13:32<15:44,  2.74s/it] 44%|████▍     | 272/615 [13:35<15:24,  2.70s/it]                                                  44%|████▍     | 272/615 [13:35<15:24,  2.70s/it] 44%|████▍     | 273/615 [13:38<15:24,  2.70s/it]                                                  44%|████▍     | 273/615 [13:38<15:24,  2.70s/it] 45%|████▍     | 274/615 [13:40<15:16,  2.69s/it]                                                  45%|████▍     | 274/615 [13:40<15:16,  2.69s/it] 45%|████▍     | 275/615 [13:43<15:13,  2.69s/it]                                                  45%|████▍     | 275/615 [13:43<15:13,  2.69s/it] 45%|████▍     | 276/615 [13:46<15:06,  2.68s/it]                                                  45%|████▍     | 276/615 [13:46<15:06,  2.68s/it] 45%|████▌     | 277/615 [13:48<14:57,  2.66s/it]                                                  45%|████▌     | 277/615 [13:48<14:57,  2.66s/it] 45%|████▌     | 278/615 [13:51<14:47,  2.63s/it]                                                  45%|████▌     | 278/615 [13:51<14:47,  2.63s/it] 45%|████▌     | 279/615 [13:53<14:50,  2.65s/it]                                                  45%|████▌     | 279/615 [13:53<14:50,  2.65s/it] 46%|████▌     | 280/615 [13:56<15:03,  2.70s/it]                                                  46%|████▌     | 280/615 [13:56<15:03,  2.70s/it] 46%|████▌     | 281/615 [13:59<15:33,  2.80s/it]                                                  46%|████▌     | 281/615 [13:59<15:33,  2.80s/it] 46%|████▌     | 282/615 [14:02<15:13,  2.74s/it]                                                  46%|████▌     | 282/615 [14:02<15:13,  2.74s/it] 46%|████▌     | 283/615 [14:05<16:03,  2.90s/it]                                                  46%|████▌     | 283/615 [14:05<16:03,  2.90s/it] 46%|████▌     | 284/615 [14:08<16:35,  3.01s/it]                                                  46%|████▌     | 284/615 [14:08<16:35,  3.01s/it] 46%|████▋     | 285/615 [14:11<16:01,  2.91s/it]                                                  46%|████▋     | 285/615 [14:11<16:01,  2.91s/it] 47%|████▋     | 286/615 [14:14<15:44,  2.87s/it]                                                  47%|████▋     | 286/615 [14:14<15:44,  2.87s/it] 47%|████▋     | 287/615 [14:17<15:22,  2.81s/it]                                                  47%|████▋     | 287/615 [14:17<15:22,  2.81s/it] 47%|████▋     | 288/615 [14:19<15:16,  2.80s/it]                                                  47%|████▋     | 288/615 [14:19<15:16,  2.80s/it] 47%|████▋     | 289/615 [14:22<14:58,  2.76s/it]                                                  47%|████▋     | 289/615 [14:22<14:58,  2.76s/it] 47%|████▋     | 290/615 [14:25<14:54,  2.75s/it]                                                  47%|████▋     | 290/615 [14:25<14:54,  2.75s/it] 47%|████▋     | 291/615 [14:27<14:31,  2.69s/it]                                                  47%|████▋     | 291/615 [14:27<14:31,  2.69s/it] 47%|████▋     | 292/615 [14:31<15:33,  2.89s/it]                                                  47%|████▋     | 292/615 [14:31<15:33,  2.89s/it] 48%|████▊     | 293/615 [14:33<15:13,  2.84s/it]                                                  48%|████▊     | 293/615 [14:33<15:13,  2.84s/it] 48%|████▊     | 294/615 [14:36<14:58,  2.80s/it]                                                  48%|████▊     | 294/615 [14:36<14:58,  2.80s/it] 48%|████▊     | 295/615 [14:39<14:39,  2.75s/it]                                                  48%|████▊     | 295/615 [14:39<14:39,  2.75s/it] 48%|████▊     | 296/615 [14:41<14:25,  2.71s/it]                                                  48%|████▊     | 296/615 [14:41<14:25,  2.71s/it] 48%|████▊     | 297/615 [14:44<14:24,  2.72s/it]                                                  48%|████▊     | 297/615 [14:44<14:24,  2.72s/it] 48%|████▊     | 298/615 [14:47<14:18,  2.71s/it]                                                  48%|████▊     | 298/615 [14:47<14:18,  2.71s/it] 49%|████▊     | 299/615 [14:49<14:12,  2.70s/it]                                                  49%|████▊     | 299/615 [14:49<14:12,  2.70s/it] 49%|████▉     | 300/615 [14:52<13:56,  2.66s/it]                                                  49%|████▉     | 300/615 [14:52<13:56,  2.66s/it] 49%|████▉     | 301/615 [14:55<14:43,  2.81s/it]                                                  49%|████▉     | 301/615 [14:55<14:43,  2.81s/it] 49%|████▉     | 302/615 [14:59<15:32,  2.98s/it]                                                  49%|████▉     | 302/615 [14:59<15:32,  2.98s/it] 49%|████▉     | 303/615 [15:01<15:15,  2.93s/it]                                                  49%|████▉     | 303/615 [15:01<15:15,  2.93s/it] 49%|████▉     | 304/615 [15:04<15:32,  3.00s/it]                                                  49%|████▉     | 304/615 [15:04<15:32,  3.00s/it] 50%|████▉     | 305/615 [15:07<14:50,  2.87s/it]                                                  50%|████▉     | 305/615 [15:07<14:50,  2.87s/it] 50%|████▉     | 306/615 [15:10<14:26,  2.81s/it]                                                  50%|████▉     | 306/615 [15:10<14:26,  2.81s/it] 50%|████▉     | 307/615 [15:12<14:11,  2.76s/it]                                                  50%|████▉     | 307/615 [15:12<14:11,  2.76s/it] 50%|█████     | 308/615 [15:15<13:47,  2.69s/it]                                                  50%|█████     | 308/615 [15:15<13:47,  2.69s/it] 50%|█████     | 309/615 [15:18<13:37,  2.67s/it]                                                  50%|█████     | 309/615 [15:18<13:37,  2.67s/it] 50%|█████     | 310/615 [15:20<13:22,  2.63s/it]                                                  50%|█████     | 310/615 [15:20<13:22,  2.63s/it] 51%|█████     | 311/615 [15:23<13:20,  2.63s/it]                                                  51%|█████     | 311/615 [15:23<13:20,  2.63s/it] 51%|█████     | 312/615 [15:25<13:10,  2.61s/it]                                                  51%|█████     | 312/615 [15:25<13:10,  2.61s/it] 51%|█████     | 313/615 [15:28<13:12,  2.62s/it]                                                  51%|█████     | 313/615 [15:28<13:12,  2.62s/it] 51%|█████     | 314/615 [15:31<13:10,  2.63s/it]                                                  51%|█████     | 314/615 [15:31<13:10,  2.63s/it] 51%|█████     | 315/615 [15:33<13:03,  2.61s/it]                                                  51%|█████     | 315/615 [15:33<13:03,  2.61s/it] 51%|█████▏    | 316/615 [15:37<14:14,  2.86s/it]                                                  51%|█████▏    | 316/615 [15:37<14:14,  2.86s/it] 52%|█████▏    | 317/615 [15:39<13:45,  2.77s/it]                                                  52%|█████▏    | 317/615 [15:39<13:45,  2.77s/it] 52%|█████▏    | 318/615 [15:42<13:27,  2.72s/it]                                                  52%|█████▏    | 318/615 [15:42<13:27,  2.72s/it] 52%|█████▏    | 319/615 [15:44<13:24,  2.72s/it]                                                  52%|█████▏    | 319/615 [15:44<13:24,  2.72s/it] 52%|█████▏    | 320/615 [15:47<13:12,  2.69s/it]                                                  52%|█████▏    | 320/615 [15:47<13:12,  2.69s/it] 52%|█████▏    | 321/615 [15:50<12:56,  2.64s/it]                                                  52%|█████▏    | 321/615 [15:50<12:56,  2.64s/it] 52%|█████▏    | 322/615 [15:52<12:48,  2.62s/it]                                                  52%|█████▏    | 322/615 [15:52<12:48,  2.62s/it] 53%|█████▎    | 323/615 [15:55<12:49,  2.64s/it]                                                  53%|█████▎    | 323/615 [15:55<12:49,  2.64s/it] 53%|█████▎    | 324/615 [15:58<12:52,  2.66s/it]                                                  53%|█████▎    | 324/615 [15:58<12:52,  2.66s/it] 53%|█████▎    | 325/615 [16:00<12:40,  2.62s/it]                                                  53%|█████▎    | 325/615 [16:00<12:40,  2.62s/it] 53%|█████▎    | 326/615 [16:03<12:39,  2.63s/it]                                                  53%|█████▎    | 326/615 [16:03<12:39,  2.63s/it] 53%|█████▎    | 327/615 [16:05<12:37,  2.63s/it]                                                  53%|█████▎    | 327/615 [16:05<12:37,  2.63s/it] 53%|█████▎    | 328/615 [16:09<13:30,  2.82s/it]                                                  53%|█████▎    | 328/615 [16:09<13:30,  2.82s/it] 53%|█████▎    | 329/615 [16:11<13:05,  2.75s/it]                                                  53%|█████▎    | 329/615 [16:11<13:05,  2.75s/it] 54%|█████▎    | 330/615 [16:14<12:53,  2.71s/it]                                                  54%|█████▎    | 330/615 [16:14<12:53,  2.71s/it] 54%|█████▍    | 331/615 [16:16<12:37,  2.67s/it]                                                  54%|█████▍    | 331/615 [16:16<12:37,  2.67s/it] 54%|█████▍    | 332/615 [16:19<12:31,  2.66s/it]                                                  54%|█████▍    | 332/615 [16:19<12:31,  2.66s/it] 54%|█████▍    | 333/615 [16:22<12:26,  2.65s/it]                                                  54%|█████▍    | 333/615 [16:22<12:26,  2.65s/it] 54%|█████▍    | 334/615 [16:24<12:22,  2.64s/it]                                                  54%|█████▍    | 334/615 [16:24<12:22,  2.64s/it] 54%|█████▍    | 335/615 [16:27<12:20,  2.65s/it]                                                  54%|█████▍    | 335/615 [16:27<12:20,  2.65s/it] 55%|█████▍    | 336/615 [16:30<12:14,  2.63s/it]                                                  55%|█████▍    | 336/615 [16:30<12:14,  2.63s/it] 55%|█████▍    | 337/615 [16:32<12:15,  2.64s/it]                                                  55%|█████▍    | 337/615 [16:32<12:15,  2.64s/it] 55%|█████▍    | 338/615 [16:35<12:13,  2.65s/it]                                                  55%|█████▍    | 338/615 [16:35<12:13,  2.65s/it] 55%|█████▌    | 339/615 [16:38<12:18,  2.68s/it]                                                  55%|█████▌    | 339/615 [16:38<12:18,  2.68s/it] 55%|█████▌    | 340/615 [16:41<13:13,  2.88s/it]                                                  55%|█████▌    | 340/615 [16:41<13:13,  2.88s/it] 55%|█████▌    | 341/615 [16:44<12:42,  2.78s/it]                                                  55%|█████▌    | 341/615 [16:44<12:42,  2.78s/it] 56%|█████▌    | 342/615 [16:46<12:25,  2.73s/it]                                                  56%|█████▌    | 342/615 [16:46<12:25,  2.73s/it] 56%|█████▌    | 343/615 [16:49<12:22,  2.73s/it]                                                  56%|█████▌    | 343/615 [16:49<12:22,  2.73s/it] 56%|█████▌    | 344/615 [16:51<12:10,  2.69s/it]                                                  56%|█████▌    | 344/615 [16:51<12:10,  2.69s/it] 56%|█████▌    | 345/615 [16:54<12:00,  2.67s/it]                                                  56%|█████▌    | 345/615 [16:54<12:00,  2.67s/it] 56%|█████▋    | 346/615 [16:58<13:32,  3.02s/it]                                                  56%|█████▋    | 346/615 [16:58<13:32,  3.02s/it] 56%|█████▋    | 347/615 [17:01<13:09,  2.95s/it]                                                  56%|█████▋    | 347/615 [17:01<13:09,  2.95s/it] 57%|█████▋    | 348/615 [17:03<12:53,  2.90s/it]                                                  57%|█████▋    | 348/615 [17:04<12:53,  2.90s/it] 57%|█████▋    | 349/615 [17:06<12:43,  2.87s/it]                                                  57%|█████▋    | 349/615 [17:06<12:43,  2.87s/it] 57%|█████▋    | 350/615 [17:09<12:25,  2.81s/it]                                                  57%|█████▋    | 350/615 [17:09<12:25,  2.81s/it] 57%|█████▋    | 351/615 [17:12<12:51,  2.92s/it]                                                  57%|█████▋    | 351/615 [17:12<12:51,  2.92s/it] 57%|█████▋    | 352/615 [17:15<12:52,  2.94s/it]                                                  57%|█████▋    | 352/615 [17:15<12:52,  2.94s/it] 57%|█████▋    | 353/615 [17:18<12:33,  2.88s/it]                                                  57%|█████▋    | 353/615 [17:18<12:33,  2.88s/it] 58%|█████▊    | 354/615 [17:20<12:12,  2.81s/it]                                                  58%|█████▊    | 354/615 [17:20<12:12,  2.81s/it] 58%|█████▊    | 355/615 [17:24<12:54,  2.98s/it]                                                  58%|█████▊    | 355/615 [17:24<12:54,  2.98s/it] 58%|█████▊    | 356/615 [17:27<12:49,  2.97s/it]                                                  58%|█████▊    | 356/615 [17:27<12:49,  2.97s/it] 58%|█████▊    | 357/615 [17:30<12:24,  2.88s/it]                                                  58%|█████▊    | 357/615 [17:30<12:24,  2.88s/it] 58%|█████▊    | 358/615 [17:32<12:18,  2.87s/it]                                                  58%|█████▊    | 358/615 [17:32<12:18,  2.87s/it] 58%|█████▊    | 359/615 [17:36<12:46,  3.00s/it]                                                  58%|█████▊    | 359/615 [17:36<12:46,  3.00s/it] 59%|█████▊    | 360/615 [17:39<13:07,  3.09s/it]                                                  59%|█████▊    | 360/615 [17:39<13:07,  3.09s/it] 59%|█████▊    | 361/615 [17:42<12:59,  3.07s/it]                                                  59%|█████▊    | 361/615 [17:42<12:59,  3.07s/it] 59%|█████▉    | 362/615 [17:45<13:19,  3.16s/it]                                                  59%|█████▉    | 362/615 [17:45<13:19,  3.16s/it] 59%|█████▉    | 363/615 [17:49<13:19,  3.17s/it]                                                  59%|█████▉    | 363/615 [17:49<13:19,  3.17s/it] 59%|█████▉    | 364/615 [17:51<12:54,  3.08s/it]                                                  59%|█████▉    | 364/615 [17:51<12:54,  3.08s/it] 59%|█████▉    | 365/615 [17:55<12:54,  3.10s/it]                                                  59%|█████▉    | 365/615 [17:55<12:54,  3.10s/it] 60%|█████▉    | 366/615 [17:58<12:49,  3.09s/it]                                                  60%|█████▉    | 366/615 [17:58<12:49,  3.09s/it] 60%|█████▉    | 367/615 [18:01<12:40,  3.07s/it]                                                  60%|█████▉    | 367/615 [18:01<12:40,  3.07s/it] 60%|█████▉    | 368/615 [18:04<12:35,  3.06s/it]                                                  60%|█████▉    | 368/615 [18:04<12:35,  3.06s/it] 60%|██████    | 369/615 [18:07<12:40,  3.09s/it]                                                  60%|██████    | 369/615 [18:07<12:40,  3.09s/it] 60%|██████    | 370/615 [18:10<12:54,  3.16s/it]                                                  60%|██████    | 370/615 [18:10<12:54,  3.16s/it] 60%|██████    | 371/615 [18:13<12:54,  3.17s/it]                                                  60%|██████    | 371/615 [18:13<12:54,  3.17s/it] 60%|██████    | 372/615 [18:17<12:51,  3.18s/it]                                                  60%|██████    | 372/615 [18:17<12:51,  3.18s/it] 61%|██████    | 373/615 [18:20<12:35,  3.12s/it]                                                  61%|██████    | 373/615 [18:20<12:35,  3.12s/it] 61%|██████    | 374/615 [18:22<12:01,  2.99s/it]                                                  61%|██████    | 374/615 [18:22<12:01,  2.99s/it] 61%|██████    | 375/615 [18:25<11:43,  2.93s/it]                                                  61%|██████    | 375/615 [18:25<11:43,  2.93s/it] 61%|██████    | 376/615 [18:28<11:58,  3.00s/it]                                                  61%|██████    | 376/615 [18:28<11:58,  3.00s/it] 61%|██████▏   | 377/615 [18:31<11:30,  2.90s/it]                                                  61%|██████▏   | 377/615 [18:31<11:30,  2.90s/it] 61%|██████▏   | 378/615 [18:34<11:21,  2.87s/it]                                                  61%|██████▏   | 378/615 [18:34<11:21,  2.87s/it] 62%|██████▏   | 379/615 [18:36<11:12,  2.85s/it]                                                  62%|██████▏   | 379/615 [18:36<11:12,  2.85s/it] 62%|██████▏   | 380/615 [18:39<10:59,  2.81s/it]                                                  62%|██████▏   | 380/615 [18:39<10:59,  2.81s/it] 62%|██████▏   | 381/615 [18:42<10:56,  2.81s/it]                                                  62%|██████▏   | 381/615 [18:42<10:56,  2.81s/it] 62%|██████▏   | 382/615 [18:45<10:47,  2.78s/it]                                                  62%|██████▏   | 382/615 [18:45<10:47,  2.78s/it] 62%|██████▏   | 383/615 [18:47<10:33,  2.73s/it]                                                  62%|██████▏   | 383/615 [18:47<10:33,  2.73s/it] 62%|██████▏   | 384/615 [18:51<11:18,  2.94s/it]                                                  62%|██████▏   | 384/615 [18:51<11:18,  2.94s/it] 63%|██████▎   | 385/615 [18:54<11:05,  2.89s/it]                                                  63%|██████▎   | 385/615 [18:54<11:05,  2.89s/it] 63%|██████▎   | 386/615 [18:57<12:04,  3.16s/it]                                                  63%|██████▎   | 386/615 [18:57<12:04,  3.16s/it] 63%|██████▎   | 387/615 [19:00<11:51,  3.12s/it]                                                  63%|██████▎   | 387/615 [19:00<11:51,  3.12s/it] 63%|██████▎   | 388/615 [19:03<11:13,  2.97s/it]                                                  63%|██████▎   | 388/615 [19:03<11:13,  2.97s/it] 63%|██████▎   | 389/615 [19:06<10:50,  2.88s/it]                                                  63%|██████▎   | 389/615 [19:06<10:50,  2.88s/it] 63%|██████▎   | 390/615 [19:08<10:36,  2.83s/it]                                                  63%|██████▎   | 390/615 [19:08<10:36,  2.83s/it] 64%|██████▎   | 391/615 [19:11<10:20,  2.77s/it]                                                  64%|██████▎   | 391/615 [19:11<10:20,  2.77s/it] 64%|██████▎   | 392/615 [19:14<10:13,  2.75s/it]                                                  64%|██████▎   | 392/615 [19:14<10:13,  2.75s/it] 64%|██████▍   | 393/615 [19:16<10:02,  2.72s/it]                                                  64%|██████▍   | 393/615 [19:16<10:02,  2.72s/it] 64%|██████▍   | 394/615 [19:19<10:02,  2.72s/it]                                                  64%|██████▍   | 394/615 [19:19<10:02,  2.72s/it] 64%|██████▍   | 395/615 [19:22<10:42,  2.92s/it]                                                  64%|██████▍   | 395/615 [19:22<10:42,  2.92s/it] 64%|██████▍   | 396/615 [19:25<10:16,  2.81s/it]                                                  64%|██████▍   | 396/615 [19:25<10:16,  2.81s/it] 65%|██████▍   | 397/615 [19:28<10:02,  2.77s/it]                                                  65%|██████▍   | 397/615 [19:28<10:02,  2.77s/it] 65%|██████▍   | 398/615 [19:30<09:49,  2.72s/it]                                                  65%|██████▍   | 398/615 [19:30<09:49,  2.72s/it] 65%|██████▍   | 399/615 [19:33<09:34,  2.66s/it]                                                  65%|██████▍   | 399/615 [19:33<09:34,  2.66s/it] 65%|██████▌   | 400/615 [19:36<09:40,  2.70s/it]                                                  65%|██████▌   | 400/615 [19:36<09:40,  2.70s/it] 65%|██████▌   | 401/615 [19:38<09:31,  2.67s/it]                                                  65%|██████▌   | 401/615 [19:38<09:31,  2.67s/it] 65%|██████▌   | 402/615 [19:41<09:30,  2.68s/it]                                                  65%|██████▌   | 402/615 [19:41<09:30,  2.68s/it] 66%|██████▌   | 403/615 [19:43<09:21,  2.65s/it]                                                  66%|██████▌   | 403/615 [19:43<09:21,  2.65s/it] 66%|██████▌   | 404/615 [19:46<09:17,  2.64s/it]                                                  66%|██████▌   | 404/615 [19:46<09:17,  2.64s/it] 66%|██████▌   | 405/615 [19:49<09:12,  2.63s/it]                                                  66%|██████▌   | 405/615 [19:49<09:12,  2.63s/it] 66%|██████▌   | 406/615 [19:51<09:12,  2.64s/it]                                                  66%|██████▌   | 406/615 [19:51<09:12,  2.64s/it] 66%|██████▌   | 407/615 [19:54<08:55,  2.57s/it]                                                  66%|██████▌   | 407/615 [19:54<08:55,  2.57s/it] 66%|██████▋   | 408/615 [19:56<08:41,  2.52s/it]                                                  66%|██████▋   | 408/615 [19:56<08:41,  2.52s/it] 67%|██████▋   | 409/615 [19:58<08:06,  2.36s/it]                                                  67%|██████▋   | 409/615 [19:58<08:06,  2.36s/it] 67%|██████▋   | 410/615 [20:01<08:25,  2.47s/it]                                                  67%|██████▋   | 410/615 [20:01<08:25,  2.47s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 67%|██████▋   | 411/615 [20:34<40:08, 11.81s/it]                                                  67%|██████▋   | 411/615 [20:34<40:08, 11.81s/it] 67%|██████▋   | 412/615 [20:37<30:48,  9.11s/it]                                                  67%|██████▋   | 412/615 [20:37<30:48,  9.11s/it] 67%|██████▋   | 413/615 [20:40<24:13,  7.20s/it]                                                  67%|██████▋   | 413/615 [20:40<24:13,  7.20s/it] 67%|██████▋   | 414/615 [20:43<19:38,  5.86s/it]                                                  67%|██████▋   | 414/615 [20:43<19:38,  5.86s/it] 67%|██████▋   | 415/615 [20:46<17:01,  5.11s/it]                                                  67%|██████▋   | 415/615 [20:46<17:01,  5.11s/it] 68%|██████▊   | 416/615 [20:49<15:01,  4.53s/it]                                                  68%|██████▊   | 416/615 [20:49<15:01,  4.53s/it] 68%|██████▊   | 417/615 [20:53<13:40,  4.15s/it]                                                  68%|██████▊   | 417/615 [20:53<13:40,  4.15s/it] 68%|██████▊   | 418/615 [20:57<13:31,  4.12s/it]                                                  68%|██████▊   | 418/615 [20:57<13:31,  4.12s/it] 68%|██████▊   | 419/615 [21:01<13:16,  4.07s/it]                                                  68%|██████▊   | 419/615 [21:01<13:16,  4.07s/it] 68%|██████▊   | 420/615 [21:04<12:31,  3.86s/it]                                                  68%|██████▊   | 420/615 [21:04<12:31,  3.86s/it] 68%|██████▊   | 421/615 [21:07<11:36,  3.59s/it]                                                  68%|██████▊   | 421/615 [21:07<11:36,  3.59s/it] 69%|██████▊   | 422/615 [21:10<10:46,  3.35s/it]                                                  69%|██████▊   | 422/615 [21:10<10:46,  3.35s/it] 69%|██████▉   | 423/615 [21:12<10:14,  3.20s/it]                                                  69%|██████▉   | 423/615 [21:13<10:14,  3.20s/it] 69%|██████▉   | 424/615 [21:15<09:42,  3.05s/it]                                                  69%|██████▉   | 424/615 [21:15<09:42,  3.05s/it] 69%|██████▉   | 425/615 [21:18<09:23,  2.97s/it]                                                  69%|██████▉   | 425/615 [21:18<09:23,  2.97s/it] 69%|██████▉   | 426/615 [21:21<09:10,  2.91s/it]                                                  69%|██████▉   | 426/615 [21:21<09:10,  2.91s/it] 69%|██████▉   | 427/615 [21:24<09:08,  2.92s/it]                                                  69%|██████▉   | 427/615 [21:24<09:08,  2.92s/it] 70%|██████▉   | 428/615 [21:26<08:54,  2.86s/it]                                                  70%|██████▉   | 428/615 [21:26<08:54,  2.86s/it] 70%|██████▉   | 429/615 [21:29<08:38,  2.79s/it]                                                  70%|██████▉   | 429/615 [21:29<08:38,  2.79s/it] 70%|██████▉   | 430/615 [21:33<09:24,  3.05s/it]                                                  70%|██████▉   | 430/615 [21:33<09:24,  3.05s/it] 70%|███████   | 431/615 [21:35<09:02,  2.95s/it]                                                  70%|███████   | 431/615 [21:35<09:02,  2.95s/it] 70%|███████   | 432/615 [21:38<08:48,  2.89s/it]                                                  70%|███████   | 432/615 [21:38<08:48,  2.89s/it] 70%|███████   | 433/615 [21:41<08:34,  2.83s/it]                                                  70%|███████   | 433/615 [21:41<08:34,  2.83s/it] 71%|███████   | 434/615 [21:44<08:26,  2.80s/it]                                                  71%|███████   | 434/615 [21:44<08:26,  2.80s/it] 71%|███████   | 435/615 [21:46<08:27,  2.82s/it]                                                  71%|███████   | 435/615 [21:46<08:27,  2.82s/it] 71%|███████   | 436/615 [21:49<08:20,  2.80s/it]                                                  71%|███████   | 436/615 [21:49<08:20,  2.80s/it] 71%|███████   | 437/615 [21:52<08:44,  2.95s/it]                                                  71%|███████   | 437/615 [21:52<08:44,  2.95s/it] 71%|███████   | 438/615 [21:56<08:59,  3.05s/it]                                                  71%|███████   | 438/615 [21:56<08:59,  3.05s/it] 71%|███████▏  | 439/615 [21:59<09:03,  3.09s/it]                                                  71%|███████▏  | 439/615 [21:59<09:03,  3.09s/it] 72%|███████▏  | 440/615 [22:02<09:09,  3.14s/it]                                                  72%|███████▏  | 440/615 [22:02<09:09,  3.14s/it] 72%|███████▏  | 441/615 [22:05<09:12,  3.17s/it]                                                  72%|███████▏  | 441/615 [22:05<09:12,  3.17s/it] 72%|███████▏  | 442/615 [22:08<08:47,  3.05s/it]                                                  72%|███████▏  | 442/615 [22:08<08:47,  3.05s/it] 72%|███████▏  | 443/615 [22:11<08:27,  2.95s/it]                                                  72%|███████▏  | 443/615 [22:11<08:27,  2.95s/it] 72%|███████▏  | 444/615 [22:14<08:14,  2.89s/it]                                                  72%|███████▏  | 444/615 [22:14<08:14,  2.89s/it] 72%|███████▏  | 445/615 [22:16<08:04,  2.85s/it]                                                  72%|███████▏  | 445/615 [22:16<08:04,  2.85s/it] 73%|███████▎  | 446/615 [22:19<07:51,  2.79s/it]                                                  73%|███████▎  | 446/615 [22:19<07:51,  2.79s/it] 73%|███████▎  | 447/615 [22:22<07:57,  2.84s/it]                                                  73%|███████▎  | 447/615 [22:22<07:57,  2.84s/it] 73%|███████▎  | 448/615 [22:25<07:59,  2.87s/it]                                                  73%|███████▎  | 448/615 [22:25<07:59,  2.87s/it] 73%|███████▎  | 449/615 [22:28<07:45,  2.80s/it]                                                  73%|███████▎  | 449/615 [22:28<07:45,  2.80s/it] 73%|███████▎  | 450/615 [22:30<07:37,  2.77s/it]                                                  73%|███████▎  | 450/615 [22:30<07:37,  2.77s/it] 73%|███████▎  | 451/615 [22:33<07:31,  2.75s/it]                                                  73%|███████▎  | 451/615 [22:33<07:31,  2.75s/it] 73%|███████▎  | 452/615 [22:37<08:07,  2.99s/it]                                                  73%|███████▎  | 452/615 [22:37<08:07,  2.99s/it] 74%|███████▎  | 453/615 [22:39<07:47,  2.88s/it]                                                  74%|███████▎  | 453/615 [22:39<07:47,  2.88s/it] 74%|███████▍  | 454/615 [22:42<07:58,  2.97s/it]                                                  74%|███████▍  | 454/615 [22:42<07:58,  2.97s/it] 74%|███████▍  | 455/615 [22:46<08:06,  3.04s/it]                                                  74%|███████▍  | 455/615 [22:46<08:06,  3.04s/it] 74%|███████▍  | 456/615 [22:49<08:02,  3.04s/it]                                                  74%|███████▍  | 456/615 [22:49<08:02,  3.04s/it] 74%|███████▍  | 457/615 [22:52<07:56,  3.02s/it]                                                  74%|███████▍  | 457/615 [22:52<07:56,  3.02s/it] 74%|███████▍  | 458/615 [22:54<07:40,  2.93s/it]                                                  74%|███████▍  | 458/615 [22:54<07:40,  2.93s/it] 75%|███████▍  | 459/615 [22:58<08:21,  3.21s/it]                                                  75%|███████▍  | 459/615 [22:58<08:21,  3.21s/it] 75%|███████▍  | 460/615 [23:02<08:27,  3.28s/it]                                                  75%|███████▍  | 460/615 [23:02<08:27,  3.28s/it] 75%|███████▍  | 461/615 [23:05<08:14,  3.21s/it]                                                  75%|███████▍  | 461/615 [23:05<08:14,  3.21s/it] 75%|███████▌  | 462/615 [23:08<08:17,  3.25s/it]                                                  75%|███████▌  | 462/615 [23:08<08:17,  3.25s/it] 75%|███████▌  | 463/615 [23:11<08:15,  3.26s/it]                                                  75%|███████▌  | 463/615 [23:11<08:15,  3.26s/it] 75%|███████▌  | 464/615 [23:14<07:57,  3.16s/it]                                                  75%|███████▌  | 464/615 [23:14<07:57,  3.16s/it] 76%|███████▌  | 465/615 [23:18<08:03,  3.22s/it]                                                  76%|███████▌  | 465/615 [23:18<08:03,  3.22s/it] 76%|███████▌  | 466/615 [23:20<07:40,  3.09s/it]                                                  76%|███████▌  | 466/615 [23:20<07:40,  3.09s/it] 76%|███████▌  | 467/615 [23:23<07:25,  3.01s/it]                                                  76%|███████▌  | 467/615 [23:23<07:25,  3.01s/it] 76%|███████▌  | 468/615 [23:27<07:34,  3.10s/it]                                                  76%|███████▌  | 468/615 [23:27<07:34,  3.10s/it] 76%|███████▋  | 469/615 [23:29<07:20,  3.01s/it]                                                  76%|███████▋  | 469/615 [23:29<07:20,  3.01s/it] 76%|███████▋  | 470/615 [23:32<07:11,  2.98s/it]                                                  76%|███████▋  | 470/615 [23:32<07:11,  2.98s/it] 77%|███████▋  | 471/615 [23:35<07:00,  2.92s/it]                                                  77%|███████▋  | 471/615 [23:35<07:00,  2.92s/it] 77%|███████▋  | 472/615 [23:38<07:14,  3.04s/it]                                                  77%|███████▋  | 472/615 [23:38<07:14,  3.04s/it] 77%|███████▋  | 473/615 [23:41<07:07,  3.01s/it]                                                  77%|███████▋  | 473/615 [23:41<07:07,  3.01s/it] 77%|███████▋  | 474/615 [23:44<06:51,  2.92s/it]                                                  77%|███████▋  | 474/615 [23:44<06:51,  2.92s/it] 77%|███████▋  | 475/615 [23:47<06:45,  2.90s/it]                                                  77%|███████▋  | 475/615 [23:47<06:45,  2.90s/it] 77%|███████▋  | 476/615 [23:50<06:45,  2.92s/it]                                                  77%|███████▋  | 476/615 [23:50<06:45,  2.92s/it] 78%|███████▊  | 477/615 [23:53<06:36,  2.88s/it]                                                  78%|███████▊  | 477/615 [23:53<06:36,  2.88s/it] 78%|███████▊  | 478/615 [23:55<06:29,  2.84s/it]                                                  78%|███████▊  | 478/615 [23:55<06:29,  2.84s/it] 78%|███████▊  | 479/615 [23:58<06:18,  2.78s/it]                                                  78%|███████▊  | 479/615 [23:58<06:18,  2.78s/it] 78%|███████▊  | 480/615 [24:01<06:19,  2.81s/it]                                                  78%|███████▊  | 480/615 [24:01<06:19,  2.81s/it] 78%|███████▊  | 481/615 [24:04<06:14,  2.80s/it]                                                  78%|███████▊  | 481/615 [24:04<06:14,  2.80s/it] 78%|███████▊  | 482/615 [24:06<06:06,  2.76s/it]                                                  78%|███████▊  | 482/615 [24:06<06:06,  2.76s/it] 79%|███████▊  | 483/615 [24:09<06:01,  2.74s/it]                                                  79%|███████▊  | 483/615 [24:09<06:01,  2.74s/it] 79%|███████▊  | 484/615 [24:13<06:38,  3.04s/it]                                                  79%|███████▊  | 484/615 [24:13<06:38,  3.04s/it] 79%|███████▉  | 485/615 [24:16<06:33,  3.03s/it]                                                  79%|███████▉  | 485/615 [24:16<06:33,  3.03s/it] 79%|███████▉  | 486/615 [24:18<06:16,  2.92s/it]                                                  79%|███████▉  | 486/615 [24:18<06:16,  2.92s/it] 79%|███████▉  | 487/615 [24:21<06:07,  2.87s/it]                                                  79%|███████▉  | 487/615 [24:21<06:07,  2.87s/it] 79%|███████▉  | 488/615 [24:24<06:02,  2.85s/it]                                                  79%|███████▉  | 488/615 [24:24<06:02,  2.85s/it] 80%|███████▉  | 489/615 [24:27<06:03,  2.88s/it]                                                  80%|███████▉  | 489/615 [24:27<06:03,  2.88s/it] 80%|███████▉  | 490/615 [24:30<05:56,  2.85s/it]                                                  80%|███████▉  | 490/615 [24:30<05:56,  2.85s/it] 80%|███████▉  | 491/615 [24:32<05:47,  2.80s/it]                                                  80%|███████▉  | 491/615 [24:32<05:47,  2.80s/it] 80%|████████  | 492/615 [24:35<05:45,  2.81s/it]                                                  80%|████████  | 492/615 [24:35<05:45,  2.81s/it] 80%|████████  | 493/615 [24:38<05:41,  2.80s/it]                                                  80%|████████  | 493/615 [24:38<05:41,  2.80s/it] 80%|████████  | 494/615 [24:41<05:37,  2.79s/it]                                                  80%|████████  | 494/615 [24:41<05:37,  2.79s/it] 80%|████████  | 495/615 [24:44<05:49,  2.91s/it]                                                  80%|████████  | 495/615 [24:44<05:49,  2.91s/it] 81%|████████  | 496/615 [24:47<05:46,  2.91s/it]                                                  81%|████████  | 496/615 [24:47<05:46,  2.91s/it] 81%|████████  | 497/615 [24:50<05:33,  2.83s/it]                                                  81%|████████  | 497/615 [24:50<05:33,  2.83s/it] 81%|████████  | 498/615 [24:52<05:22,  2.76s/it]                                                  81%|████████  | 498/615 [24:52<05:22,  2.76s/it] 81%|████████  | 499/615 [24:55<05:18,  2.75s/it]                                                  81%|████████  | 499/615 [24:55<05:18,  2.75s/it] 81%|████████▏ | 500/615 [24:59<06:02,  3.15s/it]                                                  81%|████████▏ | 500/615 [24:59<06:02,  3.15s/it] 81%|████████▏ | 501/615 [25:02<05:40,  2.98s/it]                                                  81%|████████▏ | 501/615 [25:02<05:40,  2.98s/it] 82%|████████▏ | 502/615 [25:04<05:24,  2.87s/it]                                                  82%|████████▏ | 502/615 [25:04<05:24,  2.87s/it] 82%|████████▏ | 503/615 [25:07<05:14,  2.81s/it]                                                  82%|████████▏ | 503/615 [25:07<05:14,  2.81s/it] 82%|████████▏ | 504/615 [25:09<05:06,  2.76s/it]                                                  82%|████████▏ | 504/615 [25:09<05:06,  2.76s/it] 82%|████████▏ | 505/615 [25:12<05:03,  2.75s/it]                                                  82%|████████▏ | 505/615 [25:12<05:03,  2.75s/it] 82%|████████▏ | 506/615 [25:15<05:16,  2.91s/it]                                                  82%|████████▏ | 506/615 [25:15<05:16,  2.91s/it] 82%|████████▏ | 507/615 [25:18<05:05,  2.83s/it]                                                  82%|████████▏ | 507/615 [25:18<05:05,  2.83s/it] 83%|████████▎ | 508/615 [25:21<04:56,  2.77s/it]                                                  83%|████████▎ | 508/615 [25:21<04:56,  2.77s/it] 83%|████████▎ | 509/615 [25:23<04:51,  2.75s/it]                                                  83%|████████▎ | 509/615 [25:23<04:51,  2.75s/it] 83%|████████▎ | 510/615 [25:26<04:44,  2.71s/it]                                                  83%|████████▎ | 510/615 [25:26<04:44,  2.71s/it] 83%|████████▎ | 511/615 [25:29<04:39,  2.69s/it]                                                  83%|████████▎ | 511/615 [25:29<04:39,  2.69s/it] 83%|████████▎ | 512/615 [25:31<04:36,  2.69s/it]                                                  83%|████████▎ | 512/615 [25:31<04:36,  2.69s/it] 83%|████████▎ | 513/615 [25:34<04:30,  2.66s/it]                                                  83%|████████▎ | 513/615 [25:34<04:30,  2.66s/it] 84%|████████▎ | 514/615 [25:37<04:27,  2.64s/it]                                                  84%|████████▎ | 514/615 [25:37<04:27,  2.64s/it] 84%|████████▎ | 515/615 [25:39<04:24,  2.65s/it]                                                  84%|████████▎ | 515/615 [25:39<04:24,  2.65s/it] 84%|████████▍ | 516/615 [25:42<04:20,  2.64s/it]                                                  84%|████████▍ | 516/615 [25:42<04:20,  2.64s/it] 84%|████████▍ | 517/615 [25:44<04:14,  2.60s/it]                                                  84%|████████▍ | 517/615 [25:44<04:14,  2.60s/it] 84%|████████▍ | 518/615 [25:47<04:20,  2.69s/it]                                                  84%|████████▍ | 518/615 [25:47<04:20,  2.69s/it] 84%|████████▍ | 519/615 [25:50<04:26,  2.77s/it]                                                  84%|████████▍ | 519/615 [25:50<04:26,  2.77s/it] 85%|████████▍ | 520/615 [25:53<04:17,  2.72s/it]                                                  85%|████████▍ | 520/615 [25:53<04:17,  2.72s/it] 85%|████████▍ | 521/615 [25:55<04:13,  2.70s/it]                                                  85%|████████▍ | 521/615 [25:55<04:13,  2.70s/it] 85%|████████▍ | 522/615 [25:58<04:07,  2.66s/it]                                                  85%|████████▍ | 522/615 [25:58<04:07,  2.66s/it] 85%|████████▌ | 523/615 [26:01<04:09,  2.71s/it]                                                  85%|████████▌ | 523/615 [26:01<04:09,  2.71s/it] 85%|████████▌ | 524/615 [26:03<04:04,  2.69s/it]                                                  85%|████████▌ | 524/615 [26:03<04:04,  2.69s/it] 85%|████████▌ | 525/615 [26:06<04:02,  2.69s/it]                                                  85%|████████▌ | 525/615 [26:06<04:02,  2.69s/it] 86%|████████▌ | 526/615 [26:09<03:58,  2.68s/it]                                                  86%|████████▌ | 526/615 [26:09<03:58,  2.68s/it] 86%|████████▌ | 527/615 [26:11<03:52,  2.64s/it]                                                  86%|████████▌ | 527/615 [26:11<03:52,  2.64s/it] 86%|████████▌ | 528/615 [26:14<03:50,  2.65s/it]                                                  86%|████████▌ | 528/615 [26:14<03:50,  2.65s/it] 86%|████████▌ | 529/615 [26:17<03:45,  2.62s/it]                                                  86%|████████▌ | 529/615 [26:17<03:45,  2.62s/it] 86%|████████▌ | 530/615 [26:19<03:49,  2.70s/it]                                                  86%|████████▌ | 530/615 [26:19<03:49,  2.70s/it] 86%|████████▋ | 531/615 [26:23<03:59,  2.85s/it]                                                  86%|████████▋ | 531/615 [26:23<03:59,  2.85s/it] 87%|████████▋ | 532/615 [26:25<03:51,  2.79s/it]                                                  87%|████████▋ | 532/615 [26:25<03:51,  2.79s/it] 87%|████████▋ | 533/615 [26:28<03:43,  2.73s/it]                                                  87%|████████▋ | 533/615 [26:28<03:43,  2.73s/it] 87%|████████▋ | 534/615 [26:31<03:39,  2.70s/it]                                                  87%|████████▋ | 534/615 [26:31<03:39,  2.70s/it] 87%|████████▋ | 535/615 [26:33<03:35,  2.69s/it]                                                  87%|████████▋ | 535/615 [26:33<03:35,  2.69s/it] 87%|████████▋ | 536/615 [26:36<03:31,  2.68s/it]                                                  87%|████████▋ | 536/615 [26:36<03:31,  2.68s/it] 87%|████████▋ | 537/615 [26:39<03:27,  2.66s/it]                                                  87%|████████▋ | 537/615 [26:39<03:27,  2.66s/it] 87%|████████▋ | 538/615 [26:41<03:24,  2.65s/it]                                                  87%|████████▋ | 538/615 [26:41<03:24,  2.65s/it] 88%|████████▊ | 539/615 [26:44<03:20,  2.64s/it]                                                  88%|████████▊ | 539/615 [26:44<03:20,  2.64s/it] 88%|████████▊ | 540/615 [26:46<03:16,  2.62s/it]                                                  88%|████████▊ | 540/615 [26:46<03:16,  2.62s/it] 88%|████████▊ | 541/615 [26:49<03:15,  2.64s/it]                                                  88%|████████▊ | 541/615 [26:49<03:15,  2.64s/it] 88%|████████▊ | 542/615 [26:52<03:11,  2.63s/it]                                                  88%|████████▊ | 542/615 [26:52<03:11,  2.63s/it] 88%|████████▊ | 543/615 [26:56<03:38,  3.04s/it]                                                  88%|████████▊ | 543/615 [26:56<03:38,  3.04s/it] 88%|████████▊ | 544/615 [26:59<03:39,  3.09s/it]                                                  88%|████████▊ | 544/615 [26:59<03:39,  3.09s/it] 89%|████████▊ | 545/615 [27:01<03:27,  2.96s/it]                                                  89%|████████▊ | 545/615 [27:01<03:27,  2.96s/it] 89%|████████▉ | 546/615 [27:04<03:17,  2.86s/it]                                                  89%|████████▉ | 546/615 [27:04<03:17,  2.86s/it] 89%|████████▉ | 547/615 [27:07<03:10,  2.79s/it]                                                  89%|████████▉ | 547/615 [27:07<03:10,  2.79s/it] 89%|████████▉ | 548/615 [27:09<03:04,  2.75s/it]                                                  89%|████████▉ | 548/615 [27:09<03:04,  2.75s/it] 89%|████████▉ | 549/615 [27:12<03:00,  2.73s/it]                                                  89%|████████▉ | 549/615 [27:12<03:00,  2.73s/it] 89%|████████▉ | 550/615 [27:15<02:56,  2.71s/it]                                                  89%|████████▉ | 550/615 [27:15<02:56,  2.71s/it] 90%|████████▉ | 551/615 [27:17<02:52,  2.70s/it]                                                  90%|████████▉ | 551/615 [27:17<02:52,  2.70s/it] 90%|████████▉ | 552/615 [27:20<02:51,  2.73s/it]                                                  90%|████████▉ | 552/615 [27:20<02:51,  2.73s/it] 90%|████████▉ | 553/615 [27:23<02:46,  2.69s/it]                                                  90%|████████▉ | 553/615 [27:23<02:46,  2.69s/it] 90%|█████████ | 554/615 [27:26<02:55,  2.88s/it]                                                  90%|█████████ | 554/615 [27:26<02:55,  2.88s/it] 90%|█████████ | 555/615 [27:29<02:47,  2.79s/it]                                                  90%|█████████ | 555/615 [27:29<02:47,  2.79s/it] 90%|█████████ | 556/615 [27:31<02:41,  2.74s/it]                                                  90%|█████████ | 556/615 [27:31<02:41,  2.74s/it] 91%|█████████ | 557/615 [27:34<02:38,  2.73s/it]                                                  91%|█████████ | 557/615 [27:34<02:38,  2.73s/it] 91%|█████████ | 558/615 [27:37<02:33,  2.70s/it]                                                  91%|█████████ | 558/615 [27:37<02:33,  2.70s/it] 91%|█████████ | 559/615 [27:39<02:28,  2.66s/it]                                                  91%|█████████ | 559/615 [27:39<02:28,  2.66s/it] 91%|█████████ | 560/615 [27:42<02:24,  2.62s/it]                                                  91%|█████████ | 560/615 [27:42<02:24,  2.62s/it] 91%|█████████ | 561/615 [27:44<02:20,  2.60s/it]                                                  91%|█████████ | 561/615 [27:44<02:20,  2.60s/it] 91%|█████████▏| 562/615 [27:47<02:18,  2.61s/it]                                                  91%|█████████▏| 562/615 [27:47<02:18,  2.61s/it] 92%|█████████▏| 563/615 [27:50<02:16,  2.62s/it]                                                  92%|█████████▏| 563/615 [27:50<02:16,  2.62s/it] 92%|█████████▏| 564/615 [27:52<02:14,  2.63s/it]                                                  92%|█████████▏| 564/615 [27:52<02:14,  2.63s/it] 92%|█████████▏| 565/615 [27:55<02:10,  2.60s/it]                                                  92%|█████████▏| 565/615 [27:55<02:10,  2.60s/it] 92%|█████████▏| 566/615 [27:58<02:15,  2.77s/it]                                                  92%|█████████▏| 566/615 [27:58<02:15,  2.77s/it] 92%|█████████▏| 567/615 [28:01<02:15,  2.82s/it]                                                  92%|█████████▏| 567/615 [28:01<02:15,  2.82s/it] 92%|█████████▏| 568/615 [28:04<02:11,  2.80s/it]                                                  92%|█████████▏| 568/615 [28:04<02:11,  2.80s/it] 93%|█████████▎| 569/615 [28:06<02:06,  2.75s/it]                                                  93%|█████████▎| 569/615 [28:06<02:06,  2.75s/it] 93%|█████████▎| 570/615 [28:09<02:02,  2.73s/it]                                                  93%|█████████▎| 570/615 [28:09<02:02,  2.73s/it] 93%|█████████▎| 571/615 [28:12<01:58,  2.69s/it]                                                  93%|█████████▎| 571/615 [28:12<01:58,  2.69s/it] 93%|█████████▎| 572/615 [28:14<01:55,  2.69s/it]                                                  93%|█████████▎| 572/615 [28:14<01:55,  2.69s/it] 93%|█████████▎| 573/615 [28:17<01:53,  2.70s/it]                                                  93%|█████████▎| 573/615 [28:17<01:53,  2.70s/it] 93%|█████████▎| 574/615 [28:20<01:50,  2.70s/it]                                                  93%|█████████▎| 574/615 [28:20<01:50,  2.70s/it] 93%|█████████▎| 575/615 [28:22<01:46,  2.67s/it]                                                  93%|█████████▎| 575/615 [28:22<01:46,  2.67s/it] 94%|█████████▎| 576/615 [28:25<01:44,  2.68s/it]                                                  94%|█████████▎| 576/615 [28:25<01:44,  2.68s/it] 94%|█████████▍| 577/615 [28:28<01:41,  2.67s/it]                                                  94%|█████████▍| 577/615 [28:28<01:41,  2.67s/it] 94%|█████████▍| 578/615 [28:31<01:45,  2.86s/it]                                                  94%|█████████▍| 578/615 [28:31<01:45,  2.86s/it] 94%|█████████▍| 579/615 [28:34<01:41,  2.81s/it]                                                  94%|█████████▍| 579/615 [28:34<01:41,  2.81s/it] 94%|█████████▍| 580/615 [28:36<01:37,  2.78s/it]                                                  94%|█████████▍| 580/615 [28:36<01:37,  2.78s/it] 94%|█████████▍| 581/615 [28:39<01:32,  2.74s/it]                                                  94%|█████████▍| 581/615 [28:39<01:32,  2.74s/it] 95%|█████████▍| 582/615 [28:42<01:29,  2.72s/it]                                                  95%|█████████▍| 582/615 [28:42<01:29,  2.72s/it] 95%|█████████▍| 583/615 [28:44<01:25,  2.68s/it]                                                  95%|█████████▍| 583/615 [28:44<01:25,  2.68s/it] 95%|█████████▍| 584/615 [28:47<01:23,  2.69s/it]                                                  95%|█████████▍| 584/615 [28:47<01:23,  2.69s/it] 95%|█████████▌| 585/615 [28:50<01:20,  2.69s/it]                                                  95%|█████████▌| 585/615 [28:50<01:20,  2.69s/it] 95%|█████████▌| 586/615 [28:52<01:18,  2.70s/it]                                                  95%|█████████▌| 586/615 [28:52<01:18,  2.70s/it] 95%|█████████▌| 587/615 [28:55<01:17,  2.78s/it]                                                  95%|█████████▌| 587/615 [28:55<01:17,  2.78s/it] 96%|█████████▌| 588/615 [28:59<01:22,  3.06s/it]                                                  96%|█████████▌| 588/615 [28:59<01:22,  3.06s/it] 96%|█████████▌| 589/615 [29:02<01:19,  3.07s/it]                                                  96%|█████████▌| 589/615 [29:02<01:19,  3.07s/it] 96%|█████████▌| 590/615 [29:05<01:15,  3.01s/it]                                                  96%|█████████▌| 590/615 [29:05<01:15,  3.01s/it] 96%|█████████▌| 591/615 [29:08<01:10,  2.93s/it]                                                  96%|█████████▌| 591/615 [29:08<01:10,  2.93s/it] 96%|█████████▋| 592/615 [29:10<01:04,  2.80s/it]                                                  96%|█████████▋| 592/615 [29:10<01:04,  2.80s/it] 96%|█████████▋| 593/615 [29:13<01:00,  2.73s/it]                                                  96%|█████████▋| 593/615 [29:13<01:00,  2.73s/it] 97%|█████████▋| 594/615 [29:15<00:56,  2.68s/it]                                                  97%|█████████▋| 594/615 [29:15<00:56,  2.68s/it] 97%|█████████▋| 595/615 [29:18<00:53,  2.68s/it]                                                  97%|█████████▋| 595/615 [29:18<00:53,  2.68s/it] 97%|█████████▋| 596/615 [29:21<00:50,  2.67s/it]                                                  97%|█████████▋| 596/615 [29:21<00:50,  2.67s/it] 97%|█████████▋| 597/615 [29:23<00:47,  2.66s/it]                                                  97%|█████████▋| 597/615 [29:23<00:47,  2.66s/it] 97%|█████████▋| 598/615 [29:26<00:44,  2.64s/it]                                                  97%|█████████▋| 598/615 [29:26<00:44,  2.64s/it] 97%|█████████▋| 599/615 [29:28<00:41,  2.61s/it]                                                  97%|█████████▋| 599/615 [29:28<00:41,  2.61s/it] 98%|█████████▊| 600/615 [29:31<00:39,  2.63s/it]                                                  98%|█████████▊| 600/615 [29:31<00:39,  2.63s/it] 98%|█████████▊| 601/615 [29:34<00:36,  2.63s/it]                                                  98%|█████████▊| 601/615 [29:34<00:36,  2.63s/it] 98%|█████████▊| 602/615 [29:37<00:36,  2.82s/it]                                                  98%|█████████▊| 602/615 [29:37<00:36,  2.82s/it] 98%|█████████▊| 603/615 [29:40<00:33,  2.77s/it]                                                  98%|█████████▊| 603/615 [29:40<00:33,  2.77s/it] 98%|█████████▊| 604/615 [29:42<00:29,  2.71s/it]                                                  98%|█████████▊| 604/615 [29:42<00:29,  2.71s/it] 98%|█████████▊| 605/615 [29:45<00:26,  2.69s/it]                                                  98%|█████████▊| 605/615 [29:45<00:26,  2.69s/it] 99%|█████████▊| 606/615 [29:48<00:23,  2.66s/it]                                                  99%|█████████▊| 606/615 [29:48<00:23,  2.66s/it] 99%|█████████▊| 607/615 [29:50<00:21,  2.68s/it]                                                  99%|█████████▊| 607/615 [29:50<00:21,  2.68s/it] 99%|█████████▉| 608/615 [29:53<00:18,  2.63s/it]                                                  99%|█████████▉| 608/615 [29:53<00:18,  2.63s/it] 99%|█████████▉| 609/615 [29:55<00:15,  2.62s/it]                                                  99%|█████████▉| 609/615 [29:55<00:15,  2.62s/it] 99%|█████████▉| 610/615 [29:58<00:12,  2.60s/it]                                                  99%|█████████▉| 610/615 [29:58<00:12,  2.60s/it] 99%|█████████▉| 611/615 [30:00<00:10,  2.58s/it]                                                  99%|█████████▉| 611/615 [30:00<00:10,  2.58s/it]100%|█████████▉| 612/615 [30:02<00:07,  2.43s/it]                                                 100%|█████████▉| 612/615 [30:02<00:07,  2.43s/it]100%|█████████▉| 613/615 [30:04<00:04,  2.30s/it]                                                 100%|█████████▉| 613/615 [30:04<00:04,  2.30s/it]100%|█████████▉| 614/615 [30:07<00:02,  2.30s/it]                                                 100%|█████████▉| 614/615 [30:07<00:02,  2.30s/it]100%|██████████| 615/615 [30:10<00:00,  2.51s/it]                                                 100%|██████████| 615/615 [30:10<00:00,  2.51s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
                                                 100%|██████████| 615/615 [30:35<00:00,  2.51s/it]100%|██████████| 615/615 [30:35<00:00,  2.99s/it]
wandb: - 0.016 MB of 0.016 MB uploadedwandb: \ 0.016 MB of 0.016 MB uploadedwandb: | 0.016 MB of 0.074 MB uploadedwandb: / 0.077 MB of 0.077 MB uploadedwandb: - 0.077 MB of 0.077 MB uploadedwandb: 
wandb: Run history:
wandb:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train/learning_rate ▄▇██████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:                     train/loss ▄▃▄▆▃▂▅█▃▃▂▁▄▅▃██▄▄▅▃▅▃▆▁▂▄▅▇▁▅█▄▅▂▃▆▇▃▇
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                    train/epoch 3.0
wandb:              train/global_step 615
wandb:            train/learning_rate 0.0
wandb:                     train/loss 3.4506
wandb:               train/total_flos 9984186206126080.0
wandb:               train/train_loss 3.37869
wandb:            train/train_runtime 1843.524
wandb: train/train_samples_per_second 16.005
wandb:   train/train_steps_per_second 0.334
wandb: 
wandb: 🚀 View run tiny-llava-base-pretrain-scratch/ltl2113/LLaVA-Med/TinyLLaVABench_1/checkpoints/tiny-llava-KD-pretrain/checkpoint-6594-siglip-so400m-patch14-384 at: https://wandb.ai/llavamed/huggingface/runs/d1cxdv5d
wandb: ️⚡ View job at https://wandb.ai/llavamed/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1MjEyNzg1Ng==/version_details/v3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240327_132039-d1cxdv5d/logs
