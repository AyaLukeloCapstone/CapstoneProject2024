Unloading module 'code-server/4.9.1'
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:25<00:25, 25.51s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:25<00:25, 25.28s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:25<00:25, 25.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 11.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.44s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_SG2/checkpoint-2196 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 11.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:26<00:00, 13.46s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_SG2/checkpoint-2196 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 11.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.64s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_SG2/checkpoint-2196 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
wandb: Currently logged in as: ltl2113 (llavamed). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/wandb/run-20240331_141614-ao6phsem
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tiny-llava-base-pretrain-scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_SG2/checkpoint-2196-siglip-so400m-patch14-384
wandb: ⭐️ View project at https://wandb.ai/llavamed/huggingface
wandb: 🚀 View run at https://wandb.ai/llavamed/huggingface/runs/ao6phsem
  0%|          | 0/615 [00:00<?, ?it/s]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/615 [00:13<2:19:29, 13.63s/it]                                                   0%|          | 1/615 [00:13<2:19:29, 13.63s/it]  0%|          | 2/615 [00:17<1:18:11,  7.65s/it]                                                   0%|          | 2/615 [00:17<1:18:11,  7.65s/it]  0%|          | 3/615 [00:20<57:54,  5.68s/it]                                                   0%|          | 3/615 [00:20<57:54,  5.68s/it]  1%|          | 4/615 [00:23<47:29,  4.66s/it]                                                 1%|          | 4/615 [00:23<47:29,  4.66s/it]  1%|          | 5/615 [00:26<41:40,  4.10s/it]                                                 1%|          | 5/615 [00:26<41:40,  4.10s/it]  1%|          | 6/615 [00:29<38:43,  3.81s/it]                                                 1%|          | 6/615 [00:29<38:43,  3.81s/it]  1%|          | 7/615 [00:32<35:26,  3.50s/it]                                                 1%|          | 7/615 [00:32<35:26,  3.50s/it]  1%|▏         | 8/615 [00:35<33:19,  3.29s/it]                                                 1%|▏         | 8/615 [00:35<33:19,  3.29s/it]  1%|▏         | 9/615 [00:38<32:06,  3.18s/it]                                                 1%|▏         | 9/615 [00:38<32:06,  3.18s/it]  2%|▏         | 10/615 [00:41<32:34,  3.23s/it]                                                  2%|▏         | 10/615 [00:41<32:34,  3.23s/it]  2%|▏         | 11/615 [00:44<30:57,  3.08s/it]                                                  2%|▏         | 11/615 [00:44<30:57,  3.08s/it]  2%|▏         | 12/615 [00:48<31:56,  3.18s/it]                                                  2%|▏         | 12/615 [00:48<31:56,  3.18s/it]  2%|▏         | 13/615 [00:50<31:03,  3.09s/it]                                                  2%|▏         | 13/615 [00:50<31:03,  3.09s/it]  2%|▏         | 14/615 [00:53<29:56,  2.99s/it]                                                  2%|▏         | 14/615 [00:53<29:56,  2.99s/it]  2%|▏         | 15/615 [00:56<28:41,  2.87s/it]                                                  2%|▏         | 15/615 [00:56<28:41,  2.87s/it]  3%|▎         | 16/615 [00:59<29:38,  2.97s/it]                                                  3%|▎         | 16/615 [00:59<29:38,  2.97s/it]  3%|▎         | 17/615 [01:02<28:52,  2.90s/it]                                                  3%|▎         | 17/615 [01:02<28:52,  2.90s/it]  3%|▎         | 18/615 [01:04<28:27,  2.86s/it]                                                  3%|▎         | 18/615 [01:04<28:27,  2.86s/it]  3%|▎         | 19/615 [01:07<27:32,  2.77s/it]                                                  3%|▎         | 19/615 [01:07<27:32,  2.77s/it]  3%|▎         | 20/615 [01:10<27:21,  2.76s/it]                                                  3%|▎         | 20/615 [01:10<27:21,  2.76s/it]  3%|▎         | 21/615 [01:12<26:53,  2.72s/it]                                                  3%|▎         | 21/615 [01:12<26:53,  2.72s/it]  4%|▎         | 22/615 [01:15<26:37,  2.69s/it]                                                  4%|▎         | 22/615 [01:15<26:37,  2.69s/it]  4%|▎         | 23/615 [01:18<26:27,  2.68s/it]                                                  4%|▎         | 23/615 [01:18<26:27,  2.68s/it]  4%|▍         | 24/615 [01:20<26:11,  2.66s/it]                                                  4%|▍         | 24/615 [01:20<26:11,  2.66s/it]  4%|▍         | 25/615 [01:23<25:48,  2.63s/it]                                                  4%|▍         | 25/615 [01:23<25:48,  2.63s/it]  4%|▍         | 26/615 [01:26<27:01,  2.75s/it]                                                  4%|▍         | 26/615 [01:26<27:01,  2.75s/it]  4%|▍         | 27/615 [01:28<26:34,  2.71s/it]                                                  4%|▍         | 27/615 [01:28<26:34,  2.71s/it]  5%|▍         | 28/615 [01:32<27:30,  2.81s/it]                                                  5%|▍         | 28/615 [01:32<27:30,  2.81s/it]  5%|▍         | 29/615 [01:34<27:22,  2.80s/it]                                                  5%|▍         | 29/615 [01:34<27:22,  2.80s/it]  5%|▍         | 30/615 [01:37<26:32,  2.72s/it]                                                  5%|▍         | 30/615 [01:37<26:32,  2.72s/it]  5%|▌         | 31/615 [01:39<26:02,  2.68s/it]                                                  5%|▌         | 31/615 [01:39<26:02,  2.68s/it]  5%|▌         | 32/615 [01:42<26:02,  2.68s/it]                                                  5%|▌         | 32/615 [01:42<26:02,  2.68s/it]  5%|▌         | 33/615 [01:45<25:38,  2.64s/it]                                                  5%|▌         | 33/615 [01:45<25:38,  2.64s/it]  6%|▌         | 34/615 [01:47<25:44,  2.66s/it]                                                  6%|▌         | 34/615 [01:47<25:44,  2.66s/it]  6%|▌         | 35/615 [01:50<25:20,  2.62s/it]                                                  6%|▌         | 35/615 [01:50<25:20,  2.62s/it]  6%|▌         | 36/615 [01:52<25:12,  2.61s/it]                                                  6%|▌         | 36/615 [01:53<25:12,  2.61s/it]  6%|▌         | 37/615 [01:55<25:22,  2.63s/it]                                                  6%|▌         | 37/615 [01:55<25:22,  2.63s/it]  6%|▌         | 38/615 [01:58<25:28,  2.65s/it]                                                  6%|▌         | 38/615 [01:58<25:28,  2.65s/it]  6%|▋         | 39/615 [02:01<25:28,  2.65s/it]                                                  6%|▋         | 39/615 [02:01<25:28,  2.65s/it]  7%|▋         | 40/615 [02:03<26:12,  2.74s/it]                                                  7%|▋         | 40/615 [02:03<26:12,  2.74s/it]  7%|▋         | 41/615 [02:06<26:57,  2.82s/it]                                                  7%|▋         | 41/615 [02:06<26:57,  2.82s/it]  7%|▋         | 42/615 [02:09<26:10,  2.74s/it]                                                  7%|▋         | 42/615 [02:09<26:10,  2.74s/it]  7%|▋         | 43/615 [02:12<25:31,  2.68s/it]                                                  7%|▋         | 43/615 [02:12<25:31,  2.68s/it]  7%|▋         | 44/615 [02:14<25:08,  2.64s/it]                                                  7%|▋         | 44/615 [02:14<25:08,  2.64s/it]  7%|▋         | 45/615 [02:17<25:05,  2.64s/it]                                                  7%|▋         | 45/615 [02:17<25:05,  2.64s/it]  7%|▋         | 46/615 [02:19<25:03,  2.64s/it]                                                  7%|▋         | 46/615 [02:19<25:03,  2.64s/it]  8%|▊         | 47/615 [02:22<24:48,  2.62s/it]                                                  8%|▊         | 47/615 [02:22<24:48,  2.62s/it]  8%|▊         | 48/615 [02:24<24:29,  2.59s/it]                                                  8%|▊         | 48/615 [02:24<24:29,  2.59s/it]  8%|▊         | 49/615 [02:27<24:48,  2.63s/it]                                                  8%|▊         | 49/615 [02:27<24:48,  2.63s/it]  8%|▊         | 50/615 [02:30<24:35,  2.61s/it]                                                  8%|▊         | 50/615 [02:30<24:35,  2.61s/it]  8%|▊         | 51/615 [02:32<24:29,  2.61s/it]                                                  8%|▊         | 51/615 [02:32<24:29,  2.61s/it]  8%|▊         | 52/615 [02:35<24:14,  2.58s/it]                                                  8%|▊         | 52/615 [02:35<24:14,  2.58s/it]  9%|▊         | 53/615 [02:38<26:12,  2.80s/it]                                                  9%|▊         | 53/615 [02:38<26:12,  2.80s/it]  9%|▉         | 54/615 [02:41<25:36,  2.74s/it]                                                  9%|▉         | 54/615 [02:41<25:36,  2.74s/it]  9%|▉         | 55/615 [02:44<25:31,  2.73s/it]                                                  9%|▉         | 55/615 [02:44<25:31,  2.73s/it]  9%|▉         | 56/615 [02:46<25:26,  2.73s/it]                                                  9%|▉         | 56/615 [02:46<25:26,  2.73s/it]  9%|▉         | 57/615 [02:50<28:19,  3.05s/it]                                                  9%|▉         | 57/615 [02:50<28:19,  3.05s/it]  9%|▉         | 58/615 [02:53<27:17,  2.94s/it]                                                  9%|▉         | 58/615 [02:53<27:17,  2.94s/it] 10%|▉         | 59/615 [02:55<26:34,  2.87s/it]                                                 10%|▉         | 59/615 [02:55<26:34,  2.87s/it] 10%|▉         | 60/615 [02:58<25:44,  2.78s/it]                                                 10%|▉         | 60/615 [02:58<25:44,  2.78s/it] 10%|▉         | 61/615 [03:01<25:10,  2.73s/it]                                                 10%|▉         | 61/615 [03:01<25:10,  2.73s/it] 10%|█         | 62/615 [03:03<24:34,  2.67s/it]                                                 10%|█         | 62/615 [03:03<24:34,  2.67s/it] 10%|█         | 63/615 [03:06<24:14,  2.63s/it]                                                 10%|█         | 63/615 [03:06<24:14,  2.63s/it] 10%|█         | 64/615 [03:09<25:12,  2.75s/it]                                                 10%|█         | 64/615 [03:09<25:12,  2.75s/it] 11%|█         | 65/615 [03:12<25:39,  2.80s/it]                                                 11%|█         | 65/615 [03:12<25:39,  2.80s/it] 11%|█         | 66/615 [03:14<25:00,  2.73s/it]                                                 11%|█         | 66/615 [03:14<25:00,  2.73s/it] 11%|█         | 67/615 [03:17<24:36,  2.69s/it]                                                 11%|█         | 67/615 [03:17<24:36,  2.69s/it] 11%|█         | 68/615 [03:19<24:29,  2.69s/it]                                                 11%|█         | 68/615 [03:19<24:29,  2.69s/it] 11%|█         | 69/615 [03:22<24:18,  2.67s/it]                                                 11%|█         | 69/615 [03:22<24:18,  2.67s/it] 11%|█▏        | 70/615 [03:25<24:08,  2.66s/it]                                                 11%|█▏        | 70/615 [03:25<24:08,  2.66s/it] 12%|█▏        | 71/615 [03:27<23:55,  2.64s/it]                                                 12%|█▏        | 71/615 [03:27<23:55,  2.64s/it] 12%|█▏        | 72/615 [03:30<23:51,  2.64s/it]                                                 12%|█▏        | 72/615 [03:30<23:51,  2.64s/it] 12%|█▏        | 73/615 [03:33<23:52,  2.64s/it]                                                 12%|█▏        | 73/615 [03:33<23:52,  2.64s/it] 12%|█▏        | 74/615 [03:35<23:34,  2.61s/it]                                                 12%|█▏        | 74/615 [03:35<23:34,  2.61s/it] 12%|█▏        | 75/615 [03:38<23:26,  2.60s/it]                                                 12%|█▏        | 75/615 [03:38<23:26,  2.60s/it] 12%|█▏        | 76/615 [03:40<23:01,  2.56s/it]                                                 12%|█▏        | 76/615 [03:40<23:01,  2.56s/it] 13%|█▎        | 77/615 [03:44<25:11,  2.81s/it]                                                 13%|█▎        | 77/615 [03:44<25:11,  2.81s/it] 13%|█▎        | 78/615 [03:46<24:30,  2.74s/it]                                                 13%|█▎        | 78/615 [03:46<24:30,  2.74s/it] 13%|█▎        | 79/615 [03:49<24:13,  2.71s/it]                                                 13%|█▎        | 79/615 [03:49<24:13,  2.71s/it] 13%|█▎        | 80/615 [03:51<23:46,  2.67s/it]                                                 13%|█▎        | 80/615 [03:51<23:46,  2.67s/it] 13%|█▎        | 81/615 [03:54<23:25,  2.63s/it]                                                 13%|█▎        | 81/615 [03:54<23:25,  2.63s/it] 13%|█▎        | 82/615 [03:57<23:28,  2.64s/it]                                                 13%|█▎        | 82/615 [03:57<23:28,  2.64s/it] 13%|█▎        | 83/615 [03:59<23:07,  2.61s/it]                                                 13%|█▎        | 83/615 [03:59<23:07,  2.61s/it] 14%|█▎        | 84/615 [04:02<23:02,  2.60s/it]                                                 14%|█▎        | 84/615 [04:02<23:02,  2.60s/it] 14%|█▍        | 85/615 [04:04<23:12,  2.63s/it]                                                 14%|█▍        | 85/615 [04:04<23:12,  2.63s/it] 14%|█▍        | 86/615 [04:07<23:01,  2.61s/it]                                                 14%|█▍        | 86/615 [04:07<23:01,  2.61s/it] 14%|█▍        | 87/615 [04:10<22:51,  2.60s/it]                                                 14%|█▍        | 87/615 [04:10<22:51,  2.60s/it] 14%|█▍        | 88/615 [04:12<22:34,  2.57s/it]                                                 14%|█▍        | 88/615 [04:12<22:34,  2.57s/it] 14%|█▍        | 89/615 [04:15<24:32,  2.80s/it]                                                 14%|█▍        | 89/615 [04:15<24:32,  2.80s/it] 15%|█▍        | 90/615 [04:19<26:06,  2.98s/it]                                                 15%|█▍        | 90/615 [04:19<26:06,  2.98s/it] 15%|█▍        | 91/615 [04:22<26:08,  2.99s/it]                                                 15%|█▍        | 91/615 [04:22<26:08,  2.99s/it] 15%|█▍        | 92/615 [04:25<26:15,  3.01s/it]                                                 15%|█▍        | 92/615 [04:25<26:15,  3.01s/it] 15%|█▌        | 93/615 [04:28<25:24,  2.92s/it]                                                 15%|█▌        | 93/615 [04:28<25:24,  2.92s/it] 15%|█▌        | 94/615 [04:31<25:58,  2.99s/it]                                                 15%|█▌        | 94/615 [04:31<25:58,  2.99s/it] 15%|█▌        | 95/615 [04:34<26:56,  3.11s/it]                                                 15%|█▌        | 95/615 [04:34<26:56,  3.11s/it] 16%|█▌        | 96/615 [04:37<26:22,  3.05s/it]                                                 16%|█▌        | 96/615 [04:37<26:22,  3.05s/it] 16%|█▌        | 97/615 [04:40<25:22,  2.94s/it]                                                 16%|█▌        | 97/615 [04:40<25:22,  2.94s/it] 16%|█▌        | 98/615 [04:42<24:50,  2.88s/it]                                                 16%|█▌        | 98/615 [04:42<24:50,  2.88s/it] 16%|█▌        | 99/615 [04:45<24:46,  2.88s/it]                                                 16%|█▌        | 99/615 [04:45<24:46,  2.88s/it] 16%|█▋        | 100/615 [04:49<27:11,  3.17s/it]                                                  16%|█▋        | 100/615 [04:49<27:11,  3.17s/it] 16%|█▋        | 101/615 [04:52<27:12,  3.18s/it]                                                  16%|█▋        | 101/615 [04:52<27:12,  3.18s/it] 17%|█▋        | 102/615 [04:55<26:44,  3.13s/it]                                                  17%|█▋        | 102/615 [04:55<26:44,  3.13s/it] 17%|█▋        | 103/615 [04:59<26:53,  3.15s/it]                                                  17%|█▋        | 103/615 [04:59<26:53,  3.15s/it] 17%|█▋        | 104/615 [05:01<25:28,  2.99s/it]                                                  17%|█▋        | 104/615 [05:01<25:28,  2.99s/it] 17%|█▋        | 105/615 [05:04<25:26,  2.99s/it]                                                  17%|█▋        | 105/615 [05:04<25:26,  2.99s/it] 17%|█▋        | 106/615 [05:07<25:12,  2.97s/it]                                                  17%|█▋        | 106/615 [05:07<25:12,  2.97s/it] 17%|█▋        | 107/615 [05:10<24:24,  2.88s/it]                                                  17%|█▋        | 107/615 [05:10<24:24,  2.88s/it] 18%|█▊        | 108/615 [05:12<23:49,  2.82s/it]                                                  18%|█▊        | 108/615 [05:12<23:49,  2.82s/it] 18%|█▊        | 109/615 [05:15<23:46,  2.82s/it]                                                  18%|█▊        | 109/615 [05:15<23:46,  2.82s/it] 18%|█▊        | 110/615 [05:18<24:15,  2.88s/it]                                                  18%|█▊        | 110/615 [05:18<24:15,  2.88s/it] 18%|█▊        | 111/615 [05:21<23:56,  2.85s/it]                                                  18%|█▊        | 111/615 [05:21<23:56,  2.85s/it] 18%|█▊        | 112/615 [05:24<23:12,  2.77s/it]                                                  18%|█▊        | 112/615 [05:24<23:12,  2.77s/it] 18%|█▊        | 113/615 [05:26<23:03,  2.76s/it]                                                  18%|█▊        | 113/615 [05:26<23:03,  2.76s/it] 19%|█▊        | 114/615 [05:29<22:40,  2.72s/it]                                                  19%|█▊        | 114/615 [05:29<22:40,  2.72s/it] 19%|█▊        | 115/615 [05:32<22:24,  2.69s/it]                                                  19%|█▊        | 115/615 [05:32<22:24,  2.69s/it] 19%|█▉        | 116/615 [05:34<22:42,  2.73s/it]                                                  19%|█▉        | 116/615 [05:34<22:42,  2.73s/it] 19%|█▉        | 117/615 [05:38<23:54,  2.88s/it]                                                  19%|█▉        | 117/615 [05:38<23:54,  2.88s/it] 19%|█▉        | 118/615 [05:40<23:18,  2.81s/it]                                                  19%|█▉        | 118/615 [05:40<23:18,  2.81s/it] 19%|█▉        | 119/615 [05:43<23:08,  2.80s/it]                                                  19%|█▉        | 119/615 [05:43<23:08,  2.80s/it] 20%|█▉        | 120/615 [05:46<22:33,  2.73s/it]                                                  20%|█▉        | 120/615 [05:46<22:33,  2.73s/it] 20%|█▉        | 121/615 [05:48<22:31,  2.74s/it]                                                  20%|█▉        | 121/615 [05:48<22:31,  2.74s/it] 20%|█▉        | 122/615 [05:52<23:30,  2.86s/it]                                                  20%|█▉        | 122/615 [05:52<23:30,  2.86s/it] 20%|██        | 123/615 [05:54<22:53,  2.79s/it]                                                  20%|██        | 123/615 [05:54<22:53,  2.79s/it] 20%|██        | 124/615 [05:57<22:31,  2.75s/it]                                                  20%|██        | 124/615 [05:57<22:31,  2.75s/it] 20%|██        | 125/615 [06:00<22:14,  2.72s/it]                                                  20%|██        | 125/615 [06:00<22:14,  2.72s/it] 20%|██        | 126/615 [06:02<22:06,  2.71s/it]                                                  20%|██        | 126/615 [06:02<22:06,  2.71s/it] 21%|██        | 127/615 [06:05<21:47,  2.68s/it]                                                  21%|██        | 127/615 [06:05<21:47,  2.68s/it] 21%|██        | 128/615 [06:08<21:55,  2.70s/it]                                                  21%|██        | 128/615 [06:08<21:55,  2.70s/it] 21%|██        | 129/615 [06:10<21:36,  2.67s/it]                                                  21%|██        | 129/615 [06:10<21:36,  2.67s/it] 21%|██        | 130/615 [06:13<21:37,  2.68s/it]                                                  21%|██        | 130/615 [06:13<21:37,  2.68s/it] 21%|██▏       | 131/615 [06:15<21:23,  2.65s/it]                                                  21%|██▏       | 131/615 [06:15<21:23,  2.65s/it] 21%|██▏       | 132/615 [06:18<21:27,  2.67s/it]                                                  21%|██▏       | 132/615 [06:18<21:27,  2.67s/it] 22%|██▏       | 133/615 [06:21<21:14,  2.64s/it]                                                  22%|██▏       | 133/615 [06:21<21:14,  2.64s/it] 22%|██▏       | 134/615 [06:24<22:31,  2.81s/it]                                                  22%|██▏       | 134/615 [06:24<22:31,  2.81s/it] 22%|██▏       | 135/615 [06:27<22:06,  2.76s/it]                                                  22%|██▏       | 135/615 [06:27<22:06,  2.76s/it] 22%|██▏       | 136/615 [06:29<21:27,  2.69s/it]                                                  22%|██▏       | 136/615 [06:29<21:27,  2.69s/it] 22%|██▏       | 137/615 [06:32<22:21,  2.81s/it]                                                  22%|██▏       | 137/615 [06:32<22:21,  2.81s/it] 22%|██▏       | 138/615 [06:36<24:06,  3.03s/it]                                                  22%|██▏       | 138/615 [06:36<24:06,  3.03s/it] 23%|██▎       | 139/615 [06:39<24:22,  3.07s/it]                                                  23%|██▎       | 139/615 [06:39<24:22,  3.07s/it] 23%|██▎       | 140/615 [06:42<25:01,  3.16s/it]                                                  23%|██▎       | 140/615 [06:42<25:01,  3.16s/it] 23%|██▎       | 141/615 [06:46<25:58,  3.29s/it]                                                  23%|██▎       | 141/615 [06:46<25:58,  3.29s/it] 23%|██▎       | 142/615 [06:50<26:59,  3.42s/it]                                                  23%|██▎       | 142/615 [06:50<26:59,  3.42s/it] 23%|██▎       | 143/615 [06:53<26:53,  3.42s/it]                                                  23%|██▎       | 143/615 [06:53<26:53,  3.42s/it] 23%|██▎       | 144/615 [06:56<26:23,  3.36s/it]                                                  23%|██▎       | 144/615 [06:56<26:23,  3.36s/it] 24%|██▎       | 145/615 [06:59<24:37,  3.14s/it]                                                  24%|██▎       | 145/615 [06:59<24:37,  3.14s/it] 24%|██▎       | 146/615 [07:01<23:20,  2.99s/it]                                                  24%|██▎       | 146/615 [07:01<23:20,  2.99s/it] 24%|██▍       | 147/615 [07:04<22:26,  2.88s/it]                                                  24%|██▍       | 147/615 [07:04<22:26,  2.88s/it] 24%|██▍       | 148/615 [07:07<23:13,  2.98s/it]                                                  24%|██▍       | 148/615 [07:07<23:13,  2.98s/it] 24%|██▍       | 149/615 [07:11<24:20,  3.13s/it]                                                  24%|██▍       | 149/615 [07:11<24:20,  3.13s/it] 24%|██▍       | 150/615 [07:14<24:06,  3.11s/it]                                                  24%|██▍       | 150/615 [07:14<24:06,  3.11s/it] 25%|██▍       | 151/615 [07:17<23:20,  3.02s/it]                                                  25%|██▍       | 151/615 [07:17<23:20,  3.02s/it] 25%|██▍       | 152/615 [07:20<23:27,  3.04s/it]                                                  25%|██▍       | 152/615 [07:20<23:27,  3.04s/it] 25%|██▍       | 153/615 [07:23<23:44,  3.08s/it]                                                  25%|██▍       | 153/615 [07:23<23:44,  3.08s/it] 25%|██▌       | 154/615 [07:26<24:29,  3.19s/it]                                                  25%|██▌       | 154/615 [07:26<24:29,  3.19s/it] 25%|██▌       | 155/615 [07:30<24:29,  3.20s/it]                                                  25%|██▌       | 155/615 [07:30<24:29,  3.20s/it] 25%|██▌       | 156/615 [07:32<23:33,  3.08s/it]                                                  25%|██▌       | 156/615 [07:32<23:33,  3.08s/it] 26%|██▌       | 157/615 [07:36<23:33,  3.09s/it]                                                  26%|██▌       | 157/615 [07:36<23:33,  3.09s/it] 26%|██▌       | 158/615 [07:39<24:03,  3.16s/it]                                                  26%|██▌       | 158/615 [07:39<24:03,  3.16s/it] 26%|██▌       | 159/615 [07:42<24:11,  3.18s/it]                                                  26%|██▌       | 159/615 [07:42<24:11,  3.18s/it] 26%|██▌       | 160/615 [07:46<24:50,  3.28s/it]                                                  26%|██▌       | 160/615 [07:46<24:50,  3.28s/it] 26%|██▌       | 161/615 [07:48<23:44,  3.14s/it]                                                  26%|██▌       | 161/615 [07:48<23:44,  3.14s/it] 26%|██▋       | 162/615 [07:51<22:45,  3.01s/it]                                                  26%|██▋       | 162/615 [07:51<22:45,  3.01s/it] 27%|██▋       | 163/615 [07:54<21:58,  2.92s/it]                                                  27%|██▋       | 163/615 [07:54<21:58,  2.92s/it] 27%|██▋       | 164/615 [07:57<21:28,  2.86s/it]                                                  27%|██▋       | 164/615 [07:57<21:28,  2.86s/it] 27%|██▋       | 165/615 [08:00<22:10,  2.96s/it]                                                  27%|██▋       | 165/615 [08:00<22:10,  2.96s/it] 27%|██▋       | 166/615 [08:02<21:25,  2.86s/it]                                                  27%|██▋       | 166/615 [08:02<21:25,  2.86s/it] 27%|██▋       | 167/615 [08:05<21:09,  2.83s/it]                                                  27%|██▋       | 167/615 [08:05<21:09,  2.83s/it] 27%|██▋       | 168/615 [08:08<20:47,  2.79s/it]                                                  27%|██▋       | 168/615 [08:08<20:47,  2.79s/it] 27%|██▋       | 169/615 [08:10<20:21,  2.74s/it]                                                  27%|██▋       | 169/615 [08:10<20:21,  2.74s/it] 28%|██▊       | 170/615 [08:13<20:13,  2.73s/it]                                                  28%|██▊       | 170/615 [08:13<20:13,  2.73s/it] 28%|██▊       | 171/615 [08:16<19:53,  2.69s/it]                                                  28%|██▊       | 171/615 [08:16<19:53,  2.69s/it] 28%|██▊       | 172/615 [08:18<19:49,  2.68s/it]                                                  28%|██▊       | 172/615 [08:18<19:49,  2.68s/it] 28%|██▊       | 173/615 [08:21<19:35,  2.66s/it]                                                  28%|██▊       | 173/615 [08:21<19:35,  2.66s/it] 28%|██▊       | 174/615 [08:24<19:29,  2.65s/it]                                                  28%|██▊       | 174/615 [08:24<19:29,  2.65s/it] 28%|██▊       | 175/615 [08:26<19:14,  2.62s/it]                                                  28%|██▊       | 175/615 [08:26<19:14,  2.62s/it] 29%|██▊       | 176/615 [08:29<19:30,  2.67s/it]                                                  29%|██▊       | 176/615 [08:29<19:30,  2.67s/it] 29%|██▉       | 177/615 [08:32<20:56,  2.87s/it]                                                  29%|██▉       | 177/615 [08:32<20:56,  2.87s/it] 29%|██▉       | 178/615 [08:35<20:19,  2.79s/it]                                                  29%|██▉       | 178/615 [08:35<20:19,  2.79s/it] 29%|██▉       | 179/615 [08:38<19:52,  2.74s/it]                                                  29%|██▉       | 179/615 [08:38<19:52,  2.74s/it] 29%|██▉       | 180/615 [08:40<19:31,  2.69s/it]                                                  29%|██▉       | 180/615 [08:40<19:31,  2.69s/it] 29%|██▉       | 181/615 [08:43<19:11,  2.65s/it]                                                  29%|██▉       | 181/615 [08:43<19:11,  2.65s/it] 30%|██▉       | 182/615 [08:45<18:58,  2.63s/it]                                                  30%|██▉       | 182/615 [08:45<18:58,  2.63s/it] 30%|██▉       | 183/615 [08:49<21:16,  2.95s/it]                                                  30%|██▉       | 183/615 [08:49<21:16,  2.95s/it] 30%|██▉       | 184/615 [08:52<20:37,  2.87s/it]                                                  30%|██▉       | 184/615 [08:52<20:37,  2.87s/it] 30%|███       | 185/615 [08:54<19:58,  2.79s/it]                                                  30%|███       | 185/615 [08:54<19:58,  2.79s/it] 30%|███       | 186/615 [08:57<19:29,  2.73s/it]                                                  30%|███       | 186/615 [08:57<19:29,  2.73s/it] 30%|███       | 187/615 [08:59<19:05,  2.68s/it]                                                  30%|███       | 187/615 [08:59<19:05,  2.68s/it] 31%|███       | 188/615 [09:02<19:21,  2.72s/it]                                                  31%|███       | 188/615 [09:02<19:21,  2.72s/it] 31%|███       | 189/615 [09:05<20:15,  2.85s/it]                                                  31%|███       | 189/615 [09:05<20:15,  2.85s/it] 31%|███       | 190/615 [09:08<19:38,  2.77s/it]                                                  31%|███       | 190/615 [09:08<19:38,  2.77s/it] 31%|███       | 191/615 [09:10<19:02,  2.69s/it]                                                  31%|███       | 191/615 [09:10<19:02,  2.69s/it] 31%|███       | 192/615 [09:13<18:37,  2.64s/it]                                                  31%|███       | 192/615 [09:13<18:37,  2.64s/it] 31%|███▏      | 193/615 [09:16<18:24,  2.62s/it]                                                  31%|███▏      | 193/615 [09:16<18:24,  2.62s/it] 32%|███▏      | 194/615 [09:18<18:14,  2.60s/it]                                                  32%|███▏      | 194/615 [09:18<18:14,  2.60s/it] 32%|███▏      | 195/615 [09:21<18:07,  2.59s/it]                                                  32%|███▏      | 195/615 [09:21<18:07,  2.59s/it] 32%|███▏      | 196/615 [09:23<17:56,  2.57s/it]                                                  32%|███▏      | 196/615 [09:23<17:56,  2.57s/it] 32%|███▏      | 197/615 [09:26<17:58,  2.58s/it]                                                  32%|███▏      | 197/615 [09:26<17:58,  2.58s/it] 32%|███▏      | 198/615 [09:29<18:28,  2.66s/it]                                                  32%|███▏      | 198/615 [09:29<18:28,  2.66s/it] 32%|███▏      | 199/615 [09:31<18:11,  2.62s/it]                                                  32%|███▏      | 199/615 [09:31<18:11,  2.62s/it] 33%|███▎      | 200/615 [09:34<18:07,  2.62s/it]                                                  33%|███▎      | 200/615 [09:34<18:07,  2.62s/it] 33%|███▎      | 201/615 [09:37<19:22,  2.81s/it]                                                  33%|███▎      | 201/615 [09:37<19:22,  2.81s/it] 33%|███▎      | 202/615 [09:39<17:44,  2.58s/it]                                                  33%|███▎      | 202/615 [09:39<17:44,  2.58s/it] 33%|███▎      | 203/615 [09:41<16:26,  2.40s/it]                                                  33%|███▎      | 203/615 [09:41<16:26,  2.40s/it] 33%|███▎      | 204/615 [09:43<15:30,  2.26s/it]                                                  33%|███▎      | 204/615 [09:43<15:30,  2.26s/it] 33%|███▎      | 205/615 [09:45<15:44,  2.30s/it]                                                  33%|███▎      | 205/615 [09:45<15:44,  2.30s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 33%|███▎      | 206/615 [10:18<1:17:00, 11.30s/it]                                                    33%|███▎      | 206/615 [10:18<1:17:00, 11.30s/it] 34%|███▎      | 207/615 [10:21<1:00:27,  8.89s/it]                                                    34%|███▎      | 207/615 [10:21<1:00:27,  8.89s/it] 34%|███▍      | 208/615 [10:24<48:28,  7.15s/it]                                                    34%|███▍      | 208/615 [10:24<48:28,  7.15s/it] 34%|███▍      | 209/615 [10:27<39:41,  5.86s/it]                                                  34%|███▍      | 209/615 [10:27<39:41,  5.86s/it] 34%|███▍      | 210/615 [10:30<33:59,  5.04s/it]                                                  34%|███▍      | 210/615 [10:30<33:59,  5.04s/it] 34%|███▍      | 211/615 [10:33<28:55,  4.30s/it]                                                  34%|███▍      | 211/615 [10:33<28:55,  4.30s/it] 34%|███▍      | 212/615 [10:35<25:44,  3.83s/it]                                                  34%|███▍      | 212/615 [10:35<25:44,  3.83s/it] 35%|███▍      | 213/615 [10:38<23:18,  3.48s/it]                                                  35%|███▍      | 213/615 [10:38<23:18,  3.48s/it] 35%|███▍      | 214/615 [10:41<22:43,  3.40s/it]                                                  35%|███▍      | 214/615 [10:41<22:43,  3.40s/it] 35%|███▍      | 215/615 [10:44<21:36,  3.24s/it]                                                  35%|███▍      | 215/615 [10:44<21:36,  3.24s/it] 35%|███▌      | 216/615 [10:47<20:36,  3.10s/it]                                                  35%|███▌      | 216/615 [10:47<20:36,  3.10s/it] 35%|███▌      | 217/615 [10:51<21:50,  3.29s/it]                                                  35%|███▌      | 217/615 [10:51<21:50,  3.29s/it] 35%|███▌      | 218/615 [10:53<20:39,  3.12s/it]                                                  35%|███▌      | 218/615 [10:53<20:39,  3.12s/it] 36%|███▌      | 219/615 [10:56<19:54,  3.02s/it]                                                  36%|███▌      | 219/615 [10:56<19:54,  3.02s/it] 36%|███▌      | 220/615 [10:59<19:24,  2.95s/it]                                                  36%|███▌      | 220/615 [10:59<19:24,  2.95s/it] 36%|███▌      | 221/615 [11:02<18:59,  2.89s/it]                                                  36%|███▌      | 221/615 [11:02<18:59,  2.89s/it] 36%|███▌      | 222/615 [11:05<20:30,  3.13s/it]                                                  36%|███▌      | 222/615 [11:05<20:30,  3.13s/it] 36%|███▋      | 223/615 [11:09<20:41,  3.17s/it]                                                  36%|███▋      | 223/615 [11:09<20:41,  3.17s/it] 36%|███▋      | 224/615 [11:11<19:47,  3.04s/it]                                                  36%|███▋      | 224/615 [11:11<19:47,  3.04s/it] 37%|███▋      | 225/615 [11:15<20:06,  3.09s/it]                                                  37%|███▋      | 225/615 [11:15<20:06,  3.09s/it] 37%|███▋      | 226/615 [11:17<19:17,  2.98s/it]                                                  37%|███▋      | 226/615 [11:17<19:17,  2.98s/it] 37%|███▋      | 227/615 [11:20<18:45,  2.90s/it]                                                  37%|███▋      | 227/615 [11:20<18:45,  2.90s/it] 37%|███▋      | 228/615 [11:22<17:59,  2.79s/it]                                                  37%|███▋      | 228/615 [11:22<17:59,  2.79s/it] 37%|███▋      | 229/615 [11:25<17:49,  2.77s/it]                                                  37%|███▋      | 229/615 [11:25<17:49,  2.77s/it] 37%|███▋      | 230/615 [11:28<17:44,  2.76s/it]                                                  37%|███▋      | 230/615 [11:28<17:44,  2.76s/it] 38%|███▊      | 231/615 [11:31<17:23,  2.72s/it]                                                  38%|███▊      | 231/615 [11:31<17:23,  2.72s/it] 38%|███▊      | 232/615 [11:33<17:10,  2.69s/it]                                                  38%|███▊      | 232/615 [11:33<17:10,  2.69s/it] 38%|███▊      | 233/615 [11:36<17:27,  2.74s/it]                                                  38%|███▊      | 233/615 [11:36<17:27,  2.74s/it] 38%|███▊      | 234/615 [11:39<17:20,  2.73s/it]                                                  38%|███▊      | 234/615 [11:39<17:20,  2.73s/it] 38%|███▊      | 235/615 [11:41<17:17,  2.73s/it]                                                  38%|███▊      | 235/615 [11:42<17:17,  2.73s/it] 38%|███▊      | 236/615 [11:44<17:02,  2.70s/it]                                                  38%|███▊      | 236/615 [11:44<17:02,  2.70s/it] 39%|███▊      | 237/615 [11:48<18:49,  2.99s/it]                                                  39%|███▊      | 237/615 [11:48<18:49,  2.99s/it] 39%|███▊      | 238/615 [11:51<18:55,  3.01s/it]                                                  39%|███▊      | 238/615 [11:51<18:55,  3.01s/it] 39%|███▉      | 239/615 [11:54<18:23,  2.93s/it]                                                  39%|███▉      | 239/615 [11:54<18:23,  2.93s/it] 39%|███▉      | 240/615 [11:56<17:59,  2.88s/it]                                                  39%|███▉      | 240/615 [11:56<17:59,  2.88s/it] 39%|███▉      | 241/615 [11:59<17:35,  2.82s/it]                                                  39%|███▉      | 241/615 [11:59<17:35,  2.82s/it] 39%|███▉      | 242/615 [12:02<17:22,  2.80s/it]                                                  39%|███▉      | 242/615 [12:02<17:22,  2.80s/it] 40%|███▉      | 243/615 [12:04<17:05,  2.76s/it]                                                  40%|███▉      | 243/615 [12:04<17:05,  2.76s/it] 40%|███▉      | 244/615 [12:07<17:05,  2.77s/it]                                                  40%|███▉      | 244/615 [12:07<17:05,  2.77s/it] 40%|███▉      | 245/615 [12:10<16:50,  2.73s/it]                                                  40%|███▉      | 245/615 [12:10<16:50,  2.73s/it] 40%|████      | 246/615 [12:12<16:35,  2.70s/it]                                                  40%|████      | 246/615 [12:13<16:35,  2.70s/it] 40%|████      | 247/615 [12:15<16:23,  2.67s/it]                                                  40%|████      | 247/615 [12:15<16:23,  2.67s/it] 40%|████      | 248/615 [12:18<17:19,  2.83s/it]                                                  40%|████      | 248/615 [12:18<17:19,  2.83s/it] 40%|████      | 249/615 [12:21<16:56,  2.78s/it]                                                  40%|████      | 249/615 [12:21<16:56,  2.78s/it] 41%|████      | 250/615 [12:24<16:43,  2.75s/it]                                                  41%|████      | 250/615 [12:24<16:43,  2.75s/it] 41%|████      | 251/615 [12:26<16:24,  2.71s/it]                                                  41%|████      | 251/615 [12:26<16:24,  2.71s/it] 41%|████      | 252/615 [12:29<16:08,  2.67s/it]                                                  41%|████      | 252/615 [12:29<16:08,  2.67s/it] 41%|████      | 253/615 [12:31<15:55,  2.64s/it]                                                  41%|████      | 253/615 [12:31<15:55,  2.64s/it] 41%|████▏     | 254/615 [12:34<15:45,  2.62s/it]                                                  41%|████▏     | 254/615 [12:34<15:45,  2.62s/it] 41%|████▏     | 255/615 [12:37<15:58,  2.66s/it]                                                  41%|████▏     | 255/615 [12:37<15:58,  2.66s/it] 42%|████▏     | 256/615 [12:40<17:06,  2.86s/it]                                                  42%|████▏     | 256/615 [12:40<17:06,  2.86s/it] 42%|████▏     | 257/615 [12:43<17:09,  2.88s/it]                                                  42%|████▏     | 257/615 [12:43<17:09,  2.88s/it] 42%|████▏     | 258/615 [12:46<17:30,  2.94s/it]                                                  42%|████▏     | 258/615 [12:46<17:30,  2.94s/it] 42%|████▏     | 259/615 [12:50<19:46,  3.33s/it]                                                  42%|████▏     | 259/615 [12:50<19:46,  3.33s/it] 42%|████▏     | 260/615 [12:54<19:30,  3.30s/it]                                                  42%|████▏     | 260/615 [12:54<19:30,  3.30s/it] 42%|████▏     | 261/615 [12:57<19:38,  3.33s/it]                                                  42%|████▏     | 261/615 [12:57<19:38,  3.33s/it] 43%|████▎     | 262/615 [13:00<19:42,  3.35s/it]                                                  43%|████▎     | 262/615 [13:00<19:42,  3.35s/it] 43%|████▎     | 263/615 [13:04<19:25,  3.31s/it]                                                  43%|████▎     | 263/615 [13:04<19:25,  3.31s/it] 43%|████▎     | 264/615 [13:06<18:34,  3.18s/it]                                                  43%|████▎     | 264/615 [13:06<18:34,  3.18s/it] 43%|████▎     | 265/615 [13:09<17:39,  3.03s/it]                                                  43%|████▎     | 265/615 [13:09<17:39,  3.03s/it] 43%|████▎     | 266/615 [13:12<17:12,  2.96s/it]                                                  43%|████▎     | 266/615 [13:12<17:12,  2.96s/it] 43%|████▎     | 267/615 [13:15<16:41,  2.88s/it]                                                  43%|████▎     | 267/615 [13:15<16:41,  2.88s/it] 44%|████▎     | 268/615 [13:17<16:21,  2.83s/it]                                                  44%|████▎     | 268/615 [13:17<16:21,  2.83s/it] 44%|████▎     | 269/615 [13:20<16:08,  2.80s/it]                                                  44%|████▎     | 269/615 [13:20<16:08,  2.80s/it] 44%|████▍     | 270/615 [13:23<17:07,  2.98s/it]                                                  44%|████▍     | 270/615 [13:23<17:07,  2.98s/it] 44%|████▍     | 271/615 [13:27<18:13,  3.18s/it]                                                  44%|████▍     | 271/615 [13:27<18:13,  3.18s/it] 44%|████▍     | 272/615 [13:30<17:52,  3.13s/it]                                                  44%|████▍     | 272/615 [13:30<17:52,  3.13s/it] 44%|████▍     | 273/615 [13:33<17:17,  3.03s/it]                                                  44%|████▍     | 273/615 [13:33<17:17,  3.03s/it] 45%|████▍     | 274/615 [13:36<16:43,  2.94s/it]                                                  45%|████▍     | 274/615 [13:36<16:43,  2.94s/it] 45%|████▍     | 275/615 [13:38<16:23,  2.89s/it]                                                  45%|████▍     | 275/615 [13:38<16:23,  2.89s/it] 45%|████▍     | 276/615 [13:41<16:04,  2.84s/it]                                                  45%|████▍     | 276/615 [13:41<16:04,  2.84s/it] 45%|████▌     | 277/615 [13:44<16:46,  2.98s/it]                                                  45%|████▌     | 277/615 [13:44<16:46,  2.98s/it] 45%|████▌     | 278/615 [13:47<16:12,  2.88s/it]                                                  45%|████▌     | 278/615 [13:47<16:12,  2.88s/it] 45%|████▌     | 279/615 [13:50<16:01,  2.86s/it]                                                  45%|████▌     | 279/615 [13:50<16:01,  2.86s/it] 46%|████▌     | 280/615 [13:53<15:41,  2.81s/it]                                                  46%|████▌     | 280/615 [13:53<15:41,  2.81s/it] 46%|████▌     | 281/615 [13:56<16:50,  3.02s/it]                                                  46%|████▌     | 281/615 [13:56<16:50,  3.02s/it] 46%|████▌     | 282/615 [13:59<16:05,  2.90s/it]                                                  46%|████▌     | 282/615 [13:59<16:05,  2.90s/it] 46%|████▌     | 283/615 [14:01<15:41,  2.84s/it]                                                  46%|████▌     | 283/615 [14:01<15:41,  2.84s/it] 46%|████▌     | 284/615 [14:04<15:38,  2.84s/it]                                                  46%|████▌     | 284/615 [14:04<15:38,  2.84s/it] 46%|████▋     | 285/615 [14:07<15:19,  2.79s/it]                                                  46%|████▋     | 285/615 [14:07<15:19,  2.79s/it] 47%|████▋     | 286/615 [14:10<15:08,  2.76s/it]                                                  47%|████▋     | 286/615 [14:10<15:08,  2.76s/it] 47%|████▋     | 287/615 [14:12<14:46,  2.70s/it]                                                  47%|████▋     | 287/615 [14:12<14:46,  2.70s/it] 47%|████▋     | 288/615 [14:15<14:46,  2.71s/it]                                                  47%|████▋     | 288/615 [14:15<14:46,  2.71s/it] 47%|████▋     | 289/615 [14:18<14:34,  2.68s/it]                                                  47%|████▋     | 289/615 [14:18<14:34,  2.68s/it] 47%|████▋     | 290/615 [14:20<14:46,  2.73s/it]                                                  47%|████▋     | 290/615 [14:20<14:46,  2.73s/it] 47%|████▋     | 291/615 [14:23<14:47,  2.74s/it]                                                  47%|████▋     | 291/615 [14:23<14:47,  2.74s/it] 47%|████▋     | 292/615 [14:26<15:24,  2.86s/it]                                                  47%|████▋     | 292/615 [14:26<15:24,  2.86s/it] 48%|████▊     | 293/615 [14:29<15:12,  2.83s/it]                                                  48%|████▊     | 293/615 [14:29<15:12,  2.83s/it] 48%|████▊     | 294/615 [14:32<15:37,  2.92s/it]                                                  48%|████▊     | 294/615 [14:32<15:37,  2.92s/it] 48%|████▊     | 295/615 [14:36<16:37,  3.12s/it]                                                  48%|████▊     | 295/615 [14:36<16:37,  3.12s/it] 48%|████▊     | 296/615 [14:39<16:47,  3.16s/it]                                                  48%|████▊     | 296/615 [14:39<16:47,  3.16s/it] 48%|████▊     | 297/615 [14:42<16:55,  3.19s/it]                                                  48%|████▊     | 297/615 [14:42<16:55,  3.19s/it] 48%|████▊     | 298/615 [14:45<16:12,  3.07s/it]                                                  48%|████▊     | 298/615 [14:45<16:12,  3.07s/it] 49%|████▊     | 299/615 [14:49<17:07,  3.25s/it]                                                  49%|████▊     | 299/615 [14:49<17:07,  3.25s/it] 49%|████▉     | 300/615 [14:52<17:06,  3.26s/it]                                                  49%|████▉     | 300/615 [14:52<17:06,  3.26s/it] 49%|████▉     | 301/615 [14:55<17:07,  3.27s/it]                                                  49%|████▉     | 301/615 [14:55<17:07,  3.27s/it] 49%|████▉     | 302/615 [14:59<16:57,  3.25s/it]                                                  49%|████▉     | 302/615 [14:59<16:57,  3.25s/it] 49%|████▉     | 303/615 [15:02<17:00,  3.27s/it]                                                  49%|████▉     | 303/615 [15:02<17:00,  3.27s/it] 49%|████▉     | 304/615 [15:05<16:43,  3.23s/it]                                                  49%|████▉     | 304/615 [15:05<16:43,  3.23s/it] 50%|████▉     | 305/615 [15:08<16:23,  3.17s/it]                                                  50%|████▉     | 305/615 [15:08<16:23,  3.17s/it] 50%|████▉     | 306/615 [15:11<16:13,  3.15s/it]                                                  50%|████▉     | 306/615 [15:11<16:13,  3.15s/it] 50%|████▉     | 307/615 [15:14<15:41,  3.06s/it]                                                  50%|████▉     | 307/615 [15:14<15:41,  3.06s/it] 50%|█████     | 308/615 [15:17<15:06,  2.95s/it]                                                  50%|█████     | 308/615 [15:17<15:06,  2.95s/it] 50%|█████     | 309/615 [15:19<14:45,  2.89s/it]                                                  50%|█████     | 309/615 [15:19<14:45,  2.89s/it] 50%|█████     | 310/615 [15:22<14:15,  2.80s/it]                                                  50%|█████     | 310/615 [15:22<14:15,  2.80s/it] 51%|█████     | 311/615 [15:25<14:00,  2.76s/it]                                                  51%|█████     | 311/615 [15:25<14:00,  2.76s/it] 51%|█████     | 312/615 [15:27<13:48,  2.73s/it]                                                  51%|█████     | 312/615 [15:27<13:48,  2.73s/it] 51%|█████     | 313/615 [15:31<14:35,  2.90s/it]                                                  51%|█████     | 313/615 [15:31<14:35,  2.90s/it] 51%|█████     | 314/615 [15:33<14:21,  2.86s/it]                                                  51%|█████     | 314/615 [15:33<14:21,  2.86s/it] 51%|█████     | 315/615 [15:36<14:07,  2.83s/it]                                                  51%|█████     | 315/615 [15:36<14:07,  2.83s/it] 51%|█████▏    | 316/615 [15:39<14:08,  2.84s/it]                                                  51%|█████▏    | 316/615 [15:39<14:08,  2.84s/it] 52%|█████▏    | 317/615 [15:42<14:04,  2.83s/it]                                                  52%|█████▏    | 317/615 [15:42<14:04,  2.83s/it] 52%|█████▏    | 318/615 [15:45<14:19,  2.89s/it]                                                  52%|█████▏    | 318/615 [15:45<14:19,  2.89s/it] 52%|█████▏    | 319/615 [15:48<14:45,  2.99s/it]                                                  52%|█████▏    | 319/615 [15:48<14:45,  2.99s/it] 52%|█████▏    | 320/615 [15:51<15:03,  3.06s/it]                                                  52%|█████▏    | 320/615 [15:51<15:03,  3.06s/it] 52%|█████▏    | 321/615 [15:54<14:58,  3.06s/it]                                                  52%|█████▏    | 321/615 [15:54<14:58,  3.06s/it] 52%|█████▏    | 322/615 [15:57<14:54,  3.05s/it]                                                  52%|█████▏    | 322/615 [15:57<14:54,  3.05s/it] 53%|█████▎    | 323/615 [16:00<14:56,  3.07s/it]                                                  53%|█████▎    | 323/615 [16:00<14:56,  3.07s/it] 53%|█████▎    | 324/615 [16:04<15:09,  3.12s/it]                                                  53%|█████▎    | 324/615 [16:04<15:09,  3.12s/it] 53%|█████▎    | 325/615 [16:06<14:22,  2.98s/it]                                                  53%|█████▎    | 325/615 [16:06<14:22,  2.98s/it] 53%|█████▎    | 326/615 [16:09<13:57,  2.90s/it]                                                  53%|█████▎    | 326/615 [16:09<13:57,  2.90s/it] 53%|█████▎    | 327/615 [16:12<13:40,  2.85s/it]                                                  53%|█████▎    | 327/615 [16:12<13:40,  2.85s/it] 53%|█████▎    | 328/615 [16:14<13:14,  2.77s/it]                                                  53%|█████▎    | 328/615 [16:14<13:14,  2.77s/it] 53%|█████▎    | 329/615 [16:17<13:02,  2.74s/it]                                                  53%|█████▎    | 329/615 [16:17<13:02,  2.74s/it] 54%|█████▎    | 330/615 [16:20<12:55,  2.72s/it]                                                  54%|█████▎    | 330/615 [16:20<12:55,  2.72s/it] 54%|█████▍    | 331/615 [16:22<12:45,  2.70s/it]                                                  54%|█████▍    | 331/615 [16:22<12:45,  2.70s/it] 54%|█████▍    | 332/615 [16:25<12:43,  2.70s/it]                                                  54%|█████▍    | 332/615 [16:25<12:43,  2.70s/it] 54%|█████▍    | 333/615 [16:28<12:37,  2.69s/it]                                                  54%|█████▍    | 333/615 [16:28<12:37,  2.69s/it] 54%|█████▍    | 334/615 [16:31<12:58,  2.77s/it]                                                  54%|█████▍    | 334/615 [16:31<12:58,  2.77s/it] 54%|█████▍    | 335/615 [16:34<13:27,  2.88s/it]                                                  54%|█████▍    | 335/615 [16:34<13:27,  2.88s/it] 55%|█████▍    | 336/615 [16:37<13:37,  2.93s/it]                                                  55%|█████▍    | 336/615 [16:37<13:37,  2.93s/it] 55%|█████▍    | 337/615 [16:40<13:17,  2.87s/it]                                                  55%|█████▍    | 337/615 [16:40<13:17,  2.87s/it] 55%|█████▍    | 338/615 [16:42<13:00,  2.82s/it]                                                  55%|█████▍    | 338/615 [16:42<13:00,  2.82s/it] 55%|█████▌    | 339/615 [16:45<12:45,  2.77s/it]                                                  55%|█████▌    | 339/615 [16:45<12:45,  2.77s/it] 55%|█████▌    | 340/615 [16:49<14:11,  3.10s/it]                                                  55%|█████▌    | 340/615 [16:49<14:11,  3.10s/it] 55%|█████▌    | 341/615 [16:52<14:11,  3.11s/it]                                                  55%|█████▌    | 341/615 [16:52<14:11,  3.11s/it] 56%|█████▌    | 342/615 [16:55<14:34,  3.20s/it]                                                  56%|█████▌    | 342/615 [16:55<14:34,  3.20s/it] 56%|█████▌    | 343/615 [16:58<14:04,  3.10s/it]                                                  56%|█████▌    | 343/615 [16:58<14:04,  3.10s/it] 56%|█████▌    | 344/615 [17:02<14:12,  3.14s/it]                                                  56%|█████▌    | 344/615 [17:02<14:12,  3.14s/it] 56%|█████▌    | 345/615 [17:05<14:15,  3.17s/it]                                                  56%|█████▌    | 345/615 [17:05<14:15,  3.17s/it] 56%|█████▋    | 346/615 [17:08<14:39,  3.27s/it]                                                  56%|█████▋    | 346/615 [17:08<14:39,  3.27s/it] 56%|█████▋    | 347/615 [17:11<14:13,  3.18s/it]                                                  56%|█████▋    | 347/615 [17:11<14:13,  3.18s/it] 57%|█████▋    | 348/615 [17:14<13:43,  3.08s/it]                                                  57%|█████▋    | 348/615 [17:14<13:43,  3.08s/it] 57%|█████▋    | 349/615 [17:17<13:20,  3.01s/it]                                                  57%|█████▋    | 349/615 [17:17<13:20,  3.01s/it] 57%|█████▋    | 350/615 [17:20<12:51,  2.91s/it]                                                  57%|█████▋    | 350/615 [17:20<12:51,  2.91s/it] 57%|█████▋    | 351/615 [17:22<12:34,  2.86s/it]                                                  57%|█████▋    | 351/615 [17:22<12:34,  2.86s/it] 57%|█████▋    | 352/615 [17:25<12:15,  2.80s/it]                                                  57%|█████▋    | 352/615 [17:25<12:15,  2.80s/it] 57%|█████▋    | 353/615 [17:28<12:11,  2.79s/it]                                                  57%|█████▋    | 353/615 [17:28<12:11,  2.79s/it] 58%|█████▊    | 354/615 [17:30<11:55,  2.74s/it]                                                  58%|█████▊    | 354/615 [17:30<11:55,  2.74s/it] 58%|█████▊    | 355/615 [17:33<11:52,  2.74s/it]                                                  58%|█████▊    | 355/615 [17:33<11:52,  2.74s/it] 58%|█████▊    | 356/615 [17:36<11:41,  2.71s/it]                                                  58%|█████▊    | 356/615 [17:36<11:41,  2.71s/it] 58%|█████▊    | 357/615 [17:39<12:07,  2.82s/it]                                                  58%|█████▊    | 357/615 [17:39<12:07,  2.82s/it] 58%|█████▊    | 358/615 [17:42<12:41,  2.96s/it]                                                  58%|█████▊    | 358/615 [17:42<12:41,  2.96s/it] 58%|█████▊    | 359/615 [17:45<12:30,  2.93s/it]                                                  58%|█████▊    | 359/615 [17:45<12:30,  2.93s/it] 59%|█████▊    | 360/615 [17:48<12:06,  2.85s/it]                                                  59%|█████▊    | 360/615 [17:48<12:06,  2.85s/it] 59%|█████▊    | 361/615 [17:50<11:59,  2.83s/it]                                                  59%|█████▊    | 361/615 [17:50<11:59,  2.83s/it] 59%|█████▉    | 362/615 [17:53<11:56,  2.83s/it]                                                  59%|█████▉    | 362/615 [17:53<11:56,  2.83s/it] 59%|█████▉    | 363/615 [17:56<11:43,  2.79s/it]                                                  59%|█████▉    | 363/615 [17:56<11:43,  2.79s/it] 59%|█████▉    | 364/615 [17:59<11:44,  2.81s/it]                                                  59%|█████▉    | 364/615 [17:59<11:44,  2.81s/it] 59%|█████▉    | 365/615 [18:01<11:31,  2.77s/it]                                                  59%|█████▉    | 365/615 [18:02<11:31,  2.77s/it] 60%|█████▉    | 366/615 [18:04<11:21,  2.74s/it]                                                  60%|█████▉    | 366/615 [18:04<11:21,  2.74s/it] 60%|█████▉    | 367/615 [18:07<11:20,  2.74s/it]                                                  60%|█████▉    | 367/615 [18:07<11:20,  2.74s/it] 60%|█████▉    | 368/615 [18:10<11:10,  2.71s/it]                                                  60%|█████▉    | 368/615 [18:10<11:10,  2.71s/it] 60%|██████    | 369/615 [18:13<11:41,  2.85s/it]                                                  60%|██████    | 369/615 [18:13<11:41,  2.85s/it] 60%|██████    | 370/615 [18:15<11:22,  2.79s/it]                                                  60%|██████    | 370/615 [18:15<11:22,  2.79s/it] 60%|██████    | 371/615 [18:19<11:50,  2.91s/it]                                                  60%|██████    | 371/615 [18:19<11:50,  2.91s/it] 60%|██████    | 372/615 [18:21<11:31,  2.85s/it]                                                  60%|██████    | 372/615 [18:21<11:31,  2.85s/it] 61%|██████    | 373/615 [18:24<11:30,  2.85s/it]                                                  61%|██████    | 373/615 [18:24<11:30,  2.85s/it] 61%|██████    | 374/615 [18:27<11:11,  2.79s/it]                                                  61%|██████    | 374/615 [18:27<11:11,  2.79s/it] 61%|██████    | 375/615 [18:30<11:04,  2.77s/it]                                                  61%|██████    | 375/615 [18:30<11:04,  2.77s/it] 61%|██████    | 376/615 [18:32<10:55,  2.74s/it]                                                  61%|██████    | 376/615 [18:32<10:55,  2.74s/it] 61%|██████▏   | 377/615 [18:35<10:51,  2.74s/it]                                                  61%|██████▏   | 377/615 [18:35<10:51,  2.74s/it] 61%|██████▏   | 378/615 [18:38<10:45,  2.72s/it]                                                  61%|██████▏   | 378/615 [18:38<10:45,  2.72s/it] 62%|██████▏   | 379/615 [18:40<10:46,  2.74s/it]                                                  62%|██████▏   | 379/615 [18:40<10:46,  2.74s/it] 62%|██████▏   | 380/615 [18:43<11:04,  2.83s/it]                                                  62%|██████▏   | 380/615 [18:43<11:04,  2.83s/it] 62%|██████▏   | 381/615 [18:47<12:10,  3.12s/it]                                                  62%|██████▏   | 381/615 [18:47<12:10,  3.12s/it] 62%|██████▏   | 382/615 [18:51<12:28,  3.21s/it]                                                  62%|██████▏   | 382/615 [18:51<12:28,  3.21s/it] 62%|██████▏   | 383/615 [18:53<11:45,  3.04s/it]                                                  62%|██████▏   | 383/615 [18:53<11:45,  3.04s/it] 62%|██████▏   | 384/615 [18:56<11:11,  2.90s/it]                                                  62%|██████▏   | 384/615 [18:56<11:11,  2.90s/it] 63%|██████▎   | 385/615 [18:59<10:57,  2.86s/it]                                                  63%|██████▎   | 385/615 [18:59<10:57,  2.86s/it] 63%|██████▎   | 386/615 [19:01<10:39,  2.79s/it]                                                  63%|██████▎   | 386/615 [19:01<10:39,  2.79s/it] 63%|██████▎   | 387/615 [19:05<11:32,  3.04s/it]                                                  63%|██████▎   | 387/615 [19:05<11:32,  3.04s/it] 63%|██████▎   | 388/615 [19:08<11:28,  3.03s/it]                                                  63%|██████▎   | 388/615 [19:08<11:28,  3.03s/it] 63%|██████▎   | 389/615 [19:11<11:22,  3.02s/it]                                                  63%|██████▎   | 389/615 [19:11<11:22,  3.02s/it] 63%|██████▎   | 390/615 [19:14<11:19,  3.02s/it]                                                  63%|██████▎   | 390/615 [19:14<11:19,  3.02s/it] 64%|██████▎   | 391/615 [19:17<11:54,  3.19s/it]                                                  64%|██████▎   | 391/615 [19:18<11:54,  3.19s/it] 64%|██████▎   | 392/615 [19:21<11:48,  3.18s/it]                                                  64%|██████▎   | 392/615 [19:21<11:48,  3.18s/it] 64%|██████▍   | 393/615 [19:24<11:52,  3.21s/it]                                                  64%|██████▍   | 393/615 [19:24<11:52,  3.21s/it] 64%|██████▍   | 394/615 [19:27<11:41,  3.17s/it]                                                  64%|██████▍   | 394/615 [19:27<11:41,  3.17s/it] 64%|██████▍   | 395/615 [19:30<11:37,  3.17s/it]                                                  64%|██████▍   | 395/615 [19:30<11:37,  3.17s/it] 64%|██████▍   | 396/615 [19:33<11:32,  3.16s/it]                                                  64%|██████▍   | 396/615 [19:33<11:32,  3.16s/it] 65%|██████▍   | 397/615 [19:36<11:27,  3.15s/it]                                                  65%|██████▍   | 397/615 [19:36<11:27,  3.15s/it] 65%|██████▍   | 398/615 [19:39<10:58,  3.04s/it]                                                  65%|██████▍   | 398/615 [19:39<10:58,  3.04s/it] 65%|██████▍   | 399/615 [19:42<10:30,  2.92s/it]                                                  65%|██████▍   | 399/615 [19:42<10:30,  2.92s/it] 65%|██████▌   | 400/615 [19:45<10:33,  2.95s/it]                                                  65%|██████▌   | 400/615 [19:45<10:33,  2.95s/it] 65%|██████▌   | 401/615 [19:48<10:45,  3.02s/it]                                                  65%|██████▌   | 401/615 [19:48<10:45,  3.02s/it] 65%|██████▌   | 402/615 [19:51<10:42,  3.02s/it]                                                  65%|██████▌   | 402/615 [19:51<10:42,  3.02s/it] 66%|██████▌   | 403/615 [19:54<10:17,  2.91s/it]                                                  66%|██████▌   | 403/615 [19:54<10:17,  2.91s/it] 66%|██████▌   | 404/615 [19:56<10:02,  2.85s/it]                                                  66%|██████▌   | 404/615 [19:56<10:02,  2.85s/it] 66%|██████▌   | 405/615 [19:59<09:52,  2.82s/it]                                                  66%|██████▌   | 405/615 [19:59<09:52,  2.82s/it] 66%|██████▌   | 406/615 [20:02<09:49,  2.82s/it]                                                  66%|██████▌   | 406/615 [20:02<09:49,  2.82s/it] 66%|██████▌   | 407/615 [20:04<09:00,  2.60s/it]                                                  66%|██████▌   | 407/615 [20:04<09:00,  2.60s/it] 66%|██████▋   | 408/615 [20:06<08:18,  2.41s/it]                                                  66%|██████▋   | 408/615 [20:06<08:18,  2.41s/it] 67%|██████▋   | 409/615 [20:08<07:48,  2.28s/it]                                                  67%|██████▋   | 409/615 [20:08<07:48,  2.28s/it] 67%|██████▋   | 410/615 [20:11<08:01,  2.35s/it]                                                  67%|██████▋   | 410/615 [20:11<08:01,  2.35s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 3, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 67%|██████▋   | 411/615 [20:42<37:19, 10.98s/it]                                                  67%|██████▋   | 411/615 [20:42<37:19, 10.98s/it] 67%|██████▋   | 412/615 [20:44<28:48,  8.51s/it]                                                  67%|██████▋   | 412/615 [20:44<28:48,  8.51s/it] 67%|██████▋   | 413/615 [20:48<23:13,  6.90s/it]                                                  67%|██████▋   | 413/615 [20:48<23:13,  6.90s/it] 67%|██████▋   | 414/615 [20:51<19:33,  5.84s/it]                                                  67%|██████▋   | 414/615 [20:51<19:33,  5.84s/it] 67%|██████▋   | 415/615 [20:54<16:51,  5.06s/it]                                                  67%|██████▋   | 415/615 [20:54<16:51,  5.06s/it] 68%|██████▊   | 416/615 [20:57<14:42,  4.43s/it]                                                  68%|██████▊   | 416/615 [20:57<14:42,  4.43s/it] 68%|██████▊   | 417/615 [21:00<12:49,  3.89s/it]                                                  68%|██████▊   | 417/615 [21:00<12:49,  3.89s/it] 68%|██████▊   | 418/615 [21:02<11:39,  3.55s/it]                                                  68%|██████▊   | 418/615 [21:03<11:39,  3.55s/it] 68%|██████▊   | 419/615 [21:05<10:42,  3.28s/it]                                                  68%|██████▊   | 419/615 [21:05<10:42,  3.28s/it] 68%|██████▊   | 420/615 [21:08<10:11,  3.13s/it]                                                  68%|██████▊   | 420/615 [21:08<10:11,  3.13s/it] 68%|██████▊   | 421/615 [21:11<09:40,  2.99s/it]                                                  68%|██████▊   | 421/615 [21:11<09:40,  2.99s/it] 69%|██████▊   | 422/615 [21:13<09:19,  2.90s/it]                                                  69%|██████▊   | 422/615 [21:13<09:19,  2.90s/it] 69%|██████▉   | 423/615 [21:16<08:57,  2.80s/it]                                                  69%|██████▉   | 423/615 [21:16<08:57,  2.80s/it] 69%|██████▉   | 424/615 [21:19<08:50,  2.78s/it]                                                  69%|██████▉   | 424/615 [21:19<08:50,  2.78s/it] 69%|██████▉   | 425/615 [21:21<08:39,  2.73s/it]                                                  69%|██████▉   | 425/615 [21:21<08:39,  2.73s/it] 69%|██████▉   | 426/615 [21:25<09:10,  2.91s/it]                                                  69%|██████▉   | 426/615 [21:25<09:10,  2.91s/it] 69%|██████▉   | 427/615 [21:28<09:42,  3.10s/it]                                                  69%|██████▉   | 427/615 [21:28<09:42,  3.10s/it] 70%|██████▉   | 428/615 [21:31<09:46,  3.13s/it]                                                  70%|██████▉   | 428/615 [21:31<09:46,  3.13s/it] 70%|██████▉   | 429/615 [21:34<09:28,  3.05s/it]                                                  70%|██████▉   | 429/615 [21:34<09:28,  3.05s/it] 70%|██████▉   | 430/615 [21:37<09:26,  3.06s/it]                                                  70%|██████▉   | 430/615 [21:37<09:26,  3.06s/it] 70%|███████   | 431/615 [21:40<08:58,  2.93s/it]                                                  70%|███████   | 431/615 [21:40<08:58,  2.93s/it] 70%|███████   | 432/615 [21:43<08:41,  2.85s/it]                                                  70%|███████   | 432/615 [21:43<08:41,  2.85s/it] 70%|███████   | 433/615 [21:45<08:27,  2.79s/it]                                                  70%|███████   | 433/615 [21:45<08:27,  2.79s/it] 71%|███████   | 434/615 [21:48<08:22,  2.77s/it]                                                  71%|███████   | 434/615 [21:48<08:22,  2.77s/it] 71%|███████   | 435/615 [21:51<08:13,  2.74s/it]                                                  71%|███████   | 435/615 [21:51<08:13,  2.74s/it] 71%|███████   | 436/615 [21:53<08:08,  2.73s/it]                                                  71%|███████   | 436/615 [21:53<08:08,  2.73s/it] 71%|███████   | 437/615 [21:57<08:38,  2.91s/it]                                                  71%|███████   | 437/615 [21:57<08:38,  2.91s/it] 71%|███████   | 438/615 [22:00<08:35,  2.91s/it]                                                  71%|███████   | 438/615 [22:00<08:35,  2.91s/it] 71%|███████▏  | 439/615 [22:02<08:12,  2.80s/it]                                                  71%|███████▏  | 439/615 [22:02<08:12,  2.80s/it] 72%|███████▏  | 440/615 [22:05<08:04,  2.77s/it]                                                  72%|███████▏  | 440/615 [22:05<08:04,  2.77s/it] 72%|███████▏  | 441/615 [22:08<08:05,  2.79s/it]                                                  72%|███████▏  | 441/615 [22:08<08:05,  2.79s/it] 72%|███████▏  | 442/615 [22:10<07:59,  2.77s/it]                                                  72%|███████▏  | 442/615 [22:10<07:59,  2.77s/it] 72%|███████▏  | 443/615 [22:13<07:54,  2.76s/it]                                                  72%|███████▏  | 443/615 [22:13<07:54,  2.76s/it] 72%|███████▏  | 444/615 [22:16<07:46,  2.73s/it]                                                  72%|███████▏  | 444/615 [22:16<07:46,  2.73s/it] 72%|███████▏  | 445/615 [22:18<07:42,  2.72s/it]                                                  72%|███████▏  | 445/615 [22:18<07:42,  2.72s/it] 73%|███████▎  | 446/615 [22:21<07:32,  2.68s/it]                                                  73%|███████▎  | 446/615 [22:21<07:32,  2.68s/it] 73%|███████▎  | 447/615 [22:24<07:33,  2.70s/it]                                                  73%|███████▎  | 447/615 [22:24<07:33,  2.70s/it] 73%|███████▎  | 448/615 [22:26<07:28,  2.69s/it]                                                  73%|███████▎  | 448/615 [22:26<07:28,  2.69s/it] 73%|███████▎  | 449/615 [22:30<07:55,  2.86s/it]                                                  73%|███████▎  | 449/615 [22:30<07:55,  2.86s/it] 73%|███████▎  | 450/615 [22:32<07:42,  2.80s/it]                                                  73%|███████▎  | 450/615 [22:32<07:42,  2.80s/it] 73%|███████▎  | 451/615 [22:35<07:41,  2.82s/it]                                                  73%|███████▎  | 451/615 [22:35<07:41,  2.82s/it] 73%|███████▎  | 452/615 [22:38<08:00,  2.95s/it]                                                  73%|███████▎  | 452/615 [22:38<08:00,  2.95s/it] 74%|███████▎  | 453/615 [22:41<07:59,  2.96s/it]                                                  74%|███████▎  | 453/615 [22:41<07:59,  2.96s/it] 74%|███████▍  | 454/615 [22:45<08:05,  3.02s/it]                                                  74%|███████▍  | 454/615 [22:45<08:05,  3.02s/it] 74%|███████▍  | 455/615 [22:48<08:31,  3.20s/it]                                                  74%|███████▍  | 455/615 [22:48<08:31,  3.20s/it] 74%|███████▍  | 456/615 [22:52<09:05,  3.43s/it]                                                  74%|███████▍  | 456/615 [22:52<09:05,  3.43s/it] 74%|███████▍  | 457/615 [22:55<08:38,  3.28s/it]                                                  74%|███████▍  | 457/615 [22:55<08:38,  3.28s/it] 74%|███████▍  | 458/615 [22:58<08:06,  3.10s/it]                                                  74%|███████▍  | 458/615 [22:58<08:06,  3.10s/it] 75%|███████▍  | 459/615 [23:01<08:01,  3.09s/it]                                                  75%|███████▍  | 459/615 [23:01<08:01,  3.09s/it] 75%|███████▍  | 460/615 [23:04<07:47,  3.02s/it]                                                  75%|███████▍  | 460/615 [23:04<07:47,  3.02s/it] 75%|███████▍  | 461/615 [23:07<07:50,  3.05s/it]                                                  75%|███████▍  | 461/615 [23:07<07:50,  3.05s/it] 75%|███████▌  | 462/615 [23:10<07:53,  3.10s/it]                                                  75%|███████▌  | 462/615 [23:10<07:53,  3.10s/it] 75%|███████▌  | 463/615 [23:13<07:37,  3.01s/it]                                                  75%|███████▌  | 463/615 [23:13<07:37,  3.01s/it] 75%|███████▌  | 464/615 [23:16<07:20,  2.92s/it]                                                  75%|███████▌  | 464/615 [23:16<07:20,  2.92s/it] 76%|███████▌  | 465/615 [23:18<07:08,  2.86s/it]                                                  76%|███████▌  | 465/615 [23:18<07:08,  2.86s/it] 76%|███████▌  | 466/615 [23:21<07:00,  2.83s/it]                                                  76%|███████▌  | 466/615 [23:21<07:00,  2.83s/it] 76%|███████▌  | 467/615 [23:24<07:12,  2.92s/it]                                                  76%|███████▌  | 467/615 [23:24<07:12,  2.92s/it] 76%|███████▌  | 468/615 [23:27<06:59,  2.85s/it]                                                  76%|███████▌  | 468/615 [23:27<06:59,  2.85s/it] 76%|███████▋  | 469/615 [23:30<06:52,  2.83s/it]                                                  76%|███████▋  | 469/615 [23:30<06:52,  2.83s/it] 76%|███████▋  | 470/615 [23:33<06:53,  2.85s/it]                                                  76%|███████▋  | 470/615 [23:33<06:53,  2.85s/it] 77%|███████▋  | 471/615 [23:36<07:20,  3.06s/it]                                                  77%|███████▋  | 471/615 [23:36<07:20,  3.06s/it] 77%|███████▋  | 472/615 [23:39<07:29,  3.15s/it]                                                  77%|███████▋  | 472/615 [23:39<07:29,  3.15s/it] 77%|███████▋  | 473/615 [23:43<07:48,  3.30s/it]                                                  77%|███████▋  | 473/615 [23:43<07:48,  3.30s/it] 77%|███████▋  | 474/615 [23:46<07:19,  3.12s/it]                                                  77%|███████▋  | 474/615 [23:46<07:19,  3.12s/it] 77%|███████▋  | 475/615 [23:49<07:02,  3.02s/it]                                                  77%|███████▋  | 475/615 [23:49<07:02,  3.02s/it] 77%|███████▋  | 476/615 [23:51<06:50,  2.95s/it]                                                  77%|███████▋  | 476/615 [23:51<06:50,  2.95s/it] 78%|███████▊  | 477/615 [23:54<06:39,  2.90s/it]                                                  78%|███████▊  | 477/615 [23:54<06:39,  2.90s/it] 78%|███████▊  | 478/615 [23:57<06:30,  2.85s/it]                                                  78%|███████▊  | 478/615 [23:57<06:30,  2.85s/it] 78%|███████▊  | 479/615 [24:00<06:22,  2.81s/it]                                                  78%|███████▊  | 479/615 [24:00<06:22,  2.81s/it] 78%|███████▊  | 480/615 [24:02<06:18,  2.80s/it]                                                  78%|███████▊  | 480/615 [24:02<06:18,  2.80s/it] 78%|███████▊  | 481/615 [24:05<06:11,  2.77s/it]                                                  78%|███████▊  | 481/615 [24:05<06:11,  2.77s/it] 78%|███████▊  | 482/615 [24:08<06:20,  2.86s/it]                                                  78%|███████▊  | 482/615 [24:08<06:20,  2.86s/it] 79%|███████▊  | 483/615 [24:11<06:09,  2.80s/it]                                                  79%|███████▊  | 483/615 [24:11<06:09,  2.80s/it] 79%|███████▊  | 484/615 [24:13<05:59,  2.74s/it]                                                  79%|███████▊  | 484/615 [24:13<05:59,  2.74s/it] 79%|███████▉  | 485/615 [24:16<05:51,  2.71s/it]                                                  79%|███████▉  | 485/615 [24:16<05:51,  2.71s/it] 79%|███████▉  | 486/615 [24:19<05:42,  2.66s/it]                                                  79%|███████▉  | 486/615 [24:19<05:42,  2.66s/it] 79%|███████▉  | 487/615 [24:21<05:39,  2.65s/it]                                                  79%|███████▉  | 487/615 [24:21<05:39,  2.65s/it] 79%|███████▉  | 488/615 [24:24<05:37,  2.66s/it]                                                  79%|███████▉  | 488/615 [24:24<05:37,  2.66s/it] 80%|███████▉  | 489/615 [24:26<05:33,  2.65s/it]                                                  80%|███████▉  | 489/615 [24:26<05:33,  2.65s/it] 80%|███████▉  | 490/615 [24:29<05:29,  2.64s/it]                                                  80%|███████▉  | 490/615 [24:29<05:29,  2.64s/it] 80%|███████▉  | 491/615 [24:32<05:24,  2.62s/it]                                                  80%|███████▉  | 491/615 [24:32<05:24,  2.62s/it] 80%|████████  | 492/615 [24:34<05:23,  2.63s/it]                                                  80%|████████  | 492/615 [24:34<05:23,  2.63s/it] 80%|████████  | 493/615 [24:37<05:21,  2.64s/it]                                                  80%|████████  | 493/615 [24:37<05:21,  2.64s/it] 80%|████████  | 494/615 [24:40<05:42,  2.83s/it]                                                  80%|████████  | 494/615 [24:40<05:42,  2.83s/it] 80%|████████  | 495/615 [24:43<05:27,  2.73s/it]                                                  80%|████████  | 495/615 [24:43<05:27,  2.73s/it] 81%|████████  | 496/615 [24:45<05:23,  2.72s/it]                                                  81%|████████  | 496/615 [24:45<05:23,  2.72s/it] 81%|████████  | 497/615 [24:49<05:58,  3.04s/it]                                                  81%|████████  | 497/615 [24:49<05:58,  3.04s/it] 81%|████████  | 498/615 [24:52<05:49,  2.99s/it]                                                  81%|████████  | 498/615 [24:52<05:49,  2.99s/it] 81%|████████  | 499/615 [24:55<05:38,  2.92s/it]                                                  81%|████████  | 499/615 [24:55<05:38,  2.92s/it] 81%|████████▏ | 500/615 [24:58<05:53,  3.07s/it]                                                  81%|████████▏ | 500/615 [24:58<05:53,  3.07s/it] 81%|████████▏ | 501/615 [25:01<05:36,  2.95s/it]                                                  81%|████████▏ | 501/615 [25:01<05:36,  2.95s/it] 82%|████████▏ | 502/615 [25:04<05:37,  2.99s/it]                                                  82%|████████▏ | 502/615 [25:04<05:37,  2.99s/it] 82%|████████▏ | 503/615 [25:07<05:41,  3.05s/it]                                                  82%|████████▏ | 503/615 [25:07<05:41,  3.05s/it] 82%|████████▏ | 504/615 [25:11<05:55,  3.20s/it]                                                  82%|████████▏ | 504/615 [25:11<05:55,  3.20s/it] 82%|████████▏ | 505/615 [25:14<05:57,  3.25s/it]                                                  82%|████████▏ | 505/615 [25:14<05:57,  3.25s/it] 82%|████████▏ | 506/615 [25:17<05:41,  3.13s/it]                                                  82%|████████▏ | 506/615 [25:17<05:41,  3.13s/it] 82%|████████▏ | 507/615 [25:20<05:22,  2.99s/it]                                                  82%|████████▏ | 507/615 [25:20<05:22,  2.99s/it] 83%|████████▎ | 508/615 [25:22<05:11,  2.91s/it]                                                  83%|████████▎ | 508/615 [25:22<05:11,  2.91s/it] 83%|████████▎ | 509/615 [25:25<05:02,  2.86s/it]                                                  83%|████████▎ | 509/615 [25:25<05:02,  2.86s/it] 83%|████████▎ | 510/615 [25:28<05:02,  2.89s/it]                                                  83%|████████▎ | 510/615 [25:28<05:02,  2.89s/it] 83%|████████▎ | 511/615 [25:31<05:15,  3.03s/it]                                                  83%|████████▎ | 511/615 [25:31<05:15,  3.03s/it] 83%|████████▎ | 512/615 [25:35<05:26,  3.17s/it]                                                  83%|████████▎ | 512/615 [25:35<05:26,  3.17s/it] 83%|████████▎ | 513/615 [25:38<05:11,  3.05s/it]                                                  83%|████████▎ | 513/615 [25:38<05:11,  3.05s/it] 84%|████████▎ | 514/615 [25:41<05:02,  3.00s/it]                                                  84%|████████▎ | 514/615 [25:41<05:02,  3.00s/it] 84%|████████▎ | 515/615 [25:44<05:11,  3.11s/it]                                                  84%|████████▎ | 515/615 [25:44<05:11,  3.11s/it] 84%|████████▍ | 516/615 [25:47<04:56,  3.00s/it]                                                  84%|████████▍ | 516/615 [25:47<04:56,  3.00s/it] 84%|████████▍ | 517/615 [25:49<04:43,  2.89s/it]                                                  84%|████████▍ | 517/615 [25:49<04:43,  2.89s/it] 84%|████████▍ | 518/615 [25:52<04:35,  2.84s/it]                                                  84%|████████▍ | 518/615 [25:52<04:35,  2.84s/it] 84%|████████▍ | 519/615 [25:55<04:26,  2.78s/it]                                                  84%|████████▍ | 519/615 [25:55<04:26,  2.78s/it] 85%|████████▍ | 520/615 [25:57<04:21,  2.76s/it]                                                  85%|████████▍ | 520/615 [25:57<04:21,  2.76s/it] 85%|████████▍ | 521/615 [26:00<04:16,  2.73s/it]                                                  85%|████████▍ | 521/615 [26:00<04:16,  2.73s/it] 85%|████████▍ | 522/615 [26:03<04:13,  2.73s/it]                                                  85%|████████▍ | 522/615 [26:03<04:13,  2.73s/it] 85%|████████▌ | 523/615 [26:06<04:12,  2.74s/it]                                                  85%|████████▌ | 523/615 [26:06<04:12,  2.74s/it] 85%|████████▌ | 524/615 [26:08<04:11,  2.76s/it]                                                  85%|████████▌ | 524/615 [26:08<04:11,  2.76s/it] 85%|████████▌ | 525/615 [26:11<04:08,  2.77s/it]                                                  85%|████████▌ | 525/615 [26:11<04:08,  2.77s/it] 86%|████████▌ | 526/615 [26:14<04:02,  2.73s/it]                                                  86%|████████▌ | 526/615 [26:14<04:02,  2.73s/it] 86%|████████▌ | 527/615 [26:17<04:13,  2.88s/it]                                                  86%|████████▌ | 527/615 [26:17<04:13,  2.88s/it] 86%|████████▌ | 528/615 [26:20<04:05,  2.82s/it]                                                  86%|████████▌ | 528/615 [26:20<04:05,  2.82s/it] 86%|████████▌ | 529/615 [26:22<03:57,  2.76s/it]                                                  86%|████████▌ | 529/615 [26:22<03:57,  2.76s/it] 86%|████████▌ | 530/615 [26:25<03:58,  2.80s/it]                                                  86%|████████▌ | 530/615 [26:25<03:58,  2.80s/it] 86%|████████▋ | 531/615 [26:28<04:06,  2.93s/it]                                                  86%|████████▋ | 531/615 [26:28<04:06,  2.93s/it] 87%|████████▋ | 532/615 [26:31<04:02,  2.93s/it]                                                  87%|████████▋ | 532/615 [26:31<04:02,  2.93s/it] 87%|████████▋ | 533/615 [26:34<03:55,  2.87s/it]                                                  87%|████████▋ | 533/615 [26:34<03:55,  2.87s/it] 87%|████████▋ | 534/615 [26:37<03:48,  2.82s/it]                                                  87%|████████▋ | 534/615 [26:37<03:48,  2.82s/it] 87%|████████▋ | 535/615 [26:40<03:45,  2.82s/it]                                                  87%|████████▋ | 535/615 [26:40<03:45,  2.82s/it] 87%|████████▋ | 536/615 [26:43<03:50,  2.92s/it]                                                  87%|████████▋ | 536/615 [26:43<03:50,  2.92s/it] 87%|████████▋ | 537/615 [26:46<03:44,  2.87s/it]                                                  87%|████████▋ | 537/615 [26:46<03:44,  2.87s/it] 87%|████████▋ | 538/615 [26:50<04:12,  3.28s/it]                                                  87%|████████▋ | 538/615 [26:50<04:12,  3.28s/it] 88%|████████▊ | 539/615 [26:53<04:04,  3.22s/it]                                                  88%|████████▊ | 539/615 [26:53<04:04,  3.22s/it] 88%|████████▊ | 540/615 [26:56<03:52,  3.10s/it]                                                  88%|████████▊ | 540/615 [26:56<03:52,  3.10s/it] 88%|████████▊ | 541/615 [26:58<03:41,  2.99s/it]                                                  88%|████████▊ | 541/615 [26:58<03:41,  2.99s/it] 88%|████████▊ | 542/615 [27:01<03:32,  2.92s/it]                                                  88%|████████▊ | 542/615 [27:01<03:32,  2.92s/it] 88%|████████▊ | 543/615 [27:04<03:25,  2.86s/it]                                                  88%|████████▊ | 543/615 [27:04<03:25,  2.86s/it] 88%|████████▊ | 544/615 [27:07<03:20,  2.82s/it]                                                  88%|████████▊ | 544/615 [27:07<03:20,  2.82s/it] 89%|████████▊ | 545/615 [27:09<03:15,  2.79s/it]                                                  89%|████████▊ | 545/615 [27:09<03:15,  2.79s/it] 89%|████████▉ | 546/615 [27:12<03:11,  2.77s/it]                                                  89%|████████▉ | 546/615 [27:12<03:11,  2.77s/it] 89%|████████▉ | 547/615 [27:15<03:08,  2.77s/it]                                                  89%|████████▉ | 547/615 [27:15<03:08,  2.77s/it] 89%|████████▉ | 548/615 [27:17<03:03,  2.73s/it]                                                  89%|████████▉ | 548/615 [27:17<03:03,  2.73s/it] 89%|████████▉ | 549/615 [27:21<03:11,  2.90s/it]                                                  89%|████████▉ | 549/615 [27:21<03:11,  2.90s/it] 89%|████████▉ | 550/615 [27:23<03:02,  2.81s/it]                                                  89%|████████▉ | 550/615 [27:23<03:02,  2.81s/it] 90%|████████▉ | 551/615 [27:26<02:59,  2.81s/it]                                                  90%|████████▉ | 551/615 [27:26<02:59,  2.81s/it] 90%|████████▉ | 552/615 [27:29<02:57,  2.82s/it]                                                  90%|████████▉ | 552/615 [27:29<02:57,  2.82s/it] 90%|████████▉ | 553/615 [27:32<02:51,  2.76s/it]                                                  90%|████████▉ | 553/615 [27:32<02:51,  2.76s/it] 90%|█████████ | 554/615 [27:34<02:44,  2.70s/it]                                                  90%|█████████ | 554/615 [27:34<02:44,  2.70s/it] 90%|█████████ | 555/615 [27:37<02:39,  2.66s/it]                                                  90%|█████████ | 555/615 [27:37<02:39,  2.66s/it] 90%|█████████ | 556/615 [27:40<02:39,  2.70s/it]                                                  90%|█████████ | 556/615 [27:40<02:39,  2.70s/it] 91%|█████████ | 557/615 [27:42<02:35,  2.69s/it]                                                  91%|█████████ | 557/615 [27:42<02:35,  2.69s/it] 91%|█████████ | 558/615 [27:45<02:33,  2.69s/it]                                                  91%|█████████ | 558/615 [27:45<02:33,  2.69s/it] 91%|█████████ | 559/615 [27:47<02:28,  2.65s/it]                                                  91%|█████████ | 559/615 [27:47<02:28,  2.65s/it] 91%|█████████ | 560/615 [27:50<02:25,  2.65s/it]                                                  91%|█████████ | 560/615 [27:50<02:25,  2.65s/it] 91%|█████████ | 561/615 [27:53<02:33,  2.84s/it]                                                  91%|█████████ | 561/615 [27:53<02:33,  2.84s/it] 91%|█████████▏| 562/615 [27:56<02:27,  2.77s/it]                                                  91%|█████████▏| 562/615 [27:56<02:27,  2.77s/it] 92%|█████████▏| 563/615 [27:59<02:21,  2.73s/it]                                                  92%|█████████▏| 563/615 [27:59<02:21,  2.73s/it] 92%|█████████▏| 564/615 [28:01<02:17,  2.69s/it]                                                  92%|█████████▏| 564/615 [28:01<02:17,  2.69s/it] 92%|█████████▏| 565/615 [28:04<02:12,  2.65s/it]                                                  92%|█████████▏| 565/615 [28:04<02:12,  2.65s/it] 92%|█████████▏| 566/615 [28:06<02:08,  2.62s/it]                                                  92%|█████████▏| 566/615 [28:06<02:08,  2.62s/it] 92%|█████████▏| 567/615 [28:09<02:05,  2.62s/it]                                                  92%|█████████▏| 567/615 [28:09<02:05,  2.62s/it] 92%|█████████▏| 568/615 [28:12<02:03,  2.63s/it]                                                  92%|█████████▏| 568/615 [28:12<02:03,  2.63s/it] 93%|█████████▎| 569/615 [28:14<01:59,  2.59s/it]                                                  93%|█████████▎| 569/615 [28:14<01:59,  2.59s/it] 93%|█████████▎| 570/615 [28:17<01:56,  2.59s/it]                                                  93%|█████████▎| 570/615 [28:17<01:56,  2.59s/it] 93%|█████████▎| 571/615 [28:19<01:53,  2.58s/it]                                                  93%|█████████▎| 571/615 [28:19<01:53,  2.58s/it] 93%|█████████▎| 572/615 [28:22<01:49,  2.55s/it]                                                  93%|█████████▎| 572/615 [28:22<01:49,  2.55s/it] 93%|█████████▎| 573/615 [28:25<01:56,  2.77s/it]                                                  93%|█████████▎| 573/615 [28:25<01:56,  2.77s/it] 93%|█████████▎| 574/615 [28:28<01:51,  2.72s/it]                                                  93%|█████████▎| 574/615 [28:28<01:51,  2.72s/it] 93%|█████████▎| 575/615 [28:30<01:47,  2.69s/it]                                                  93%|█████████▎| 575/615 [28:30<01:47,  2.69s/it] 94%|█████████▎| 576/615 [28:33<01:43,  2.66s/it]                                                  94%|█████████▎| 576/615 [28:33<01:43,  2.66s/it] 94%|█████████▍| 577/615 [28:35<01:40,  2.66s/it]                                                  94%|█████████▍| 577/615 [28:35<01:40,  2.66s/it] 94%|█████████▍| 578/615 [28:38<01:38,  2.66s/it]                                                  94%|█████████▍| 578/615 [28:38<01:38,  2.66s/it] 94%|█████████▍| 579/615 [28:41<01:35,  2.67s/it]                                                  94%|█████████▍| 579/615 [28:41<01:35,  2.67s/it] 94%|█████████▍| 580/615 [28:43<01:32,  2.63s/it]                                                  94%|█████████▍| 580/615 [28:43<01:32,  2.63s/it] 94%|█████████▍| 581/615 [28:46<01:29,  2.63s/it]                                                  94%|█████████▍| 581/615 [28:46<01:29,  2.63s/it] 95%|█████████▍| 582/615 [28:50<01:41,  3.08s/it]                                                  95%|█████████▍| 582/615 [28:50<01:41,  3.08s/it] 95%|█████████▍| 583/615 [28:53<01:33,  2.92s/it]                                                  95%|█████████▍| 583/615 [28:53<01:33,  2.92s/it] 95%|█████████▍| 584/615 [28:55<01:27,  2.83s/it]                                                  95%|█████████▍| 584/615 [28:55<01:27,  2.83s/it] 95%|█████████▌| 585/615 [28:59<01:28,  2.94s/it]                                                  95%|█████████▌| 585/615 [28:59<01:28,  2.94s/it] 95%|█████████▌| 586/615 [29:01<01:23,  2.87s/it]                                                  95%|█████████▌| 586/615 [29:01<01:23,  2.87s/it] 95%|█████████▌| 587/615 [29:04<01:17,  2.77s/it]                                                  95%|█████████▌| 587/615 [29:04<01:17,  2.77s/it] 96%|█████████▌| 588/615 [29:06<01:13,  2.71s/it]                                                  96%|█████████▌| 588/615 [29:06<01:13,  2.71s/it] 96%|█████████▌| 589/615 [29:09<01:09,  2.67s/it]                                                  96%|█████████▌| 589/615 [29:09<01:09,  2.67s/it] 96%|█████████▌| 590/615 [29:11<01:05,  2.63s/it]                                                  96%|█████████▌| 590/615 [29:11<01:05,  2.63s/it] 96%|█████████▌| 591/615 [29:14<01:03,  2.64s/it]                                                  96%|█████████▌| 591/615 [29:14<01:03,  2.64s/it] 96%|█████████▋| 592/615 [29:17<00:59,  2.60s/it]                                                  96%|█████████▋| 592/615 [29:17<00:59,  2.60s/it] 96%|█████████▋| 593/615 [29:19<00:56,  2.58s/it]                                                  96%|█████████▋| 593/615 [29:19<00:56,  2.58s/it] 97%|█████████▋| 594/615 [29:22<00:53,  2.57s/it]                                                  97%|█████████▋| 594/615 [29:22<00:53,  2.57s/it] 97%|█████████▋| 595/615 [29:24<00:51,  2.58s/it]                                                  97%|█████████▋| 595/615 [29:24<00:51,  2.58s/it] 97%|█████████▋| 596/615 [29:27<00:49,  2.59s/it]                                                  97%|█████████▋| 596/615 [29:27<00:49,  2.59s/it] 97%|█████████▋| 597/615 [29:30<00:50,  2.82s/it]                                                  97%|█████████▋| 597/615 [29:30<00:50,  2.82s/it] 97%|█████████▋| 598/615 [29:33<00:46,  2.75s/it]                                                  97%|█████████▋| 598/615 [29:33<00:46,  2.75s/it] 97%|█████████▋| 599/615 [29:35<00:42,  2.69s/it]                                                  97%|█████████▋| 599/615 [29:35<00:42,  2.69s/it] 98%|█████████▊| 600/615 [29:38<00:40,  2.68s/it]                                                  98%|█████████▊| 600/615 [29:38<00:40,  2.68s/it] 98%|█████████▊| 601/615 [29:41<00:37,  2.66s/it]                                                  98%|█████████▊| 601/615 [29:41<00:37,  2.66s/it] 98%|█████████▊| 602/615 [29:43<00:34,  2.64s/it]                                                  98%|█████████▊| 602/615 [29:43<00:34,  2.64s/it] 98%|█████████▊| 603/615 [29:46<00:31,  2.64s/it]                                                  98%|█████████▊| 603/615 [29:46<00:31,  2.64s/it] 98%|█████████▊| 604/615 [29:48<00:28,  2.61s/it]                                                  98%|█████████▊| 604/615 [29:48<00:28,  2.61s/it] 98%|█████████▊| 605/615 [29:51<00:26,  2.61s/it]                                                  98%|█████████▊| 605/615 [29:51<00:26,  2.61s/it] 99%|█████████▊| 606/615 [29:54<00:23,  2.60s/it]                                                  99%|█████████▊| 606/615 [29:54<00:23,  2.60s/it] 99%|█████████▊| 607/615 [29:56<00:20,  2.62s/it]                                                  99%|█████████▊| 607/615 [29:56<00:20,  2.62s/it] 99%|█████████▉| 608/615 [29:59<00:18,  2.59s/it]                                                  99%|█████████▉| 608/615 [29:59<00:18,  2.59s/it] 99%|█████████▉| 609/615 [30:02<00:16,  2.76s/it]                                                  99%|█████████▉| 609/615 [30:02<00:16,  2.76s/it] 99%|█████████▉| 610/615 [30:05<00:13,  2.73s/it]                                                  99%|█████████▉| 610/615 [30:05<00:13,  2.73s/it] 99%|█████████▉| 611/615 [30:07<00:10,  2.67s/it]                                                  99%|█████████▉| 611/615 [30:07<00:10,  2.67s/it]100%|█████████▉| 612/615 [30:09<00:07,  2.48s/it]                                                 100%|█████████▉| 612/615 [30:09<00:07,  2.48s/it]100%|█████████▉| 613/615 [30:11<00:04,  2.33s/it]                                                 100%|█████████▉| 613/615 [30:11<00:04,  2.33s/it]100%|█████████▉| 614/615 [30:13<00:02,  2.22s/it]                                                 100%|█████████▉| 614/615 [30:13<00:02,  2.22s/it]100%|██████████| 615/615 [30:16<00:00,  2.38s/it]                                                 100%|██████████| 615/615 [30:16<00:00,  2.38s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
                                                 100%|██████████| 615/615 [30:43<00:00,  2.38s/it]100%|██████████| 615/615 [30:43<00:00,  3.00s/it]
wandb: - 0.016 MB of 0.016 MB uploadedwandb: \ 0.016 MB of 0.016 MB uploadedwandb: | 0.016 MB of 0.016 MB uploadedwandb: / 0.016 MB of 0.016 MB uploadedwandb: - 0.016 MB of 0.016 MB uploadedwandb: \ 0.044 MB of 0.095 MB uploaded (0.003 MB deduped)wandb: | 0.106 MB of 0.106 MB uploaded (0.003 MB deduped)wandb: / 0.106 MB of 0.106 MB uploaded (0.003 MB deduped)wandb: 
wandb: Run history:
wandb:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train/learning_rate ▄▇██████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁
wandb:                     train/loss ▄▃▄▆▃▂▅█▃▃▂▁▄▅▃██▄▄▅▃▅▃▆▁▂▄▅▇▁▅█▄▅▂▃▆▇▃▇
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                    train/epoch 3.0
wandb:              train/global_step 615
wandb:            train/learning_rate 0.0
wandb:                     train/loss 3.4506
wandb:               train/total_flos 9984186206126080.0
wandb:               train/train_loss 3.37869
wandb:            train/train_runtime 1851.6381
wandb: train/train_samples_per_second 15.935
wandb:   train/train_steps_per_second 0.332
wandb: 
wandb: 🚀 View run tiny-llava-base-pretrain-scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_SG2/checkpoint-2196-siglip-so400m-patch14-384 at: https://wandb.ai/llavamed/huggingface/runs/ao6phsem
wandb: ️⚡ View job at https://wandb.ai/llavamed/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1MjEyNzg1Ng==/version_details/v4
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240331_141614-ao6phsem/logs
