Unloading module 'code-server/4.9.1'
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.81s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:21<00:21, 21.87s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.47s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:23<00:23, 23.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 10.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 11.79s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_Norm_SG2_FULL/checkpoint-1326 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 10.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:23<00:00, 11.80s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_Norm_SG2_FULL/checkpoint-1326 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 10.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.10s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_Norm_SG2_FULL/checkpoint-1326 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 10.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.81s/it]
Some weights of the model checkpoint at /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_Norm_SG2_FULL/checkpoint-1326 were not used when initializing TinyLlavaLlamaForCausalLM: ['model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.bias', 'model.vision_tower.vision_tower.vision_model.embeddings.patch_embedding.weight', 'model.vision_tower.vision_tower.vision_model.embeddings.position_embedding.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.0.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.1.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.10.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.11.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.12.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.13.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.14.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.15.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.16.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.17.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.18.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.19.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.2.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.20.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.21.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.22.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.23.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.24.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.25.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.3.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.4.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.5.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.6.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.7.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.8.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.layer_norm2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc1.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.mlp.fc2.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.k_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.out_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.q_proj.weight', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.bias', 'model.vision_tower.vision_tower.vision_model.encoder.layers.9.self_attn.v_proj.weight', 'model.vision_tower.vision_tower.vision_model.post_layernorm.bias', 'model.vision_tower.vision_tower.vision_model.post_layernorm.weight']
- This IS expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TinyLlavaLlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
WARNING:root:Loading data...
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:root:Formatting inputs...Skip in lazy mode
WARNING:root:Loading data...
WARNING:root:Formatting inputs...Skip in lazy mode
WARNING:root:Loading data...
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
WARNING:root:Formatting inputs...Skip in lazy mode
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
wandb: Currently logged in as: ltl2113 (llavamed). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /scratch/ltl2113/LLaVA-Med/TinyLLaVABench/wandb/run-20240407_044936-2suw1crz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tiny-llava-base-pretrain-scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_Norm_SG2_FULL/checkpoint-1326-siglip-so400m-patch14-384
wandb: ⭐️ View project at https://wandb.ai/llavamed/huggingface
wandb: 🚀 View run at https://wandb.ai/llavamed/huggingface/runs/2suw1crz
  0%|          | 0/1140 [00:00<?, ?it/s]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/1140 [00:20<6:34:17, 20.77s/it]                                                    0%|          | 1/1140 [00:20<6:34:17, 20.77s/it]  0%|          | 2/1140 [00:24<3:19:20, 10.51s/it]                                                    0%|          | 2/1140 [00:24<3:19:20, 10.51s/it]  0%|          | 3/1140 [00:27<2:18:01,  7.28s/it]                                                    0%|          | 3/1140 [00:27<2:18:01,  7.28s/it]  0%|          | 4/1140 [00:30<1:47:49,  5.70s/it]                                                    0%|          | 4/1140 [00:30<1:47:49,  5.70s/it]  0%|          | 5/1140 [00:33<1:30:14,  4.77s/it]                                                    0%|          | 5/1140 [00:33<1:30:14,  4.77s/it]  1%|          | 6/1140 [00:37<1:19:31,  4.21s/it]                                                    1%|          | 6/1140 [00:37<1:19:31,  4.21s/it]  1%|          | 7/1140 [00:40<1:13:32,  3.89s/it]                                                    1%|          | 7/1140 [00:40<1:13:32,  3.89s/it]  1%|          | 8/1140 [00:43<1:09:34,  3.69s/it]                                                    1%|          | 8/1140 [00:43<1:09:34,  3.69s/it]  1%|          | 9/1140 [00:46<1:05:07,  3.46s/it]                                                    1%|          | 9/1140 [00:46<1:05:07,  3.46s/it]  1%|          | 10/1140 [00:49<1:02:44,  3.33s/it]                                                     1%|          | 10/1140 [00:49<1:02:44,  3.33s/it]  1%|          | 11/1140 [00:52<1:00:46,  3.23s/it]                                                     1%|          | 11/1140 [00:52<1:00:46,  3.23s/it]  1%|          | 12/1140 [00:56<1:02:21,  3.32s/it]                                                     1%|          | 12/1140 [00:56<1:02:21,  3.32s/it]  1%|          | 13/1140 [00:59<1:01:37,  3.28s/it]                                                     1%|          | 13/1140 [00:59<1:01:37,  3.28s/it]  1%|          | 14/1140 [01:02<1:01:37,  3.28s/it]                                                     1%|          | 14/1140 [01:02<1:01:37,  3.28s/it]  1%|▏         | 15/1140 [01:05<1:01:56,  3.30s/it]                                                     1%|▏         | 15/1140 [01:05<1:01:56,  3.30s/it]  1%|▏         | 16/1140 [01:09<1:01:18,  3.27s/it]                                                     1%|▏         | 16/1140 [01:09<1:01:18,  3.27s/it]  1%|▏         | 17/1140 [01:12<1:01:11,  3.27s/it]                                                     1%|▏         | 17/1140 [01:12<1:01:11,  3.27s/it]  2%|▏         | 18/1140 [01:15<1:01:15,  3.28s/it]                                                     2%|▏         | 18/1140 [01:15<1:01:15,  3.28s/it]  2%|▏         | 19/1140 [01:19<1:01:41,  3.30s/it]                                                     2%|▏         | 19/1140 [01:19<1:01:41,  3.30s/it]  2%|▏         | 20/1140 [01:22<1:02:21,  3.34s/it]                                                     2%|▏         | 20/1140 [01:22<1:02:21,  3.34s/it]  2%|▏         | 21/1140 [01:25<1:02:04,  3.33s/it]                                                     2%|▏         | 21/1140 [01:25<1:02:04,  3.33s/it]  2%|▏         | 22/1140 [01:29<1:01:39,  3.31s/it]                                                     2%|▏         | 22/1140 [01:29<1:01:39,  3.31s/it]  2%|▏         | 23/1140 [01:32<1:01:07,  3.28s/it]                                                     2%|▏         | 23/1140 [01:32<1:01:07,  3.28s/it]  2%|▏         | 24/1140 [01:35<1:00:44,  3.27s/it]                                                     2%|▏         | 24/1140 [01:35<1:00:44,  3.27s/it]  2%|▏         | 25/1140 [01:38<1:00:09,  3.24s/it]                                                     2%|▏         | 25/1140 [01:38<1:00:09,  3.24s/it]  2%|▏         | 26/1140 [01:41<58:40,  3.16s/it]                                                     2%|▏         | 26/1140 [01:41<58:40,  3.16s/it]  2%|▏         | 27/1140 [01:44<59:03,  3.18s/it]                                                   2%|▏         | 27/1140 [01:44<59:03,  3.18s/it]  2%|▏         | 28/1140 [01:48<59:51,  3.23s/it]                                                   2%|▏         | 28/1140 [01:48<59:51,  3.23s/it]  3%|▎         | 29/1140 [01:51<1:00:57,  3.29s/it]                                                     3%|▎         | 29/1140 [01:51<1:00:57,  3.29s/it]  3%|▎         | 30/1140 [01:54<1:00:57,  3.30s/it]                                                     3%|▎         | 30/1140 [01:54<1:00:57,  3.30s/it]  3%|▎         | 31/1140 [01:58<1:00:07,  3.25s/it]                                                     3%|▎         | 31/1140 [01:58<1:00:07,  3.25s/it]  3%|▎         | 32/1140 [02:01<59:55,  3.25s/it]                                                     3%|▎         | 32/1140 [02:01<59:55,  3.25s/it]  3%|▎         | 33/1140 [02:04<59:20,  3.22s/it]                                                   3%|▎         | 33/1140 [02:04<59:20,  3.22s/it]  3%|▎         | 34/1140 [02:07<58:32,  3.18s/it]                                                   3%|▎         | 34/1140 [02:07<58:32,  3.18s/it]  3%|▎         | 35/1140 [02:10<57:40,  3.13s/it]                                                   3%|▎         | 35/1140 [02:10<57:40,  3.13s/it]  3%|▎         | 36/1140 [02:13<56:58,  3.10s/it]                                                   3%|▎         | 36/1140 [02:13<56:58,  3.10s/it]  3%|▎         | 37/1140 [02:16<56:33,  3.08s/it]                                                   3%|▎         | 37/1140 [02:16<56:33,  3.08s/it]  3%|▎         | 38/1140 [02:19<56:04,  3.05s/it]                                                   3%|▎         | 38/1140 [02:19<56:04,  3.05s/it]  3%|▎         | 39/1140 [02:22<55:16,  3.01s/it]                                                   3%|▎         | 39/1140 [02:22<55:16,  3.01s/it]  4%|▎         | 40/1140 [02:25<55:02,  3.00s/it]                                                   4%|▎         | 40/1140 [02:25<55:02,  3.00s/it]  4%|▎         | 41/1140 [02:28<54:30,  2.98s/it]                                                   4%|▎         | 41/1140 [02:28<54:30,  2.98s/it]  4%|▎         | 42/1140 [02:31<55:19,  3.02s/it]                                                   4%|▎         | 42/1140 [02:31<55:19,  3.02s/it]  4%|▍         | 43/1140 [02:35<58:08,  3.18s/it]                                                   4%|▍         | 43/1140 [02:35<58:08,  3.18s/it]  4%|▍         | 44/1140 [02:38<58:34,  3.21s/it]                                                   4%|▍         | 44/1140 [02:38<58:34,  3.21s/it]  4%|▍         | 45/1140 [02:41<1:00:23,  3.31s/it]                                                     4%|▍         | 45/1140 [02:41<1:00:23,  3.31s/it]  4%|▍         | 46/1140 [02:45<59:47,  3.28s/it]                                                     4%|▍         | 46/1140 [02:45<59:47,  3.28s/it]  4%|▍         | 47/1140 [02:48<1:00:25,  3.32s/it]                                                     4%|▍         | 47/1140 [02:48<1:00:25,  3.32s/it]  4%|▍         | 48/1140 [02:51<1:00:41,  3.33s/it]                                                     4%|▍         | 48/1140 [02:51<1:00:41,  3.33s/it]  4%|▍         | 49/1140 [02:55<1:02:32,  3.44s/it]                                                     4%|▍         | 49/1140 [02:55<1:02:32,  3.44s/it]  4%|▍         | 50/1140 [02:58<1:01:50,  3.40s/it]                                                     4%|▍         | 50/1140 [02:58<1:01:50,  3.40s/it]  4%|▍         | 51/1140 [03:02<1:01:27,  3.39s/it]                                                     4%|▍         | 51/1140 [03:02<1:01:27,  3.39s/it]  5%|▍         | 52/1140 [03:05<1:00:52,  3.36s/it]                                                     5%|▍         | 52/1140 [03:05<1:00:52,  3.36s/it]  5%|▍         | 53/1140 [03:08<1:00:01,  3.31s/it]                                                     5%|▍         | 53/1140 [03:08<1:00:01,  3.31s/it]  5%|▍         | 54/1140 [03:11<58:28,  3.23s/it]                                                     5%|▍         | 54/1140 [03:11<58:28,  3.23s/it]  5%|▍         | 55/1140 [03:15<58:49,  3.25s/it]                                                   5%|▍         | 55/1140 [03:15<58:49,  3.25s/it]  5%|▍         | 56/1140 [03:18<59:15,  3.28s/it]                                                   5%|▍         | 56/1140 [03:18<59:15,  3.28s/it]  5%|▌         | 57/1140 [03:21<58:24,  3.24s/it]                                                   5%|▌         | 57/1140 [03:21<58:24,  3.24s/it]  5%|▌         | 58/1140 [03:24<57:57,  3.21s/it]                                                   5%|▌         | 58/1140 [03:24<57:57,  3.21s/it]  5%|▌         | 59/1140 [03:27<57:51,  3.21s/it]                                                   5%|▌         | 59/1140 [03:27<57:51,  3.21s/it]  5%|▌         | 60/1140 [03:31<57:33,  3.20s/it]                                                   5%|▌         | 60/1140 [03:31<57:33,  3.20s/it]  5%|▌         | 61/1140 [03:34<58:32,  3.26s/it]                                                   5%|▌         | 61/1140 [03:34<58:32,  3.26s/it]  5%|▌         | 62/1140 [03:37<59:08,  3.29s/it]                                                   5%|▌         | 62/1140 [03:37<59:08,  3.29s/it]  6%|▌         | 63/1140 [03:41<58:21,  3.25s/it]                                                   6%|▌         | 63/1140 [03:41<58:21,  3.25s/it]  6%|▌         | 64/1140 [03:44<58:19,  3.25s/it]                                                   6%|▌         | 64/1140 [03:44<58:19,  3.25s/it]  6%|▌         | 65/1140 [03:47<58:16,  3.25s/it]                                                   6%|▌         | 65/1140 [03:47<58:16,  3.25s/it]  6%|▌         | 66/1140 [03:50<57:31,  3.21s/it]                                                   6%|▌         | 66/1140 [03:50<57:31,  3.21s/it]  6%|▌         | 67/1140 [03:53<57:24,  3.21s/it]                                                   6%|▌         | 67/1140 [03:53<57:24,  3.21s/it]  6%|▌         | 68/1140 [03:57<58:22,  3.27s/it]                                                   6%|▌         | 68/1140 [03:57<58:22,  3.27s/it]  6%|▌         | 69/1140 [04:00<58:51,  3.30s/it]                                                   6%|▌         | 69/1140 [04:00<58:51,  3.30s/it]  6%|▌         | 70/1140 [04:03<58:18,  3.27s/it]                                                   6%|▌         | 70/1140 [04:03<58:18,  3.27s/it]  6%|▌         | 71/1140 [04:06<57:37,  3.23s/it]                                                   6%|▌         | 71/1140 [04:06<57:37,  3.23s/it]  6%|▋         | 72/1140 [04:10<57:15,  3.22s/it]                                                   6%|▋         | 72/1140 [04:10<57:15,  3.22s/it]  6%|▋         | 73/1140 [04:13<57:20,  3.22s/it]                                                   6%|▋         | 73/1140 [04:13<57:20,  3.22s/it]  6%|▋         | 74/1140 [04:15<51:36,  2.90s/it]                                                   6%|▋         | 74/1140 [04:15<51:36,  2.90s/it]  7%|▋         | 75/1140 [04:17<47:25,  2.67s/it]                                                   7%|▋         | 75/1140 [04:17<47:25,  2.67s/it]  7%|▋         | 76/1140 [04:19<44:37,  2.52s/it]                                                   7%|▋         | 76/1140 [04:19<44:37,  2.52s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  7%|▋         | 77/1140 [04:49<3:10:32, 10.75s/it]                                                     7%|▋         | 77/1140 [04:49<3:10:32, 10.75s/it]  7%|▋         | 78/1140 [04:53<2:32:14,  8.60s/it]                                                     7%|▋         | 78/1140 [04:53<2:32:14,  8.60s/it]  7%|▋         | 79/1140 [04:56<2:05:14,  7.08s/it]                                                     7%|▋         | 79/1140 [04:56<2:05:14,  7.08s/it]  7%|▋         | 80/1140 [05:00<1:44:50,  5.93s/it]                                                     7%|▋         | 80/1140 [05:00<1:44:50,  5.93s/it]  7%|▋         | 81/1140 [05:03<1:29:27,  5.07s/it]                                                     7%|▋         | 81/1140 [05:03<1:29:27,  5.07s/it]  7%|▋         | 82/1140 [05:06<1:19:15,  4.49s/it]                                                     7%|▋         | 82/1140 [05:06<1:19:15,  4.49s/it]  7%|▋         | 83/1140 [05:09<1:11:27,  4.06s/it]                                                     7%|▋         | 83/1140 [05:09<1:11:27,  4.06s/it]  7%|▋         | 84/1140 [05:12<1:06:04,  3.75s/it]                                                     7%|▋         | 84/1140 [05:12<1:06:04,  3.75s/it]  7%|▋         | 85/1140 [05:15<1:03:17,  3.60s/it]                                                     7%|▋         | 85/1140 [05:15<1:03:17,  3.60s/it]  8%|▊         | 86/1140 [05:18<59:56,  3.41s/it]                                                     8%|▊         | 86/1140 [05:18<59:56,  3.41s/it]  8%|▊         | 87/1140 [05:22<59:30,  3.39s/it]                                                   8%|▊         | 87/1140 [05:22<59:30,  3.39s/it]  8%|▊         | 88/1140 [05:25<58:48,  3.35s/it]                                                   8%|▊         | 88/1140 [05:25<58:48,  3.35s/it]  8%|▊         | 89/1140 [05:28<59:01,  3.37s/it]                                                   8%|▊         | 89/1140 [05:28<59:01,  3.37s/it]  8%|▊         | 90/1140 [05:32<59:15,  3.39s/it]                                                   8%|▊         | 90/1140 [05:32<59:15,  3.39s/it]  8%|▊         | 91/1140 [05:35<59:18,  3.39s/it]                                                   8%|▊         | 91/1140 [05:35<59:18,  3.39s/it]  8%|▊         | 92/1140 [05:38<58:04,  3.33s/it]                                                   8%|▊         | 92/1140 [05:38<58:04,  3.33s/it]  8%|▊         | 93/1140 [05:42<58:11,  3.33s/it]                                                   8%|▊         | 93/1140 [05:42<58:11,  3.33s/it]  8%|▊         | 94/1140 [05:45<58:02,  3.33s/it]                                                   8%|▊         | 94/1140 [05:45<58:02,  3.33s/it]  8%|▊         | 95/1140 [05:48<58:37,  3.37s/it]                                                   8%|▊         | 95/1140 [05:48<58:37,  3.37s/it]  8%|▊         | 96/1140 [05:52<57:52,  3.33s/it]                                                   8%|▊         | 96/1140 [05:52<57:52,  3.33s/it]  9%|▊         | 97/1140 [05:55<57:32,  3.31s/it]                                                   9%|▊         | 97/1140 [05:55<57:32,  3.31s/it]  9%|▊         | 98/1140 [05:58<56:25,  3.25s/it]                                                   9%|▊         | 98/1140 [05:58<56:25,  3.25s/it]  9%|▊         | 99/1140 [06:01<57:27,  3.31s/it]                                                   9%|▊         | 99/1140 [06:01<57:27,  3.31s/it]  9%|▉         | 100/1140 [06:05<57:08,  3.30s/it]                                                    9%|▉         | 100/1140 [06:05<57:08,  3.30s/it]  9%|▉         | 101/1140 [06:08<56:51,  3.28s/it]                                                    9%|▉         | 101/1140 [06:08<56:51,  3.28s/it]  9%|▉         | 102/1140 [06:11<56:44,  3.28s/it]                                                    9%|▉         | 102/1140 [06:11<56:44,  3.28s/it]  9%|▉         | 103/1140 [06:14<56:13,  3.25s/it]                                                    9%|▉         | 103/1140 [06:14<56:13,  3.25s/it]  9%|▉         | 104/1140 [06:18<56:15,  3.26s/it]                                                    9%|▉         | 104/1140 [06:18<56:15,  3.26s/it]  9%|▉         | 105/1140 [06:21<57:03,  3.31s/it]                                                    9%|▉         | 105/1140 [06:21<57:03,  3.31s/it]  9%|▉         | 106/1140 [06:24<56:47,  3.30s/it]                                                    9%|▉         | 106/1140 [06:24<56:47,  3.30s/it]  9%|▉         | 107/1140 [06:28<56:56,  3.31s/it]                                                    9%|▉         | 107/1140 [06:28<56:56,  3.31s/it]  9%|▉         | 108/1140 [06:31<57:33,  3.35s/it]                                                    9%|▉         | 108/1140 [06:31<57:33,  3.35s/it] 10%|▉         | 109/1140 [06:34<57:04,  3.32s/it]                                                   10%|▉         | 109/1140 [06:34<57:04,  3.32s/it] 10%|▉         | 110/1140 [06:38<57:39,  3.36s/it]                                                   10%|▉         | 110/1140 [06:38<57:39,  3.36s/it] 10%|▉         | 111/1140 [06:41<57:53,  3.38s/it]                                                   10%|▉         | 111/1140 [06:41<57:53,  3.38s/it] 10%|▉         | 112/1140 [06:45<57:20,  3.35s/it]                                                   10%|▉         | 112/1140 [06:45<57:20,  3.35s/it] 10%|▉         | 113/1140 [06:48<56:02,  3.27s/it]                                                   10%|▉         | 113/1140 [06:48<56:02,  3.27s/it] 10%|█         | 114/1140 [06:51<55:32,  3.25s/it]                                                   10%|█         | 114/1140 [06:51<55:32,  3.25s/it] 10%|█         | 115/1140 [06:55<58:39,  3.43s/it]                                                   10%|█         | 115/1140 [06:55<58:39,  3.43s/it] 10%|█         | 116/1140 [06:58<58:06,  3.41s/it]                                                   10%|█         | 116/1140 [06:58<58:06,  3.41s/it] 10%|█         | 117/1140 [07:01<57:02,  3.35s/it]                                                   10%|█         | 117/1140 [07:01<57:02,  3.35s/it] 10%|█         | 118/1140 [07:04<55:42,  3.27s/it]                                                   10%|█         | 118/1140 [07:04<55:42,  3.27s/it] 10%|█         | 119/1140 [07:08<55:40,  3.27s/it]                                                   10%|█         | 119/1140 [07:08<55:40,  3.27s/it] 11%|█         | 120/1140 [07:11<55:13,  3.25s/it]                                                   11%|█         | 120/1140 [07:11<55:13,  3.25s/it] 11%|█         | 121/1140 [07:14<55:43,  3.28s/it]                                                   11%|█         | 121/1140 [07:14<55:43,  3.28s/it] 11%|█         | 122/1140 [07:17<54:52,  3.23s/it]                                                   11%|█         | 122/1140 [07:17<54:52,  3.23s/it] 11%|█         | 123/1140 [07:20<53:59,  3.19s/it]                                                   11%|█         | 123/1140 [07:20<53:59,  3.19s/it] 11%|█         | 124/1140 [07:24<54:35,  3.22s/it]                                                   11%|█         | 124/1140 [07:24<54:35,  3.22s/it] 11%|█         | 125/1140 [07:27<54:53,  3.24s/it]                                                   11%|█         | 125/1140 [07:27<54:53,  3.24s/it] 11%|█         | 126/1140 [07:30<55:05,  3.26s/it]                                                   11%|█         | 126/1140 [07:30<55:05,  3.26s/it] 11%|█         | 127/1140 [07:34<55:02,  3.26s/it]                                                   11%|█         | 127/1140 [07:34<55:02,  3.26s/it] 11%|█         | 128/1140 [07:37<53:56,  3.20s/it]                                                   11%|█         | 128/1140 [07:37<53:56,  3.20s/it] 11%|█▏        | 129/1140 [07:40<53:32,  3.18s/it]                                                   11%|█▏        | 129/1140 [07:40<53:32,  3.18s/it] 11%|█▏        | 130/1140 [07:43<53:54,  3.20s/it]                                                   11%|█▏        | 130/1140 [07:43<53:54,  3.20s/it] 11%|█▏        | 131/1140 [07:46<54:09,  3.22s/it]                                                   11%|█▏        | 131/1140 [07:46<54:09,  3.22s/it] 12%|█▏        | 132/1140 [07:50<55:30,  3.30s/it]                                                   12%|█▏        | 132/1140 [07:50<55:30,  3.30s/it] 12%|█▏        | 133/1140 [07:53<54:59,  3.28s/it]                                                   12%|█▏        | 133/1140 [07:53<54:59,  3.28s/it] 12%|█▏        | 134/1140 [07:56<56:06,  3.35s/it]                                                   12%|█▏        | 134/1140 [07:56<56:06,  3.35s/it] 12%|█▏        | 135/1140 [08:00<54:56,  3.28s/it]                                                   12%|█▏        | 135/1140 [08:00<54:56,  3.28s/it] 12%|█▏        | 136/1140 [08:03<54:18,  3.25s/it]                                                   12%|█▏        | 136/1140 [08:03<54:18,  3.25s/it] 12%|█▏        | 137/1140 [08:06<52:58,  3.17s/it]                                                   12%|█▏        | 137/1140 [08:06<52:58,  3.17s/it] 12%|█▏        | 138/1140 [08:09<52:44,  3.16s/it]                                                   12%|█▏        | 138/1140 [08:09<52:44,  3.16s/it] 12%|█▏        | 139/1140 [08:12<53:54,  3.23s/it]                                                   12%|█▏        | 139/1140 [08:12<53:54,  3.23s/it] 12%|█▏        | 140/1140 [08:15<53:19,  3.20s/it]                                                   12%|█▏        | 140/1140 [08:15<53:19,  3.20s/it] 12%|█▏        | 141/1140 [08:19<53:23,  3.21s/it]                                                   12%|█▏        | 141/1140 [08:19<53:23,  3.21s/it] 12%|█▏        | 142/1140 [08:22<51:51,  3.12s/it]                                                   12%|█▏        | 142/1140 [08:22<51:51,  3.12s/it] 13%|█▎        | 143/1140 [08:25<51:50,  3.12s/it]                                                   13%|█▎        | 143/1140 [08:25<51:50,  3.12s/it] 13%|█▎        | 144/1140 [08:28<53:03,  3.20s/it]                                                   13%|█▎        | 144/1140 [08:28<53:03,  3.20s/it] 13%|█▎        | 145/1140 [08:31<52:53,  3.19s/it]                                                   13%|█▎        | 145/1140 [08:31<52:53,  3.19s/it] 13%|█▎        | 146/1140 [08:34<52:58,  3.20s/it]                                                   13%|█▎        | 146/1140 [08:34<52:58,  3.20s/it] 13%|█▎        | 147/1140 [08:38<52:55,  3.20s/it]                                                   13%|█▎        | 147/1140 [08:38<52:55,  3.20s/it] 13%|█▎        | 148/1140 [08:41<53:15,  3.22s/it]                                                   13%|█▎        | 148/1140 [08:41<53:15,  3.22s/it] 13%|█▎        | 149/1140 [08:44<52:18,  3.17s/it]                                                   13%|█▎        | 149/1140 [08:44<52:18,  3.17s/it] 13%|█▎        | 150/1140 [08:47<51:32,  3.12s/it]                                                   13%|█▎        | 150/1140 [08:47<51:32,  3.12s/it] 13%|█▎        | 151/1140 [08:49<48:10,  2.92s/it]                                                   13%|█▎        | 151/1140 [08:49<48:10,  2.92s/it] 13%|█▎        | 152/1140 [08:52<46:23,  2.82s/it]                                                   13%|█▎        | 152/1140 [08:52<46:23,  2.82s/it] 13%|█▎        | 153/1140 [08:55<45:36,  2.77s/it]                                                   13%|█▎        | 153/1140 [08:55<45:36,  2.77s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 14%|█▎        | 154/1140 [09:24<2:58:59, 10.89s/it]                                                     14%|█▎        | 154/1140 [09:24<2:58:59, 10.89s/it] 14%|█▎        | 155/1140 [09:28<2:21:19,  8.61s/it]                                                     14%|█▎        | 155/1140 [09:28<2:21:19,  8.61s/it] 14%|█▎        | 156/1140 [09:31<1:55:19,  7.03s/it]                                                     14%|█▎        | 156/1140 [09:31<1:55:19,  7.03s/it] 14%|█▍        | 157/1140 [09:34<1:35:49,  5.85s/it]                                                     14%|█▍        | 157/1140 [09:34<1:35:49,  5.85s/it] 14%|█▍        | 158/1140 [09:37<1:22:04,  5.02s/it]                                                     14%|█▍        | 158/1140 [09:37<1:22:04,  5.02s/it] 14%|█▍        | 159/1140 [09:40<1:13:06,  4.47s/it]                                                     14%|█▍        | 159/1140 [09:40<1:13:06,  4.47s/it] 14%|█▍        | 160/1140 [09:44<1:06:23,  4.06s/it]                                                     14%|█▍        | 160/1140 [09:44<1:06:23,  4.06s/it] 14%|█▍        | 161/1140 [09:47<1:02:16,  3.82s/it]                                                     14%|█▍        | 161/1140 [09:47<1:02:16,  3.82s/it] 14%|█▍        | 162/1140 [09:50<58:32,  3.59s/it]                                                     14%|█▍        | 162/1140 [09:50<58:32,  3.59s/it] 14%|█▍        | 163/1140 [09:53<57:23,  3.52s/it]                                                   14%|█▍        | 163/1140 [09:53<57:23,  3.52s/it] 14%|█▍        | 164/1140 [09:56<54:55,  3.38s/it]                                                   14%|█▍        | 164/1140 [09:56<54:55,  3.38s/it] 14%|█▍        | 165/1140 [09:59<53:32,  3.29s/it]                                                   14%|█▍        | 165/1140 [09:59<53:32,  3.29s/it] 15%|█▍        | 166/1140 [10:03<52:41,  3.25s/it]                                                   15%|█▍        | 166/1140 [10:03<52:41,  3.25s/it] 15%|█▍        | 167/1140 [10:06<53:04,  3.27s/it]                                                   15%|█▍        | 167/1140 [10:06<53:04,  3.27s/it] 15%|█▍        | 168/1140 [10:09<52:54,  3.27s/it]                                                   15%|█▍        | 168/1140 [10:09<52:54,  3.27s/it] 15%|█▍        | 169/1140 [10:12<52:47,  3.26s/it]                                                   15%|█▍        | 169/1140 [10:12<52:47,  3.26s/it] 15%|█▍        | 170/1140 [10:16<52:51,  3.27s/it]                                                   15%|█▍        | 170/1140 [10:16<52:51,  3.27s/it] 15%|█▌        | 171/1140 [10:19<51:50,  3.21s/it]                                                   15%|█▌        | 171/1140 [10:19<51:50,  3.21s/it] 15%|█▌        | 172/1140 [10:22<50:50,  3.15s/it]                                                   15%|█▌        | 172/1140 [10:22<50:50,  3.15s/it] 15%|█▌        | 173/1140 [10:25<50:12,  3.12s/it]                                                   15%|█▌        | 173/1140 [10:25<50:12,  3.12s/it] 15%|█▌        | 174/1140 [10:28<50:05,  3.11s/it]                                                   15%|█▌        | 174/1140 [10:28<50:05,  3.11s/it] 15%|█▌        | 175/1140 [10:31<50:14,  3.12s/it]                                                   15%|█▌        | 175/1140 [10:31<50:14,  3.12s/it] 15%|█▌        | 176/1140 [10:34<51:38,  3.21s/it]                                                   15%|█▌        | 176/1140 [10:34<51:38,  3.21s/it] 16%|█▌        | 177/1140 [10:38<51:46,  3.23s/it]                                                   16%|█▌        | 177/1140 [10:38<51:46,  3.23s/it] 16%|█▌        | 178/1140 [10:41<51:48,  3.23s/it]                                                   16%|█▌        | 178/1140 [10:41<51:48,  3.23s/it] 16%|█▌        | 179/1140 [10:44<53:16,  3.33s/it]                                                   16%|█▌        | 179/1140 [10:45<53:16,  3.33s/it] 16%|█▌        | 180/1140 [10:48<53:03,  3.32s/it]                                                   16%|█▌        | 180/1140 [10:48<53:03,  3.32s/it] 16%|█▌        | 181/1140 [10:51<53:58,  3.38s/it]                                                   16%|█▌        | 181/1140 [10:51<53:58,  3.38s/it] 16%|█▌        | 182/1140 [10:55<54:34,  3.42s/it]                                                   16%|█▌        | 182/1140 [10:55<54:34,  3.42s/it] 16%|█▌        | 183/1140 [10:58<54:20,  3.41s/it]                                                   16%|█▌        | 183/1140 [10:58<54:20,  3.41s/it] 16%|█▌        | 184/1140 [11:02<54:30,  3.42s/it]                                                   16%|█▌        | 184/1140 [11:02<54:30,  3.42s/it] 16%|█▌        | 185/1140 [11:05<52:59,  3.33s/it]                                                   16%|█▌        | 185/1140 [11:05<52:59,  3.33s/it] 16%|█▋        | 186/1140 [11:08<53:30,  3.37s/it]                                                   16%|█▋        | 186/1140 [11:08<53:30,  3.37s/it] 16%|█▋        | 187/1140 [11:12<54:05,  3.41s/it]                                                   16%|█▋        | 187/1140 [11:12<54:05,  3.41s/it] 16%|█▋        | 188/1140 [11:15<53:23,  3.36s/it]                                                   16%|█▋        | 188/1140 [11:15<53:23,  3.36s/it] 17%|█▋        | 189/1140 [11:18<53:56,  3.40s/it]                                                   17%|█▋        | 189/1140 [11:18<53:56,  3.40s/it] 17%|█▋        | 190/1140 [11:22<53:04,  3.35s/it]                                                   17%|█▋        | 190/1140 [11:22<53:04,  3.35s/it] 17%|█▋        | 191/1140 [11:25<52:53,  3.34s/it]                                                   17%|█▋        | 191/1140 [11:25<52:53,  3.34s/it] 17%|█▋        | 192/1140 [11:28<51:59,  3.29s/it]                                                   17%|█▋        | 192/1140 [11:28<51:59,  3.29s/it] 17%|█▋        | 193/1140 [11:31<51:00,  3.23s/it]                                                   17%|█▋        | 193/1140 [11:31<51:00,  3.23s/it] 17%|█▋        | 194/1140 [11:35<51:37,  3.27s/it]                                                   17%|█▋        | 194/1140 [11:35<51:37,  3.27s/it] 17%|█▋        | 195/1140 [11:38<52:20,  3.32s/it]                                                   17%|█▋        | 195/1140 [11:38<52:20,  3.32s/it] 17%|█▋        | 196/1140 [11:41<52:23,  3.33s/it]                                                   17%|█▋        | 196/1140 [11:41<52:23,  3.33s/it] 17%|█▋        | 197/1140 [11:45<51:16,  3.26s/it]                                                   17%|█▋        | 197/1140 [11:45<51:16,  3.26s/it] 17%|█▋        | 198/1140 [11:48<50:49,  3.24s/it]                                                   17%|█▋        | 198/1140 [11:48<50:49,  3.24s/it] 17%|█▋        | 199/1140 [11:51<49:26,  3.15s/it]                                                   17%|█▋        | 199/1140 [11:51<49:26,  3.15s/it] 18%|█▊        | 200/1140 [11:54<48:51,  3.12s/it]                                                   18%|█▊        | 200/1140 [11:54<48:51,  3.12s/it] 18%|█▊        | 201/1140 [11:57<48:03,  3.07s/it]                                                   18%|█▊        | 201/1140 [11:57<48:03,  3.07s/it] 18%|█▊        | 202/1140 [12:00<48:14,  3.09s/it]                                                   18%|█▊        | 202/1140 [12:00<48:14,  3.09s/it] 18%|█▊        | 203/1140 [12:03<47:26,  3.04s/it]                                                   18%|█▊        | 203/1140 [12:03<47:26,  3.04s/it] 18%|█▊        | 204/1140 [12:06<48:27,  3.11s/it]                                                   18%|█▊        | 204/1140 [12:06<48:27,  3.11s/it] 18%|█▊        | 205/1140 [12:09<49:02,  3.15s/it]                                                   18%|█▊        | 205/1140 [12:09<49:02,  3.15s/it] 18%|█▊        | 206/1140 [12:13<50:05,  3.22s/it]                                                   18%|█▊        | 206/1140 [12:13<50:05,  3.22s/it] 18%|█▊        | 207/1140 [12:16<51:38,  3.32s/it]                                                   18%|█▊        | 207/1140 [12:16<51:38,  3.32s/it] 18%|█▊        | 208/1140 [12:19<50:50,  3.27s/it]                                                   18%|█▊        | 208/1140 [12:19<50:50,  3.27s/it] 18%|█▊        | 209/1140 [12:23<51:06,  3.29s/it]                                                   18%|█▊        | 209/1140 [12:23<51:06,  3.29s/it] 18%|█▊        | 210/1140 [12:26<50:52,  3.28s/it]                                                   18%|█▊        | 210/1140 [12:26<50:52,  3.28s/it] 19%|█▊        | 211/1140 [12:29<50:39,  3.27s/it]                                                   19%|█▊        | 211/1140 [12:29<50:39,  3.27s/it] 19%|█▊        | 212/1140 [12:33<51:21,  3.32s/it]                                                   19%|█▊        | 212/1140 [12:33<51:21,  3.32s/it] 19%|█▊        | 213/1140 [12:36<50:28,  3.27s/it]                                                   19%|█▊        | 213/1140 [12:36<50:28,  3.27s/it] 19%|█▉        | 214/1140 [12:39<49:55,  3.23s/it]                                                   19%|█▉        | 214/1140 [12:39<49:55,  3.23s/it] 19%|█▉        | 215/1140 [12:42<51:00,  3.31s/it]                                                   19%|█▉        | 215/1140 [12:42<51:00,  3.31s/it] 19%|█▉        | 216/1140 [12:46<50:50,  3.30s/it]                                                   19%|█▉        | 216/1140 [12:46<50:50,  3.30s/it] 19%|█▉        | 217/1140 [12:49<49:40,  3.23s/it]                                                   19%|█▉        | 217/1140 [12:49<49:40,  3.23s/it] 19%|█▉        | 218/1140 [12:52<51:07,  3.33s/it]                                                   19%|█▉        | 218/1140 [12:52<51:07,  3.33s/it] 19%|█▉        | 219/1140 [12:56<52:25,  3.41s/it]                                                   19%|█▉        | 219/1140 [12:56<52:25,  3.41s/it] 19%|█▉        | 220/1140 [12:59<50:50,  3.32s/it]                                                   19%|█▉        | 220/1140 [12:59<50:50,  3.32s/it] 19%|█▉        | 221/1140 [13:02<49:42,  3.25s/it]                                                   19%|█▉        | 221/1140 [13:02<49:42,  3.25s/it] 19%|█▉        | 222/1140 [13:05<49:12,  3.22s/it]                                                   19%|█▉        | 222/1140 [13:05<49:12,  3.22s/it] 20%|█▉        | 223/1140 [13:09<49:45,  3.26s/it]                                                   20%|█▉        | 223/1140 [13:09<49:45,  3.26s/it] 20%|█▉        | 224/1140 [13:12<48:55,  3.20s/it]                                                   20%|█▉        | 224/1140 [13:12<48:55,  3.20s/it] 20%|█▉        | 225/1140 [13:15<49:54,  3.27s/it]                                                   20%|█▉        | 225/1140 [13:15<49:54,  3.27s/it] 20%|█▉        | 226/1140 [13:19<50:26,  3.31s/it]                                                   20%|█▉        | 226/1140 [13:19<50:26,  3.31s/it] 20%|█▉        | 227/1140 [13:22<49:41,  3.27s/it]                                                   20%|█▉        | 227/1140 [13:22<49:41,  3.27s/it] 20%|██        | 228/1140 [13:24<46:08,  3.04s/it]                                                   20%|██        | 228/1140 [13:24<46:08,  3.04s/it] 20%|██        | 229/1140 [13:27<44:25,  2.93s/it]                                                   20%|██        | 229/1140 [13:27<44:25,  2.93s/it] 20%|██        | 230/1140 [13:29<42:14,  2.78s/it]                                                   20%|██        | 230/1140 [13:29<42:14,  2.78s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 20%|██        | 231/1140 [14:01<2:55:19, 11.57s/it]                                                     20%|██        | 231/1140 [14:01<2:55:19, 11.57s/it] 20%|██        | 232/1140 [14:05<2:18:13,  9.13s/it]                                                     20%|██        | 232/1140 [14:05<2:18:13,  9.13s/it] 20%|██        | 233/1140 [14:08<1:52:00,  7.41s/it]                                                     20%|██        | 233/1140 [14:08<1:52:00,  7.41s/it] 21%|██        | 234/1140 [14:12<1:33:19,  6.18s/it]                                                     21%|██        | 234/1140 [14:12<1:33:19,  6.18s/it] 21%|██        | 235/1140 [14:15<1:20:26,  5.33s/it]                                                     21%|██        | 235/1140 [14:15<1:20:26,  5.33s/it] 21%|██        | 236/1140 [14:18<1:11:06,  4.72s/it]                                                     21%|██        | 236/1140 [14:18<1:11:06,  4.72s/it] 21%|██        | 237/1140 [14:21<1:03:59,  4.25s/it]                                                     21%|██        | 237/1140 [14:21<1:03:59,  4.25s/it] 21%|██        | 238/1140 [14:24<58:43,  3.91s/it]                                                     21%|██        | 238/1140 [14:24<58:43,  3.91s/it] 21%|██        | 239/1140 [14:28<56:17,  3.75s/it]                                                   21%|██        | 239/1140 [14:28<56:17,  3.75s/it] 21%|██        | 240/1140 [14:31<54:09,  3.61s/it]                                                   21%|██        | 240/1140 [14:31<54:09,  3.61s/it] 21%|██        | 241/1140 [14:34<52:15,  3.49s/it]                                                   21%|██        | 241/1140 [14:34<52:15,  3.49s/it] 21%|██        | 242/1140 [14:38<51:20,  3.43s/it]                                                   21%|██        | 242/1140 [14:38<51:20,  3.43s/it] 21%|██▏       | 243/1140 [14:41<50:52,  3.40s/it]                                                   21%|██▏       | 243/1140 [14:41<50:52,  3.40s/it] 21%|██▏       | 244/1140 [14:44<49:56,  3.34s/it]                                                   21%|██▏       | 244/1140 [14:44<49:56,  3.34s/it] 21%|██▏       | 245/1140 [14:47<48:54,  3.28s/it]                                                   21%|██▏       | 245/1140 [14:47<48:54,  3.28s/it] 22%|██▏       | 246/1140 [14:50<48:30,  3.26s/it]                                                   22%|██▏       | 246/1140 [14:50<48:30,  3.26s/it] 22%|██▏       | 247/1140 [14:54<49:50,  3.35s/it]                                                   22%|██▏       | 247/1140 [14:54<49:50,  3.35s/it] 22%|██▏       | 248/1140 [14:57<50:17,  3.38s/it]                                                   22%|██▏       | 248/1140 [14:57<50:17,  3.38s/it] 22%|██▏       | 249/1140 [15:01<50:33,  3.40s/it]                                                   22%|██▏       | 249/1140 [15:01<50:33,  3.40s/it] 22%|██▏       | 250/1140 [15:04<49:20,  3.33s/it]                                                   22%|██▏       | 250/1140 [15:04<49:20,  3.33s/it] 22%|██▏       | 251/1140 [15:07<48:05,  3.25s/it]                                                   22%|██▏       | 251/1140 [15:07<48:05,  3.25s/it] 22%|██▏       | 252/1140 [15:10<47:48,  3.23s/it]                                                   22%|██▏       | 252/1140 [15:10<47:48,  3.23s/it] 22%|██▏       | 253/1140 [15:14<48:26,  3.28s/it]                                                   22%|██▏       | 253/1140 [15:14<48:26,  3.28s/it] 22%|██▏       | 254/1140 [15:17<47:40,  3.23s/it]                                                   22%|██▏       | 254/1140 [15:17<47:40,  3.23s/it] 22%|██▏       | 255/1140 [15:20<48:11,  3.27s/it]                                                   22%|██▏       | 255/1140 [15:20<48:11,  3.27s/it] 22%|██▏       | 256/1140 [15:24<48:18,  3.28s/it]                                                   22%|██▏       | 256/1140 [15:24<48:18,  3.28s/it] 23%|██▎       | 257/1140 [15:27<47:52,  3.25s/it]                                                   23%|██▎       | 257/1140 [15:27<47:52,  3.25s/it] 23%|██▎       | 258/1140 [15:30<48:20,  3.29s/it]                                                   23%|██▎       | 258/1140 [15:30<48:20,  3.29s/it] 23%|██▎       | 259/1140 [15:33<47:55,  3.26s/it]                                                   23%|██▎       | 259/1140 [15:33<47:55,  3.26s/it] 23%|██▎       | 260/1140 [15:37<47:56,  3.27s/it]                                                   23%|██▎       | 260/1140 [15:37<47:56,  3.27s/it] 23%|██▎       | 261/1140 [15:40<48:14,  3.29s/it]                                                   23%|██▎       | 261/1140 [15:40<48:14,  3.29s/it] 23%|██▎       | 262/1140 [15:43<48:08,  3.29s/it]                                                   23%|██▎       | 262/1140 [15:43<48:08,  3.29s/it] 23%|██▎       | 263/1140 [15:47<48:24,  3.31s/it]                                                   23%|██▎       | 263/1140 [15:47<48:24,  3.31s/it] 23%|██▎       | 264/1140 [15:50<48:33,  3.33s/it]                                                   23%|██▎       | 264/1140 [15:50<48:33,  3.33s/it] 23%|██▎       | 265/1140 [15:53<48:06,  3.30s/it]                                                   23%|██▎       | 265/1140 [15:53<48:06,  3.30s/it] 23%|██▎       | 266/1140 [15:56<47:38,  3.27s/it]                                                   23%|██▎       | 266/1140 [15:56<47:38,  3.27s/it] 23%|██▎       | 267/1140 [16:00<48:13,  3.31s/it]                                                   23%|██▎       | 267/1140 [16:00<48:13,  3.31s/it] 24%|██▎       | 268/1140 [16:03<47:15,  3.25s/it]                                                   24%|██▎       | 268/1140 [16:03<47:15,  3.25s/it] 24%|██▎       | 269/1140 [16:06<47:21,  3.26s/it]                                                   24%|██▎       | 269/1140 [16:06<47:21,  3.26s/it] 24%|██▎       | 270/1140 [16:09<47:30,  3.28s/it]                                                   24%|██▎       | 270/1140 [16:09<47:30,  3.28s/it] 24%|██▍       | 271/1140 [16:13<47:10,  3.26s/it]                                                   24%|██▍       | 271/1140 [16:13<47:10,  3.26s/it] 24%|██▍       | 272/1140 [16:16<45:55,  3.17s/it]                                                   24%|██▍       | 272/1140 [16:16<45:55,  3.17s/it] 24%|██▍       | 273/1140 [16:19<46:07,  3.19s/it]                                                   24%|██▍       | 273/1140 [16:19<46:07,  3.19s/it] 24%|██▍       | 274/1140 [16:22<45:45,  3.17s/it]                                                   24%|██▍       | 274/1140 [16:22<45:45,  3.17s/it] 24%|██▍       | 275/1140 [16:25<47:02,  3.26s/it]                                                   24%|██▍       | 275/1140 [16:26<47:02,  3.26s/it] 24%|██▍       | 276/1140 [16:29<46:05,  3.20s/it]                                                   24%|██▍       | 276/1140 [16:29<46:05,  3.20s/it] 24%|██▍       | 277/1140 [16:32<46:46,  3.25s/it]                                                   24%|██▍       | 277/1140 [16:32<46:46,  3.25s/it] 24%|██▍       | 278/1140 [16:35<46:51,  3.26s/it]                                                   24%|██▍       | 278/1140 [16:35<46:51,  3.26s/it] 24%|██▍       | 279/1140 [16:38<46:21,  3.23s/it]                                                   24%|██▍       | 279/1140 [16:38<46:21,  3.23s/it] 25%|██▍       | 280/1140 [16:42<47:40,  3.33s/it]                                                   25%|██▍       | 280/1140 [16:42<47:40,  3.33s/it] 25%|██▍       | 281/1140 [16:45<47:47,  3.34s/it]                                                   25%|██▍       | 281/1140 [16:45<47:47,  3.34s/it] 25%|██▍       | 282/1140 [16:48<46:58,  3.28s/it]                                                   25%|██▍       | 282/1140 [16:48<46:58,  3.28s/it] 25%|██▍       | 283/1140 [16:52<46:29,  3.25s/it]                                                   25%|██▍       | 283/1140 [16:52<46:29,  3.25s/it] 25%|██▍       | 284/1140 [16:55<48:07,  3.37s/it]                                                   25%|██▍       | 284/1140 [16:55<48:07,  3.37s/it] 25%|██▌       | 285/1140 [16:59<48:25,  3.40s/it]                                                   25%|██▌       | 285/1140 [16:59<48:25,  3.40s/it] 25%|██▌       | 286/1140 [17:02<47:29,  3.34s/it]                                                   25%|██▌       | 286/1140 [17:02<47:29,  3.34s/it] 25%|██▌       | 287/1140 [17:05<47:54,  3.37s/it]                                                   25%|██▌       | 287/1140 [17:05<47:54,  3.37s/it] 25%|██▌       | 288/1140 [17:09<47:04,  3.32s/it]                                                   25%|██▌       | 288/1140 [17:09<47:04,  3.32s/it] 25%|██▌       | 289/1140 [17:12<46:39,  3.29s/it]                                                   25%|██▌       | 289/1140 [17:12<46:39,  3.29s/it] 25%|██▌       | 290/1140 [17:15<46:16,  3.27s/it]                                                   25%|██▌       | 290/1140 [17:15<46:16,  3.27s/it] 26%|██▌       | 291/1140 [17:19<47:30,  3.36s/it]                                                   26%|██▌       | 291/1140 [17:19<47:30,  3.36s/it] 26%|██▌       | 292/1140 [17:22<47:49,  3.38s/it]                                                   26%|██▌       | 292/1140 [17:22<47:49,  3.38s/it] 26%|██▌       | 293/1140 [17:25<47:35,  3.37s/it]                                                   26%|██▌       | 293/1140 [17:25<47:35,  3.37s/it] 26%|██▌       | 294/1140 [17:29<48:11,  3.42s/it]                                                   26%|██▌       | 294/1140 [17:29<48:11,  3.42s/it] 26%|██▌       | 295/1140 [17:32<47:28,  3.37s/it]                                                   26%|██▌       | 295/1140 [17:32<47:28,  3.37s/it] 26%|██▌       | 296/1140 [17:35<46:22,  3.30s/it]                                                   26%|██▌       | 296/1140 [17:35<46:22,  3.30s/it] 26%|██▌       | 297/1140 [17:39<46:11,  3.29s/it]                                                   26%|██▌       | 297/1140 [17:39<46:11,  3.29s/it] 26%|██▌       | 298/1140 [17:42<45:54,  3.27s/it]                                                   26%|██▌       | 298/1140 [17:42<45:54,  3.27s/it] 26%|██▌       | 299/1140 [17:45<45:53,  3.27s/it]                                                   26%|██▌       | 299/1140 [17:45<45:53,  3.27s/it] 26%|██▋       | 300/1140 [17:48<45:05,  3.22s/it]                                                   26%|██▋       | 300/1140 [17:48<45:05,  3.22s/it] 26%|██▋       | 301/1140 [17:52<45:49,  3.28s/it]                                                   26%|██▋       | 301/1140 [17:52<45:49,  3.28s/it] 26%|██▋       | 302/1140 [17:55<45:47,  3.28s/it]                                                   26%|██▋       | 302/1140 [17:55<45:47,  3.28s/it] 27%|██▋       | 303/1140 [17:58<45:45,  3.28s/it]                                                   27%|██▋       | 303/1140 [17:58<45:45,  3.28s/it] 27%|██▋       | 304/1140 [18:01<43:44,  3.14s/it]                                                   27%|██▋       | 304/1140 [18:01<43:44,  3.14s/it] 27%|██▋       | 305/1140 [18:03<39:34,  2.84s/it]                                                   27%|██▋       | 305/1140 [18:03<39:34,  2.84s/it] 27%|██▋       | 306/1140 [18:05<36:34,  2.63s/it]                                                   27%|██▋       | 306/1140 [18:05<36:34,  2.63s/it] 27%|██▋       | 307/1140 [18:07<34:31,  2.49s/it]                                                   27%|██▋       | 307/1140 [18:07<34:31,  2.49s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 27%|██▋       | 308/1140 [18:38<2:31:24, 10.92s/it]                                                     27%|██▋       | 308/1140 [18:38<2:31:24, 10.92s/it] 27%|██▋       | 309/1140 [18:41<1:59:50,  8.65s/it]                                                     27%|██▋       | 309/1140 [18:41<1:59:50,  8.65s/it] 27%|██▋       | 310/1140 [18:45<1:38:07,  7.09s/it]                                                     27%|██▋       | 310/1140 [18:45<1:38:07,  7.09s/it] 27%|██▋       | 311/1140 [18:48<1:22:51,  6.00s/it]                                                     27%|██▋       | 311/1140 [18:48<1:22:51,  6.00s/it] 27%|██▋       | 312/1140 [18:52<1:12:03,  5.22s/it]                                                     27%|██▋       | 312/1140 [18:52<1:12:03,  5.22s/it] 27%|██▋       | 313/1140 [18:55<1:05:39,  4.76s/it]                                                     27%|██▋       | 313/1140 [18:55<1:05:39,  4.76s/it] 28%|██▊       | 314/1140 [18:59<59:19,  4.31s/it]                                                     28%|██▊       | 314/1140 [18:59<59:19,  4.31s/it] 28%|██▊       | 315/1140 [19:02<55:15,  4.02s/it]                                                   28%|██▊       | 315/1140 [19:02<55:15,  4.02s/it] 28%|██▊       | 316/1140 [19:05<52:29,  3.82s/it]                                                   28%|██▊       | 316/1140 [19:05<52:29,  3.82s/it] 28%|██▊       | 317/1140 [19:09<50:36,  3.69s/it]                                                   28%|██▊       | 317/1140 [19:09<50:36,  3.69s/it] 28%|██▊       | 318/1140 [19:12<48:30,  3.54s/it]                                                   28%|██▊       | 318/1140 [19:12<48:30,  3.54s/it] 28%|██▊       | 319/1140 [19:15<46:15,  3.38s/it]                                                   28%|██▊       | 319/1140 [19:15<46:15,  3.38s/it] 28%|██▊       | 320/1140 [19:18<44:39,  3.27s/it]                                                   28%|██▊       | 320/1140 [19:18<44:39,  3.27s/it] 28%|██▊       | 321/1140 [19:21<44:22,  3.25s/it]                                                   28%|██▊       | 321/1140 [19:21<44:22,  3.25s/it] 28%|██▊       | 322/1140 [19:24<44:42,  3.28s/it]                                                   28%|██▊       | 322/1140 [19:24<44:42,  3.28s/it] 28%|██▊       | 323/1140 [19:27<43:48,  3.22s/it]                                                   28%|██▊       | 323/1140 [19:28<43:48,  3.22s/it] 28%|██▊       | 324/1140 [19:31<43:56,  3.23s/it]                                                   28%|██▊       | 324/1140 [19:31<43:56,  3.23s/it] 29%|██▊       | 325/1140 [19:34<43:39,  3.21s/it]                                                   29%|██▊       | 325/1140 [19:34<43:39,  3.21s/it] 29%|██▊       | 326/1140 [19:37<44:19,  3.27s/it]                                                   29%|██▊       | 326/1140 [19:37<44:19,  3.27s/it] 29%|██▊       | 327/1140 [19:40<43:46,  3.23s/it]                                                   29%|██▊       | 327/1140 [19:40<43:46,  3.23s/it] 29%|██▉       | 328/1140 [19:44<43:26,  3.21s/it]                                                   29%|██▉       | 328/1140 [19:44<43:26,  3.21s/it] 29%|██▉       | 329/1140 [19:47<43:49,  3.24s/it]                                                   29%|██▉       | 329/1140 [19:47<43:49,  3.24s/it] 29%|██▉       | 330/1140 [19:50<43:37,  3.23s/it]                                                   29%|██▉       | 330/1140 [19:50<43:37,  3.23s/it] 29%|██▉       | 331/1140 [19:53<42:21,  3.14s/it]                                                   29%|██▉       | 331/1140 [19:53<42:21,  3.14s/it] 29%|██▉       | 332/1140 [19:56<42:19,  3.14s/it]                                                   29%|██▉       | 332/1140 [19:56<42:19,  3.14s/it] 29%|██▉       | 333/1140 [19:59<42:29,  3.16s/it]                                                   29%|██▉       | 333/1140 [19:59<42:29,  3.16s/it] 29%|██▉       | 334/1140 [20:03<42:59,  3.20s/it]                                                   29%|██▉       | 334/1140 [20:03<42:59,  3.20s/it] 29%|██▉       | 335/1140 [20:06<43:09,  3.22s/it]                                                   29%|██▉       | 335/1140 [20:06<43:09,  3.22s/it] 29%|██▉       | 336/1140 [20:10<44:35,  3.33s/it]                                                   29%|██▉       | 336/1140 [20:10<44:35,  3.33s/it] 30%|██▉       | 337/1140 [20:13<43:46,  3.27s/it]                                                   30%|██▉       | 337/1140 [20:13<43:46,  3.27s/it] 30%|██▉       | 338/1140 [20:16<44:11,  3.31s/it]                                                   30%|██▉       | 338/1140 [20:16<44:11,  3.31s/it] 30%|██▉       | 339/1140 [20:19<43:35,  3.26s/it]                                                   30%|██▉       | 339/1140 [20:19<43:35,  3.26s/it] 30%|██▉       | 340/1140 [20:23<43:56,  3.30s/it]                                                   30%|██▉       | 340/1140 [20:23<43:56,  3.30s/it] 30%|██▉       | 341/1140 [20:26<44:27,  3.34s/it]                                                   30%|██▉       | 341/1140 [20:26<44:27,  3.34s/it] 30%|███       | 342/1140 [20:29<43:54,  3.30s/it]                                                   30%|███       | 342/1140 [20:29<43:54,  3.30s/it] 30%|███       | 343/1140 [20:33<43:54,  3.31s/it]                                                   30%|███       | 343/1140 [20:33<43:54,  3.31s/it] 30%|███       | 344/1140 [20:36<43:54,  3.31s/it]                                                   30%|███       | 344/1140 [20:36<43:54,  3.31s/it] 30%|███       | 345/1140 [20:39<43:41,  3.30s/it]                                                   30%|███       | 345/1140 [20:39<43:41,  3.30s/it] 30%|███       | 346/1140 [20:42<42:38,  3.22s/it]                                                   30%|███       | 346/1140 [20:42<42:38,  3.22s/it] 30%|███       | 347/1140 [20:46<42:49,  3.24s/it]                                                   30%|███       | 347/1140 [20:46<42:49,  3.24s/it] 31%|███       | 348/1140 [20:49<42:02,  3.19s/it]                                                   31%|███       | 348/1140 [20:49<42:02,  3.19s/it] 31%|███       | 349/1140 [20:52<41:50,  3.17s/it]                                                   31%|███       | 349/1140 [20:52<41:50,  3.17s/it] 31%|███       | 350/1140 [20:55<43:34,  3.31s/it]                                                   31%|███       | 350/1140 [20:55<43:34,  3.31s/it] 31%|███       | 351/1140 [20:59<43:50,  3.33s/it]                                                   31%|███       | 351/1140 [20:59<43:50,  3.33s/it] 31%|███       | 352/1140 [21:02<43:22,  3.30s/it]                                                   31%|███       | 352/1140 [21:02<43:22,  3.30s/it] 31%|███       | 353/1140 [21:05<42:16,  3.22s/it]                                                   31%|███       | 353/1140 [21:05<42:16,  3.22s/it] 31%|███       | 354/1140 [21:08<41:31,  3.17s/it]                                                   31%|███       | 354/1140 [21:08<41:31,  3.17s/it] 31%|███       | 355/1140 [21:11<41:32,  3.17s/it]                                                   31%|███       | 355/1140 [21:11<41:32,  3.17s/it] 31%|███       | 356/1140 [21:15<41:56,  3.21s/it]                                                   31%|███       | 356/1140 [21:15<41:56,  3.21s/it] 31%|███▏      | 357/1140 [21:18<41:23,  3.17s/it]                                                   31%|███▏      | 357/1140 [21:18<41:23,  3.17s/it] 31%|███▏      | 358/1140 [21:21<41:24,  3.18s/it]                                                   31%|███▏      | 358/1140 [21:21<41:24,  3.18s/it] 31%|███▏      | 359/1140 [21:24<41:05,  3.16s/it]                                                   31%|███▏      | 359/1140 [21:24<41:05,  3.16s/it] 32%|███▏      | 360/1140 [21:27<41:34,  3.20s/it]                                                   32%|███▏      | 360/1140 [21:27<41:34,  3.20s/it] 32%|███▏      | 361/1140 [21:31<42:27,  3.27s/it]                                                   32%|███▏      | 361/1140 [21:31<42:27,  3.27s/it] 32%|███▏      | 362/1140 [21:34<41:34,  3.21s/it]                                                   32%|███▏      | 362/1140 [21:34<41:34,  3.21s/it] 32%|███▏      | 363/1140 [21:37<41:13,  3.18s/it]                                                   32%|███▏      | 363/1140 [21:37<41:13,  3.18s/it] 32%|███▏      | 364/1140 [21:40<40:49,  3.16s/it]                                                   32%|███▏      | 364/1140 [21:40<40:49,  3.16s/it] 32%|███▏      | 365/1140 [21:43<41:26,  3.21s/it]                                                   32%|███▏      | 365/1140 [21:43<41:26,  3.21s/it] 32%|███▏      | 366/1140 [21:46<41:22,  3.21s/it]                                                   32%|███▏      | 366/1140 [21:46<41:22,  3.21s/it] 32%|███▏      | 367/1140 [21:50<41:16,  3.20s/it]                                                   32%|███▏      | 367/1140 [21:50<41:16,  3.20s/it] 32%|███▏      | 368/1140 [21:53<41:49,  3.25s/it]                                                   32%|███▏      | 368/1140 [21:53<41:49,  3.25s/it] 32%|███▏      | 369/1140 [21:56<41:22,  3.22s/it]                                                   32%|███▏      | 369/1140 [21:56<41:22,  3.22s/it] 32%|███▏      | 370/1140 [21:59<40:35,  3.16s/it]                                                   32%|███▏      | 370/1140 [21:59<40:35,  3.16s/it] 33%|███▎      | 371/1140 [22:03<41:16,  3.22s/it]                                                   33%|███▎      | 371/1140 [22:03<41:16,  3.22s/it] 33%|███▎      | 372/1140 [22:06<42:29,  3.32s/it]                                                   33%|███▎      | 372/1140 [22:06<42:29,  3.32s/it] 33%|███▎      | 373/1140 [22:09<42:07,  3.30s/it]                                                   33%|███▎      | 373/1140 [22:09<42:07,  3.30s/it] 33%|███▎      | 374/1140 [22:13<41:49,  3.28s/it]                                                   33%|███▎      | 374/1140 [22:13<41:49,  3.28s/it] 33%|███▎      | 375/1140 [22:16<42:26,  3.33s/it]                                                   33%|███▎      | 375/1140 [22:16<42:26,  3.33s/it] 33%|███▎      | 376/1140 [22:19<41:14,  3.24s/it]                                                   33%|███▎      | 376/1140 [22:19<41:14,  3.24s/it] 33%|███▎      | 377/1140 [22:22<40:35,  3.19s/it]                                                   33%|███▎      | 377/1140 [22:22<40:35,  3.19s/it] 33%|███▎      | 378/1140 [22:25<40:35,  3.20s/it]                                                   33%|███▎      | 378/1140 [22:25<40:35,  3.20s/it] 33%|███▎      | 379/1140 [22:29<40:33,  3.20s/it]                                                   33%|███▎      | 379/1140 [22:29<40:33,  3.20s/it] 33%|███▎      | 380/1140 [22:32<40:17,  3.18s/it]                                                   33%|███▎      | 380/1140 [22:32<40:17,  3.18s/it] 33%|███▎      | 381/1140 [22:34<38:09,  3.02s/it]                                                   33%|███▎      | 381/1140 [22:34<38:09,  3.02s/it] 34%|███▎      | 382/1140 [22:36<34:47,  2.75s/it]                                                   34%|███▎      | 382/1140 [22:36<34:47,  2.75s/it] 34%|███▎      | 383/1140 [22:39<32:29,  2.57s/it]                                                   34%|███▎      | 383/1140 [22:39<32:29,  2.57s/it] 34%|███▎      | 384/1140 [22:41<30:52,  2.45s/it]                                                   34%|███▎      | 384/1140 [22:41<30:52,  2.45s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 34%|███▍      | 385/1140 [23:11<2:16:53, 10.88s/it]                                                     34%|███▍      | 385/1140 [23:11<2:16:53, 10.88s/it] 34%|███▍      | 386/1140 [23:15<1:48:06,  8.60s/it]                                                     34%|███▍      | 386/1140 [23:15<1:48:06,  8.60s/it] 34%|███▍      | 387/1140 [23:18<1:28:17,  7.03s/it]                                                     34%|███▍      | 387/1140 [23:18<1:28:17,  7.03s/it] 34%|███▍      | 388/1140 [23:21<1:14:36,  5.95s/it]                                                     34%|███▍      | 388/1140 [23:21<1:14:36,  5.95s/it] 34%|███▍      | 389/1140 [23:25<1:05:10,  5.21s/it]                                                     34%|███▍      | 389/1140 [23:25<1:05:10,  5.21s/it] 34%|███▍      | 390/1140 [23:28<57:26,  4.59s/it]                                                     34%|███▍      | 390/1140 [23:28<57:26,  4.59s/it] 34%|███▍      | 391/1140 [23:31<52:20,  4.19s/it]                                                   34%|███▍      | 391/1140 [23:31<52:20,  4.19s/it] 34%|███▍      | 392/1140 [23:35<48:37,  3.90s/it]                                                   34%|███▍      | 392/1140 [23:35<48:37,  3.90s/it] 34%|███▍      | 393/1140 [23:38<45:56,  3.69s/it]                                                   34%|███▍      | 393/1140 [23:38<45:56,  3.69s/it] 35%|███▍      | 394/1140 [23:41<44:06,  3.55s/it]                                                   35%|███▍      | 394/1140 [23:41<44:06,  3.55s/it] 35%|███▍      | 395/1140 [23:44<42:22,  3.41s/it]                                                   35%|███▍      | 395/1140 [23:44<42:22,  3.41s/it] 35%|███▍      | 396/1140 [23:47<41:14,  3.33s/it]                                                   35%|███▍      | 396/1140 [23:47<41:14,  3.33s/it] 35%|███▍      | 397/1140 [23:50<40:23,  3.26s/it]                                                   35%|███▍      | 397/1140 [23:50<40:23,  3.26s/it] 35%|███▍      | 398/1140 [23:54<40:31,  3.28s/it]                                                   35%|███▍      | 398/1140 [23:54<40:31,  3.28s/it] 35%|███▌      | 399/1140 [23:57<39:54,  3.23s/it]                                                   35%|███▌      | 399/1140 [23:57<39:54,  3.23s/it] 35%|███▌      | 400/1140 [24:00<39:59,  3.24s/it]                                                   35%|███▌      | 400/1140 [24:00<39:59,  3.24s/it] 35%|███▌      | 401/1140 [24:03<40:20,  3.27s/it]                                                   35%|███▌      | 401/1140 [24:03<40:20,  3.27s/it] 35%|███▌      | 402/1140 [24:06<39:38,  3.22s/it]                                                   35%|███▌      | 402/1140 [24:06<39:38,  3.22s/it] 35%|███▌      | 403/1140 [24:10<39:51,  3.25s/it]                                                   35%|███▌      | 403/1140 [24:10<39:51,  3.25s/it] 35%|███▌      | 404/1140 [24:13<40:01,  3.26s/it]                                                   35%|███▌      | 404/1140 [24:13<40:01,  3.26s/it] 36%|███▌      | 405/1140 [24:16<39:37,  3.23s/it]                                                   36%|███▌      | 405/1140 [24:16<39:37,  3.23s/it] 36%|███▌      | 406/1140 [24:19<39:38,  3.24s/it]                                                   36%|███▌      | 406/1140 [24:19<39:38,  3.24s/it] 36%|███▌      | 407/1140 [24:23<40:36,  3.32s/it]                                                   36%|███▌      | 407/1140 [24:23<40:36,  3.32s/it] 36%|███▌      | 408/1140 [24:26<40:55,  3.35s/it]                                                   36%|███▌      | 408/1140 [24:26<40:55,  3.35s/it] 36%|███▌      | 409/1140 [24:30<41:15,  3.39s/it]                                                   36%|███▌      | 409/1140 [24:30<41:15,  3.39s/it] 36%|███▌      | 410/1140 [24:33<41:53,  3.44s/it]                                                   36%|███▌      | 410/1140 [24:33<41:53,  3.44s/it] 36%|███▌      | 411/1140 [24:37<41:50,  3.44s/it]                                                   36%|███▌      | 411/1140 [24:37<41:50,  3.44s/it] 36%|███▌      | 412/1140 [24:40<41:55,  3.46s/it]                                                   36%|███▌      | 412/1140 [24:40<41:55,  3.46s/it] 36%|███▌      | 413/1140 [24:44<41:30,  3.43s/it]                                                   36%|███▌      | 413/1140 [24:44<41:30,  3.43s/it] 36%|███▋      | 414/1140 [24:47<40:55,  3.38s/it]                                                   36%|███▋      | 414/1140 [24:47<40:55,  3.38s/it] 36%|███▋      | 415/1140 [24:50<40:28,  3.35s/it]                                                   36%|███▋      | 415/1140 [24:50<40:28,  3.35s/it] 36%|███▋      | 416/1140 [24:54<41:44,  3.46s/it]                                                   36%|███▋      | 416/1140 [24:54<41:44,  3.46s/it] 37%|███▋      | 417/1140 [24:57<41:35,  3.45s/it]                                                   37%|███▋      | 417/1140 [24:57<41:35,  3.45s/it] 37%|███▋      | 418/1140 [25:01<40:50,  3.39s/it]                                                   37%|███▋      | 418/1140 [25:01<40:50,  3.39s/it] 37%|███▋      | 419/1140 [25:04<39:48,  3.31s/it]                                                   37%|███▋      | 419/1140 [25:04<39:48,  3.31s/it] 37%|███▋      | 420/1140 [25:07<39:51,  3.32s/it]                                                   37%|███▋      | 420/1140 [25:07<39:51,  3.32s/it] 37%|███▋      | 421/1140 [25:10<39:01,  3.26s/it]                                                   37%|███▋      | 421/1140 [25:10<39:01,  3.26s/it] 37%|███▋      | 422/1140 [25:13<38:49,  3.24s/it]                                                   37%|███▋      | 422/1140 [25:13<38:49,  3.24s/it] 37%|███▋      | 423/1140 [25:17<38:40,  3.24s/it]                                                   37%|███▋      | 423/1140 [25:17<38:40,  3.24s/it] 37%|███▋      | 424/1140 [25:20<38:15,  3.21s/it]                                                   37%|███▋      | 424/1140 [25:20<38:15,  3.21s/it] 37%|███▋      | 425/1140 [25:23<38:46,  3.25s/it]                                                   37%|███▋      | 425/1140 [25:23<38:46,  3.25s/it] 37%|███▋      | 426/1140 [25:27<39:00,  3.28s/it]                                                   37%|███▋      | 426/1140 [25:27<39:00,  3.28s/it] 37%|███▋      | 427/1140 [25:30<38:36,  3.25s/it]                                                   37%|███▋      | 427/1140 [25:30<38:36,  3.25s/it] 38%|███▊      | 428/1140 [25:33<38:35,  3.25s/it]                                                   38%|███▊      | 428/1140 [25:33<38:35,  3.25s/it] 38%|███▊      | 429/1140 [25:36<38:07,  3.22s/it]                                                   38%|███▊      | 429/1140 [25:36<38:07,  3.22s/it] 38%|███▊      | 430/1140 [25:39<38:05,  3.22s/it]                                                   38%|███▊      | 430/1140 [25:39<38:05,  3.22s/it] 38%|███▊      | 431/1140 [25:42<37:53,  3.21s/it]                                                   38%|███▊      | 431/1140 [25:42<37:53,  3.21s/it] 38%|███▊      | 432/1140 [25:46<37:31,  3.18s/it]                                                   38%|███▊      | 432/1140 [25:46<37:31,  3.18s/it] 38%|███▊      | 433/1140 [25:49<37:34,  3.19s/it]                                                   38%|███▊      | 433/1140 [25:49<37:34,  3.19s/it] 38%|███▊      | 434/1140 [25:52<37:39,  3.20s/it]                                                   38%|███▊      | 434/1140 [25:52<37:39,  3.20s/it] 38%|███▊      | 435/1140 [25:55<37:55,  3.23s/it]                                                   38%|███▊      | 435/1140 [25:55<37:55,  3.23s/it] 38%|███▊      | 436/1140 [25:59<38:03,  3.24s/it]                                                   38%|███▊      | 436/1140 [25:59<38:03,  3.24s/it] 38%|███▊      | 437/1140 [26:02<39:02,  3.33s/it]                                                   38%|███▊      | 437/1140 [26:02<39:02,  3.33s/it] 38%|███▊      | 438/1140 [26:06<39:07,  3.34s/it]                                                   38%|███▊      | 438/1140 [26:06<39:07,  3.34s/it] 39%|███▊      | 439/1140 [26:09<38:23,  3.29s/it]                                                   39%|███▊      | 439/1140 [26:09<38:23,  3.29s/it] 39%|███▊      | 440/1140 [26:12<38:15,  3.28s/it]                                                   39%|███▊      | 440/1140 [26:12<38:15,  3.28s/it] 39%|███▊      | 441/1140 [26:15<37:35,  3.23s/it]                                                   39%|███▊      | 441/1140 [26:15<37:35,  3.23s/it] 39%|███▉      | 442/1140 [26:18<37:14,  3.20s/it]                                                   39%|███▉      | 442/1140 [26:18<37:14,  3.20s/it] 39%|███▉      | 443/1140 [26:21<36:44,  3.16s/it]                                                   39%|███▉      | 443/1140 [26:21<36:44,  3.16s/it] 39%|███▉      | 444/1140 [26:25<37:07,  3.20s/it]                                                   39%|███▉      | 444/1140 [26:25<37:07,  3.20s/it] 39%|███▉      | 445/1140 [26:28<37:02,  3.20s/it]                                                   39%|███▉      | 445/1140 [26:28<37:02,  3.20s/it] 39%|███▉      | 446/1140 [26:31<37:51,  3.27s/it]                                                   39%|███▉      | 446/1140 [26:31<37:51,  3.27s/it] 39%|███▉      | 447/1140 [26:35<38:13,  3.31s/it]                                                   39%|███▉      | 447/1140 [26:35<38:13,  3.31s/it] 39%|███▉      | 448/1140 [26:38<37:28,  3.25s/it]                                                   39%|███▉      | 448/1140 [26:38<37:28,  3.25s/it] 39%|███▉      | 449/1140 [26:41<37:49,  3.28s/it]                                                   39%|███▉      | 449/1140 [26:41<37:49,  3.28s/it] 39%|███▉      | 450/1140 [26:44<37:33,  3.27s/it]                                                   39%|███▉      | 450/1140 [26:44<37:33,  3.27s/it] 40%|███▉      | 451/1140 [26:47<37:13,  3.24s/it]                                                   40%|███▉      | 451/1140 [26:48<37:13,  3.24s/it] 40%|███▉      | 452/1140 [26:51<37:58,  3.31s/it]                                                   40%|███▉      | 452/1140 [26:51<37:58,  3.31s/it] 40%|███▉      | 453/1140 [26:55<39:24,  3.44s/it]                                                   40%|███▉      | 453/1140 [26:55<39:24,  3.44s/it] 40%|███▉      | 454/1140 [26:58<38:54,  3.40s/it]                                                   40%|███▉      | 454/1140 [26:58<38:54,  3.40s/it] 40%|███▉      | 455/1140 [27:01<38:30,  3.37s/it]                                                   40%|███▉      | 455/1140 [27:01<38:30,  3.37s/it] 40%|████      | 456/1140 [27:05<38:00,  3.33s/it]                                                   40%|████      | 456/1140 [27:05<38:00,  3.33s/it] 40%|████      | 457/1140 [27:08<37:09,  3.26s/it]                                                   40%|████      | 457/1140 [27:08<37:09,  3.26s/it] 40%|████      | 458/1140 [27:10<34:19,  3.02s/it]                                                   40%|████      | 458/1140 [27:10<34:19,  3.02s/it] 40%|████      | 459/1140 [27:12<31:18,  2.76s/it]                                                   40%|████      | 459/1140 [27:12<31:18,  2.76s/it] 40%|████      | 460/1140 [27:14<29:10,  2.57s/it]                                                   40%|████      | 460/1140 [27:14<29:10,  2.57s/it] 40%|████      | 461/1140 [27:17<27:42,  2.45s/it]                                                   40%|████      | 461/1140 [27:17<27:42,  2.45s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 41%|████      | 462/1140 [27:49<2:09:33, 11.47s/it]                                                     41%|████      | 462/1140 [27:49<2:09:33, 11.47s/it] 41%|████      | 463/1140 [27:52<1:42:06,  9.05s/it]                                                     41%|████      | 463/1140 [27:52<1:42:06,  9.05s/it] 41%|████      | 464/1140 [27:56<1:22:17,  7.30s/it]                                                     41%|████      | 464/1140 [27:56<1:22:17,  7.30s/it] 41%|████      | 465/1140 [27:59<1:08:39,  6.10s/it]                                                     41%|████      | 465/1140 [27:59<1:08:39,  6.10s/it] 41%|████      | 466/1140 [28:02<58:32,  5.21s/it]                                                     41%|████      | 466/1140 [28:02<58:32,  5.21s/it] 41%|████      | 467/1140 [28:05<51:30,  4.59s/it]                                                   41%|████      | 467/1140 [28:05<51:30,  4.59s/it] 41%|████      | 468/1140 [28:08<46:19,  4.14s/it]                                                   41%|████      | 468/1140 [28:08<46:19,  4.14s/it] 41%|████      | 469/1140 [28:12<43:31,  3.89s/it]                                                   41%|████      | 469/1140 [28:12<43:31,  3.89s/it] 41%|████      | 470/1140 [28:15<41:36,  3.73s/it]                                                   41%|████      | 470/1140 [28:15<41:36,  3.73s/it] 41%|████▏     | 471/1140 [28:18<39:52,  3.58s/it]                                                   41%|████▏     | 471/1140 [28:18<39:52,  3.58s/it] 41%|████▏     | 472/1140 [28:22<38:50,  3.49s/it]                                                   41%|████▏     | 472/1140 [28:22<38:50,  3.49s/it] 41%|████▏     | 473/1140 [28:25<37:22,  3.36s/it]                                                   41%|████▏     | 473/1140 [28:25<37:22,  3.36s/it] 42%|████▏     | 474/1140 [28:28<36:33,  3.29s/it]                                                   42%|████▏     | 474/1140 [28:28<36:33,  3.29s/it] 42%|████▏     | 475/1140 [28:31<35:12,  3.18s/it]                                                   42%|████▏     | 475/1140 [28:31<35:12,  3.18s/it] 42%|████▏     | 476/1140 [28:34<35:04,  3.17s/it]                                                   42%|████▏     | 476/1140 [28:34<35:04,  3.17s/it] 42%|████▏     | 477/1140 [28:37<34:39,  3.14s/it]                                                   42%|████▏     | 477/1140 [28:37<34:39,  3.14s/it] 42%|████▏     | 478/1140 [28:40<35:53,  3.25s/it]                                                   42%|████▏     | 478/1140 [28:40<35:53,  3.25s/it] 42%|████▏     | 479/1140 [28:43<35:19,  3.21s/it]                                                   42%|████▏     | 479/1140 [28:43<35:19,  3.21s/it] 42%|████▏     | 480/1140 [28:47<35:37,  3.24s/it]                                                   42%|████▏     | 480/1140 [28:47<35:37,  3.24s/it] 42%|████▏     | 481/1140 [28:50<35:17,  3.21s/it]                                                   42%|████▏     | 481/1140 [28:50<35:17,  3.21s/it] 42%|████▏     | 482/1140 [28:54<36:38,  3.34s/it]                                                   42%|████▏     | 482/1140 [28:54<36:38,  3.34s/it] 42%|████▏     | 483/1140 [28:57<36:43,  3.35s/it]                                                   42%|████▏     | 483/1140 [28:57<36:43,  3.35s/it] 42%|████▏     | 484/1140 [29:00<36:19,  3.32s/it]                                                   42%|████▏     | 484/1140 [29:00<36:19,  3.32s/it] 43%|████▎     | 485/1140 [29:04<36:34,  3.35s/it]                                                   43%|████▎     | 485/1140 [29:04<36:34,  3.35s/it] 43%|████▎     | 486/1140 [29:07<36:58,  3.39s/it]                                                   43%|████▎     | 486/1140 [29:07<36:58,  3.39s/it] 43%|████▎     | 487/1140 [29:10<36:51,  3.39s/it]                                                   43%|████▎     | 487/1140 [29:10<36:51,  3.39s/it] 43%|████▎     | 488/1140 [29:14<36:31,  3.36s/it]                                                   43%|████▎     | 488/1140 [29:14<36:31,  3.36s/it] 43%|████▎     | 489/1140 [29:17<35:47,  3.30s/it]                                                   43%|████▎     | 489/1140 [29:17<35:47,  3.30s/it] 43%|████▎     | 490/1140 [29:20<36:11,  3.34s/it]                                                   43%|████▎     | 490/1140 [29:20<36:11,  3.34s/it] 43%|████▎     | 491/1140 [29:24<36:28,  3.37s/it]                                                   43%|████▎     | 491/1140 [29:24<36:28,  3.37s/it] 43%|████▎     | 492/1140 [29:27<36:04,  3.34s/it]                                                   43%|████▎     | 492/1140 [29:27<36:04,  3.34s/it] 43%|████▎     | 493/1140 [29:31<36:55,  3.42s/it]                                                   43%|████▎     | 493/1140 [29:31<36:55,  3.42s/it] 43%|████▎     | 494/1140 [29:34<36:25,  3.38s/it]                                                   43%|████▎     | 494/1140 [29:34<36:25,  3.38s/it] 43%|████▎     | 495/1140 [29:37<36:00,  3.35s/it]                                                   43%|████▎     | 495/1140 [29:37<36:00,  3.35s/it] 44%|████▎     | 496/1140 [29:41<35:40,  3.32s/it]                                                   44%|████▎     | 496/1140 [29:41<35:40,  3.32s/it] 44%|████▎     | 497/1140 [29:44<35:39,  3.33s/it]                                                   44%|████▎     | 497/1140 [29:44<35:39,  3.33s/it] 44%|████▎     | 498/1140 [29:47<35:38,  3.33s/it]                                                   44%|████▎     | 498/1140 [29:47<35:38,  3.33s/it] 44%|████▍     | 499/1140 [29:50<35:21,  3.31s/it]                                                   44%|████▍     | 499/1140 [29:50<35:21,  3.31s/it] 44%|████▍     | 500/1140 [29:54<34:58,  3.28s/it]                                                   44%|████▍     | 500/1140 [29:54<34:58,  3.28s/it] 44%|████▍     | 501/1140 [29:57<34:26,  3.23s/it]                                                   44%|████▍     | 501/1140 [29:57<34:26,  3.23s/it] 44%|████▍     | 502/1140 [30:00<33:40,  3.17s/it]                                                   44%|████▍     | 502/1140 [30:00<33:40,  3.17s/it] 44%|████▍     | 503/1140 [30:03<33:52,  3.19s/it]                                                   44%|████▍     | 503/1140 [30:03<33:52,  3.19s/it] 44%|████▍     | 504/1140 [30:06<33:21,  3.15s/it]                                                   44%|████▍     | 504/1140 [30:06<33:21,  3.15s/it] 44%|████▍     | 505/1140 [30:09<33:45,  3.19s/it]                                                   44%|████▍     | 505/1140 [30:09<33:45,  3.19s/it] 44%|████▍     | 506/1140 [30:13<34:25,  3.26s/it]                                                   44%|████▍     | 506/1140 [30:13<34:25,  3.26s/it] 44%|████▍     | 507/1140 [30:16<34:35,  3.28s/it]                                                   44%|████▍     | 507/1140 [30:16<34:35,  3.28s/it] 45%|████▍     | 508/1140 [30:20<35:22,  3.36s/it]                                                   45%|████▍     | 508/1140 [30:20<35:22,  3.36s/it] 45%|████▍     | 509/1140 [30:23<35:12,  3.35s/it]                                                   45%|████▍     | 509/1140 [30:23<35:12,  3.35s/it] 45%|████▍     | 510/1140 [30:26<34:46,  3.31s/it]                                                   45%|████▍     | 510/1140 [30:26<34:46,  3.31s/it] 45%|████▍     | 511/1140 [30:30<35:11,  3.36s/it]                                                   45%|████▍     | 511/1140 [30:30<35:11,  3.36s/it] 45%|████▍     | 512/1140 [30:33<35:17,  3.37s/it]                                                   45%|████▍     | 512/1140 [30:33<35:17,  3.37s/it] 45%|████▌     | 513/1140 [30:36<34:38,  3.32s/it]                                                   45%|████▌     | 513/1140 [30:36<34:38,  3.32s/it] 45%|████▌     | 514/1140 [30:39<34:04,  3.27s/it]                                                   45%|████▌     | 514/1140 [30:39<34:04,  3.27s/it] 45%|████▌     | 515/1140 [30:43<34:31,  3.31s/it]                                                   45%|████▌     | 515/1140 [30:43<34:31,  3.31s/it] 45%|████▌     | 516/1140 [30:46<33:52,  3.26s/it]                                                   45%|████▌     | 516/1140 [30:46<33:52,  3.26s/it] 45%|████▌     | 517/1140 [30:49<33:42,  3.25s/it]                                                   45%|████▌     | 517/1140 [30:49<33:42,  3.25s/it] 45%|████▌     | 518/1140 [30:53<33:49,  3.26s/it]                                                   45%|████▌     | 518/1140 [30:53<33:49,  3.26s/it] 46%|████▌     | 519/1140 [30:56<34:25,  3.33s/it]                                                   46%|████▌     | 519/1140 [30:56<34:25,  3.33s/it] 46%|████▌     | 520/1140 [30:59<34:32,  3.34s/it]                                                   46%|████▌     | 520/1140 [30:59<34:32,  3.34s/it] 46%|████▌     | 521/1140 [31:03<33:52,  3.28s/it]                                                   46%|████▌     | 521/1140 [31:03<33:52,  3.28s/it] 46%|████▌     | 522/1140 [31:06<33:50,  3.29s/it]                                                   46%|████▌     | 522/1140 [31:06<33:50,  3.29s/it] 46%|████▌     | 523/1140 [31:09<33:57,  3.30s/it]                                                   46%|████▌     | 523/1140 [31:09<33:57,  3.30s/it] 46%|████▌     | 524/1140 [31:13<34:21,  3.35s/it]                                                   46%|████▌     | 524/1140 [31:13<34:21,  3.35s/it] 46%|████▌     | 525/1140 [31:16<34:47,  3.39s/it]                                                   46%|████▌     | 525/1140 [31:16<34:47,  3.39s/it] 46%|████▌     | 526/1140 [31:20<34:56,  3.41s/it]                                                   46%|████▌     | 526/1140 [31:20<34:56,  3.41s/it] 46%|████▌     | 527/1140 [31:23<34:23,  3.37s/it]                                                   46%|████▌     | 527/1140 [31:23<34:23,  3.37s/it] 46%|████▋     | 528/1140 [31:26<34:23,  3.37s/it]                                                   46%|████▋     | 528/1140 [31:26<34:23,  3.37s/it] 46%|████▋     | 529/1140 [31:29<33:01,  3.24s/it]                                                   46%|████▋     | 529/1140 [31:29<33:01,  3.24s/it] 46%|████▋     | 530/1140 [31:32<33:16,  3.27s/it]                                                   46%|████▋     | 530/1140 [31:33<33:16,  3.27s/it] 47%|████▋     | 531/1140 [31:36<33:32,  3.30s/it]                                                   47%|████▋     | 531/1140 [31:36<33:32,  3.30s/it] 47%|████▋     | 532/1140 [31:39<33:47,  3.33s/it]                                                   47%|████▋     | 532/1140 [31:39<33:47,  3.33s/it] 47%|████▋     | 533/1140 [31:43<33:30,  3.31s/it]                                                   47%|████▋     | 533/1140 [31:43<33:30,  3.31s/it] 47%|████▋     | 534/1140 [31:46<33:10,  3.29s/it]                                                   47%|████▋     | 534/1140 [31:46<33:10,  3.29s/it] 47%|████▋     | 535/1140 [31:48<30:18,  3.01s/it]                                                   47%|████▋     | 535/1140 [31:48<30:18,  3.01s/it] 47%|████▋     | 536/1140 [31:51<29:13,  2.90s/it]                                                   47%|████▋     | 536/1140 [31:51<29:13,  2.90s/it] 47%|████▋     | 537/1140 [31:53<28:39,  2.85s/it]                                                   47%|████▋     | 537/1140 [31:54<28:39,  2.85s/it] 47%|████▋     | 538/1140 [31:56<27:33,  2.75s/it]                                                   47%|████▋     | 538/1140 [31:56<27:33,  2.75s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 47%|████▋     | 539/1140 [32:27<1:53:47, 11.36s/it]                                                     47%|████▋     | 539/1140 [32:27<1:53:47, 11.36s/it] 47%|████▋     | 540/1140 [32:31<1:29:26,  8.94s/it]                                                     47%|████▋     | 540/1140 [32:31<1:29:26,  8.94s/it] 47%|████▋     | 541/1140 [32:34<1:12:38,  7.28s/it]                                                     47%|████▋     | 541/1140 [32:34<1:12:38,  7.28s/it] 48%|████▊     | 542/1140 [32:37<1:00:14,  6.04s/it]                                                     48%|████▊     | 542/1140 [32:37<1:00:14,  6.04s/it] 48%|████▊     | 543/1140 [32:41<52:37,  5.29s/it]                                                     48%|████▊     | 543/1140 [32:41<52:37,  5.29s/it] 48%|████▊     | 544/1140 [32:44<46:48,  4.71s/it]                                                   48%|████▊     | 544/1140 [32:44<46:48,  4.71s/it] 48%|████▊     | 545/1140 [32:47<42:21,  4.27s/it]                                                   48%|████▊     | 545/1140 [32:47<42:21,  4.27s/it] 48%|████▊     | 546/1140 [32:51<38:45,  3.92s/it]                                                   48%|████▊     | 546/1140 [32:51<38:45,  3.92s/it] 48%|████▊     | 547/1140 [32:54<38:27,  3.89s/it]                                                   48%|████▊     | 547/1140 [32:54<38:27,  3.89s/it] 48%|████▊     | 548/1140 [32:58<36:25,  3.69s/it]                                                   48%|████▊     | 548/1140 [32:58<36:25,  3.69s/it] 48%|████▊     | 549/1140 [33:01<34:57,  3.55s/it]                                                   48%|████▊     | 549/1140 [33:01<34:57,  3.55s/it] 48%|████▊     | 550/1140 [33:04<33:55,  3.45s/it]                                                   48%|████▊     | 550/1140 [33:04<33:55,  3.45s/it] 48%|████▊     | 551/1140 [33:07<33:53,  3.45s/it]                                                   48%|████▊     | 551/1140 [33:08<33:53,  3.45s/it] 48%|████▊     | 552/1140 [33:11<33:10,  3.39s/it]                                                   48%|████▊     | 552/1140 [33:11<33:10,  3.39s/it] 49%|████▊     | 553/1140 [33:14<33:03,  3.38s/it]                                                   49%|████▊     | 553/1140 [33:14<33:03,  3.38s/it] 49%|████▊     | 554/1140 [33:17<32:48,  3.36s/it]                                                   49%|████▊     | 554/1140 [33:17<32:48,  3.36s/it] 49%|████▊     | 555/1140 [33:21<32:44,  3.36s/it]                                                   49%|████▊     | 555/1140 [33:21<32:44,  3.36s/it] 49%|████▉     | 556/1140 [33:24<32:22,  3.33s/it]                                                   49%|████▉     | 556/1140 [33:24<32:22,  3.33s/it] 49%|████▉     | 557/1140 [33:27<32:46,  3.37s/it]                                                   49%|████▉     | 557/1140 [33:28<32:46,  3.37s/it] 49%|████▉     | 558/1140 [33:31<32:28,  3.35s/it]                                                   49%|████▉     | 558/1140 [33:31<32:28,  3.35s/it] 49%|████▉     | 559/1140 [33:34<31:55,  3.30s/it]                                                   49%|████▉     | 559/1140 [33:34<31:55,  3.30s/it] 49%|████▉     | 560/1140 [33:37<32:00,  3.31s/it]                                                   49%|████▉     | 560/1140 [33:37<32:00,  3.31s/it] 49%|████▉     | 561/1140 [33:41<32:20,  3.35s/it]                                                   49%|████▉     | 561/1140 [33:41<32:20,  3.35s/it] 49%|████▉     | 562/1140 [33:44<32:08,  3.34s/it]                                                   49%|████▉     | 562/1140 [33:44<32:08,  3.34s/it] 49%|████▉     | 563/1140 [33:47<32:07,  3.34s/it]                                                   49%|████▉     | 563/1140 [33:47<32:07,  3.34s/it] 49%|████▉     | 564/1140 [33:50<31:02,  3.23s/it]                                                   49%|████▉     | 564/1140 [33:50<31:02,  3.23s/it] 50%|████▉     | 565/1140 [33:54<31:51,  3.32s/it]                                                   50%|████▉     | 565/1140 [33:54<31:51,  3.32s/it] 50%|████▉     | 566/1140 [33:57<32:03,  3.35s/it]                                                   50%|████▉     | 566/1140 [33:57<32:03,  3.35s/it] 50%|████▉     | 567/1140 [34:00<31:23,  3.29s/it]                                                   50%|████▉     | 567/1140 [34:00<31:23,  3.29s/it] 50%|████▉     | 568/1140 [34:03<30:22,  3.19s/it]                                                   50%|████▉     | 568/1140 [34:03<30:22,  3.19s/it] 50%|████▉     | 569/1140 [34:07<30:46,  3.23s/it]                                                   50%|████▉     | 569/1140 [34:07<30:46,  3.23s/it] 50%|█████     | 570/1140 [34:10<30:09,  3.17s/it]                                                   50%|█████     | 570/1140 [34:10<30:09,  3.17s/it] 50%|█████     | 571/1140 [34:13<29:46,  3.14s/it]                                                   50%|█████     | 571/1140 [34:13<29:46,  3.14s/it] 50%|█████     | 572/1140 [34:16<29:36,  3.13s/it]                                                   50%|█████     | 572/1140 [34:16<29:36,  3.13s/it] 50%|█████     | 573/1140 [34:19<30:02,  3.18s/it]                                                   50%|█████     | 573/1140 [34:19<30:02,  3.18s/it] 50%|█████     | 574/1140 [34:22<29:48,  3.16s/it]                                                   50%|█████     | 574/1140 [34:22<29:48,  3.16s/it] 50%|█████     | 575/1140 [34:26<30:04,  3.19s/it]                                                   50%|█████     | 575/1140 [34:26<30:04,  3.19s/it] 51%|█████     | 576/1140 [34:29<30:27,  3.24s/it]                                                   51%|█████     | 576/1140 [34:29<30:27,  3.24s/it] 51%|█████     | 577/1140 [34:32<30:16,  3.23s/it]                                                   51%|█████     | 577/1140 [34:32<30:16,  3.23s/it] 51%|█████     | 578/1140 [34:35<30:26,  3.25s/it]                                                   51%|█████     | 578/1140 [34:36<30:26,  3.25s/it] 51%|█████     | 579/1140 [34:39<30:41,  3.28s/it]                                                   51%|█████     | 579/1140 [34:39<30:41,  3.28s/it] 51%|█████     | 580/1140 [34:42<30:30,  3.27s/it]                                                   51%|█████     | 580/1140 [34:42<30:30,  3.27s/it] 51%|█████     | 581/1140 [34:45<29:53,  3.21s/it]                                                   51%|█████     | 581/1140 [34:45<29:53,  3.21s/it] 51%|█████     | 582/1140 [34:48<30:03,  3.23s/it]                                                   51%|█████     | 582/1140 [34:48<30:03,  3.23s/it] 51%|█████     | 583/1140 [34:52<30:57,  3.33s/it]                                                   51%|█████     | 583/1140 [34:52<30:57,  3.33s/it] 51%|█████     | 584/1140 [34:56<31:31,  3.40s/it]                                                   51%|█████     | 584/1140 [34:56<31:31,  3.40s/it] 51%|█████▏    | 585/1140 [34:59<30:36,  3.31s/it]                                                   51%|█████▏    | 585/1140 [34:59<30:36,  3.31s/it] 51%|█████▏    | 586/1140 [35:02<30:42,  3.33s/it]                                                   51%|█████▏    | 586/1140 [35:02<30:42,  3.33s/it] 51%|█████▏    | 587/1140 [35:05<29:54,  3.25s/it]                                                   51%|█████▏    | 587/1140 [35:05<29:54,  3.25s/it] 52%|█████▏    | 588/1140 [35:08<29:47,  3.24s/it]                                                   52%|█████▏    | 588/1140 [35:08<29:47,  3.24s/it] 52%|█████▏    | 589/1140 [35:12<29:48,  3.25s/it]                                                   52%|█████▏    | 589/1140 [35:12<29:48,  3.25s/it] 52%|█████▏    | 590/1140 [35:15<29:44,  3.25s/it]                                                   52%|█████▏    | 590/1140 [35:15<29:44,  3.25s/it] 52%|█████▏    | 591/1140 [35:18<29:44,  3.25s/it]                                                   52%|█████▏    | 591/1140 [35:18<29:44,  3.25s/it] 52%|█████▏    | 592/1140 [35:21<29:19,  3.21s/it]                                                   52%|█████▏    | 592/1140 [35:21<29:19,  3.21s/it] 52%|█████▏    | 593/1140 [35:24<29:14,  3.21s/it]                                                   52%|█████▏    | 593/1140 [35:24<29:14,  3.21s/it] 52%|█████▏    | 594/1140 [35:27<28:41,  3.15s/it]                                                   52%|█████▏    | 594/1140 [35:27<28:41,  3.15s/it] 52%|█████▏    | 595/1140 [35:31<28:40,  3.16s/it]                                                   52%|█████▏    | 595/1140 [35:31<28:40,  3.16s/it] 52%|█████▏    | 596/1140 [35:34<28:50,  3.18s/it]                                                   52%|█████▏    | 596/1140 [35:34<28:50,  3.18s/it] 52%|█████▏    | 597/1140 [35:37<28:39,  3.17s/it]                                                   52%|█████▏    | 597/1140 [35:37<28:39,  3.17s/it] 52%|█████▏    | 598/1140 [35:40<29:07,  3.22s/it]                                                   52%|█████▏    | 598/1140 [35:40<29:07,  3.22s/it] 53%|█████▎    | 599/1140 [35:44<29:01,  3.22s/it]                                                   53%|█████▎    | 599/1140 [35:44<29:01,  3.22s/it] 53%|█████▎    | 600/1140 [35:47<28:55,  3.21s/it]                                                   53%|█████▎    | 600/1140 [35:47<28:55,  3.21s/it] 53%|█████▎    | 601/1140 [35:50<29:20,  3.27s/it]                                                   53%|█████▎    | 601/1140 [35:50<29:20,  3.27s/it] 53%|█████▎    | 602/1140 [35:53<29:19,  3.27s/it]                                                   53%|█████▎    | 602/1140 [35:53<29:19,  3.27s/it] 53%|█████▎    | 603/1140 [35:57<29:06,  3.25s/it]                                                   53%|█████▎    | 603/1140 [35:57<29:06,  3.25s/it] 53%|█████▎    | 604/1140 [36:00<28:47,  3.22s/it]                                                   53%|█████▎    | 604/1140 [36:00<28:47,  3.22s/it] 53%|█████▎    | 605/1140 [36:03<29:38,  3.32s/it]                                                   53%|█████▎    | 605/1140 [36:03<29:38,  3.32s/it] 53%|█████▎    | 606/1140 [36:07<29:33,  3.32s/it]                                                   53%|█████▎    | 606/1140 [36:07<29:33,  3.32s/it] 53%|█████▎    | 607/1140 [36:10<28:53,  3.25s/it]                                                   53%|█████▎    | 607/1140 [36:10<28:53,  3.25s/it] 53%|█████▎    | 608/1140 [36:13<28:23,  3.20s/it]                                                   53%|█████▎    | 608/1140 [36:13<28:23,  3.20s/it] 53%|█████▎    | 609/1140 [36:16<28:59,  3.28s/it]                                                   53%|█████▎    | 609/1140 [36:16<28:59,  3.28s/it] 54%|█████▎    | 610/1140 [36:19<28:40,  3.25s/it]                                                   54%|█████▎    | 610/1140 [36:19<28:40,  3.25s/it] 54%|█████▎    | 611/1140 [36:23<28:41,  3.25s/it]                                                   54%|█████▎    | 611/1140 [36:23<28:41,  3.25s/it] 54%|█████▎    | 612/1140 [36:25<25:59,  2.95s/it]                                                   54%|█████▎    | 612/1140 [36:25<25:59,  2.95s/it] 54%|█████▍    | 613/1140 [36:27<23:46,  2.71s/it]                                                   54%|█████▍    | 613/1140 [36:27<23:46,  2.71s/it] 54%|█████▍    | 614/1140 [36:29<22:16,  2.54s/it]                                                   54%|█████▍    | 614/1140 [36:29<22:16,  2.54s/it] 54%|█████▍    | 615/1140 [36:32<22:24,  2.56s/it]                                                   54%|█████▍    | 615/1140 [36:32<22:24,  2.56s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 54%|█████▍    | 616/1140 [37:02<1:35:33, 10.94s/it]                                                     54%|█████▍    | 616/1140 [37:02<1:35:33, 10.94s/it] 54%|█████▍    | 617/1140 [37:06<1:15:10,  8.63s/it]                                                     54%|█████▍    | 617/1140 [37:06<1:15:10,  8.63s/it] 54%|█████▍    | 618/1140 [37:09<1:01:40,  7.09s/it]                                                     54%|█████▍    | 618/1140 [37:09<1:01:40,  7.09s/it] 54%|█████▍    | 619/1140 [37:12<51:40,  5.95s/it]                                                     54%|█████▍    | 619/1140 [37:12<51:40,  5.95s/it] 54%|█████▍    | 620/1140 [37:16<44:17,  5.11s/it]                                                   54%|█████▍    | 620/1140 [37:16<44:17,  5.11s/it] 54%|█████▍    | 621/1140 [37:19<39:34,  4.58s/it]                                                   54%|█████▍    | 621/1140 [37:19<39:34,  4.58s/it] 55%|█████▍    | 622/1140 [37:22<35:48,  4.15s/it]                                                   55%|█████▍    | 622/1140 [37:22<35:48,  4.15s/it] 55%|█████▍    | 623/1140 [37:25<33:51,  3.93s/it]                                                   55%|█████▍    | 623/1140 [37:25<33:51,  3.93s/it] 55%|█████▍    | 624/1140 [37:28<31:35,  3.67s/it]                                                   55%|█████▍    | 624/1140 [37:28<31:35,  3.67s/it] 55%|█████▍    | 625/1140 [37:32<30:16,  3.53s/it]                                                   55%|█████▍    | 625/1140 [37:32<30:16,  3.53s/it] 55%|█████▍    | 626/1140 [37:35<29:18,  3.42s/it]                                                   55%|█████▍    | 626/1140 [37:35<29:18,  3.42s/it] 55%|█████▌    | 627/1140 [37:38<28:31,  3.34s/it]                                                   55%|█████▌    | 627/1140 [37:38<28:31,  3.34s/it] 55%|█████▌    | 628/1140 [37:41<28:27,  3.33s/it]                                                   55%|█████▌    | 628/1140 [37:41<28:27,  3.33s/it] 55%|█████▌    | 629/1140 [37:44<27:41,  3.25s/it]                                                   55%|█████▌    | 629/1140 [37:44<27:41,  3.25s/it] 55%|█████▌    | 630/1140 [37:47<26:58,  3.17s/it]                                                   55%|█████▌    | 630/1140 [37:47<26:58,  3.17s/it] 55%|█████▌    | 631/1140 [37:50<26:29,  3.12s/it]                                                   55%|█████▌    | 631/1140 [37:50<26:29,  3.12s/it] 55%|█████▌    | 632/1140 [37:54<26:47,  3.17s/it]                                                   55%|█████▌    | 632/1140 [37:54<26:47,  3.17s/it] 56%|█████▌    | 633/1140 [37:57<26:43,  3.16s/it]                                                   56%|█████▌    | 633/1140 [37:57<26:43,  3.16s/it] 56%|█████▌    | 634/1140 [38:00<27:30,  3.26s/it]                                                   56%|█████▌    | 634/1140 [38:00<27:30,  3.26s/it] 56%|█████▌    | 635/1140 [38:04<27:21,  3.25s/it]                                                   56%|█████▌    | 635/1140 [38:04<27:21,  3.25s/it] 56%|█████▌    | 636/1140 [38:07<27:56,  3.33s/it]                                                   56%|█████▌    | 636/1140 [38:07<27:56,  3.33s/it] 56%|█████▌    | 637/1140 [38:10<27:50,  3.32s/it]                                                   56%|█████▌    | 637/1140 [38:10<27:50,  3.32s/it] 56%|█████▌    | 638/1140 [38:14<27:44,  3.32s/it]                                                   56%|█████▌    | 638/1140 [38:14<27:44,  3.32s/it] 56%|█████▌    | 639/1140 [38:17<27:36,  3.31s/it]                                                   56%|█████▌    | 639/1140 [38:17<27:36,  3.31s/it] 56%|█████▌    | 640/1140 [38:20<26:59,  3.24s/it]                                                   56%|█████▌    | 640/1140 [38:20<26:59,  3.24s/it] 56%|█████▌    | 641/1140 [38:23<27:12,  3.27s/it]                                                   56%|█████▌    | 641/1140 [38:23<27:12,  3.27s/it] 56%|█████▋    | 642/1140 [38:27<27:36,  3.33s/it]                                                   56%|█████▋    | 642/1140 [38:27<27:36,  3.33s/it] 56%|█████▋    | 643/1140 [38:30<27:25,  3.31s/it]                                                   56%|█████▋    | 643/1140 [38:30<27:25,  3.31s/it] 56%|█████▋    | 644/1140 [38:33<27:07,  3.28s/it]                                                   56%|█████▋    | 644/1140 [38:33<27:07,  3.28s/it] 57%|█████▋    | 645/1140 [38:36<26:36,  3.23s/it]                                                   57%|█████▋    | 645/1140 [38:36<26:36,  3.23s/it] 57%|█████▋    | 646/1140 [38:39<26:00,  3.16s/it]                                                   57%|█████▋    | 646/1140 [38:39<26:00,  3.16s/it] 57%|█████▋    | 647/1140 [38:42<25:27,  3.10s/it]                                                   57%|█████▋    | 647/1140 [38:42<25:27,  3.10s/it] 57%|█████▋    | 648/1140 [38:46<25:37,  3.12s/it]                                                   57%|█████▋    | 648/1140 [38:46<25:37,  3.12s/it] 57%|█████▋    | 649/1140 [38:49<25:41,  3.14s/it]                                                   57%|█████▋    | 649/1140 [38:49<25:41,  3.14s/it] 57%|█████▋    | 650/1140 [38:52<25:20,  3.10s/it]                                                   57%|█████▋    | 650/1140 [38:52<25:20,  3.10s/it] 57%|█████▋    | 651/1140 [38:55<26:38,  3.27s/it]                                                   57%|█████▋    | 651/1140 [38:55<26:38,  3.27s/it] 57%|█████▋    | 652/1140 [38:59<27:07,  3.34s/it]                                                   57%|█████▋    | 652/1140 [38:59<27:07,  3.34s/it] 57%|█████▋    | 653/1140 [39:02<26:38,  3.28s/it]                                                   57%|█████▋    | 653/1140 [39:02<26:38,  3.28s/it] 57%|█████▋    | 654/1140 [39:05<26:25,  3.26s/it]                                                   57%|█████▋    | 654/1140 [39:05<26:25,  3.26s/it] 57%|█████▋    | 655/1140 [39:08<26:01,  3.22s/it]                                                   57%|█████▋    | 655/1140 [39:08<26:01,  3.22s/it] 58%|█████▊    | 656/1140 [39:12<26:05,  3.24s/it]                                                   58%|█████▊    | 656/1140 [39:12<26:05,  3.24s/it] 58%|█████▊    | 657/1140 [39:15<26:03,  3.24s/it]                                                   58%|█████▊    | 657/1140 [39:15<26:03,  3.24s/it] 58%|█████▊    | 658/1140 [39:18<25:58,  3.23s/it]                                                   58%|█████▊    | 658/1140 [39:18<25:58,  3.23s/it] 58%|█████▊    | 659/1140 [39:21<26:15,  3.27s/it]                                                   58%|█████▊    | 659/1140 [39:21<26:15,  3.27s/it] 58%|█████▊    | 660/1140 [39:25<25:57,  3.25s/it]                                                   58%|█████▊    | 660/1140 [39:25<25:57,  3.25s/it] 58%|█████▊    | 661/1140 [39:28<26:16,  3.29s/it]                                                   58%|█████▊    | 661/1140 [39:28<26:16,  3.29s/it] 58%|█████▊    | 662/1140 [39:31<25:53,  3.25s/it]                                                   58%|█████▊    | 662/1140 [39:31<25:53,  3.25s/it] 58%|█████▊    | 663/1140 [39:34<25:29,  3.21s/it]                                                   58%|█████▊    | 663/1140 [39:34<25:29,  3.21s/it] 58%|█████▊    | 664/1140 [39:38<25:44,  3.24s/it]                                                   58%|█████▊    | 664/1140 [39:38<25:44,  3.24s/it] 58%|█████▊    | 665/1140 [39:41<25:12,  3.18s/it]                                                   58%|█████▊    | 665/1140 [39:41<25:12,  3.18s/it] 58%|█████▊    | 666/1140 [39:44<24:52,  3.15s/it]                                                   58%|█████▊    | 666/1140 [39:44<24:52,  3.15s/it] 59%|█████▊    | 667/1140 [39:47<25:34,  3.25s/it]                                                   59%|█████▊    | 667/1140 [39:47<25:34,  3.25s/it] 59%|█████▊    | 668/1140 [39:51<25:47,  3.28s/it]                                                   59%|█████▊    | 668/1140 [39:51<25:47,  3.28s/it] 59%|█████▊    | 669/1140 [39:54<25:33,  3.26s/it]                                                   59%|█████▊    | 669/1140 [39:54<25:33,  3.26s/it] 59%|█████▉    | 670/1140 [39:57<25:38,  3.27s/it]                                                   59%|█████▉    | 670/1140 [39:57<25:38,  3.27s/it] 59%|█████▉    | 671/1140 [40:00<25:52,  3.31s/it]                                                   59%|█████▉    | 671/1140 [40:01<25:52,  3.31s/it] 59%|█████▉    | 672/1140 [40:04<26:00,  3.34s/it]                                                   59%|█████▉    | 672/1140 [40:04<26:00,  3.34s/it] 59%|█████▉    | 673/1140 [40:07<25:36,  3.29s/it]                                                   59%|█████▉    | 673/1140 [40:07<25:36,  3.29s/it] 59%|█████▉    | 674/1140 [40:10<25:46,  3.32s/it]                                                   59%|█████▉    | 674/1140 [40:10<25:46,  3.32s/it] 59%|█████▉    | 675/1140 [40:14<25:34,  3.30s/it]                                                   59%|█████▉    | 675/1140 [40:14<25:34,  3.30s/it] 59%|█████▉    | 676/1140 [40:17<25:26,  3.29s/it]                                                   59%|█████▉    | 676/1140 [40:17<25:26,  3.29s/it] 59%|█████▉    | 677/1140 [40:20<25:31,  3.31s/it]                                                   59%|█████▉    | 677/1140 [40:20<25:31,  3.31s/it] 59%|█████▉    | 678/1140 [40:24<25:30,  3.31s/it]                                                   59%|█████▉    | 678/1140 [40:24<25:30,  3.31s/it] 60%|█████▉    | 679/1140 [40:27<25:12,  3.28s/it]                                                   60%|█████▉    | 679/1140 [40:27<25:12,  3.28s/it] 60%|█████▉    | 680/1140 [40:30<25:18,  3.30s/it]                                                   60%|█████▉    | 680/1140 [40:30<25:18,  3.30s/it] 60%|█████▉    | 681/1140 [40:34<25:16,  3.30s/it]                                                   60%|█████▉    | 681/1140 [40:34<25:16,  3.30s/it] 60%|█████▉    | 682/1140 [40:37<24:56,  3.27s/it]                                                   60%|█████▉    | 682/1140 [40:37<24:56,  3.27s/it] 60%|█████▉    | 683/1140 [40:40<25:35,  3.36s/it]                                                   60%|█████▉    | 683/1140 [40:40<25:35,  3.36s/it] 60%|██████    | 684/1140 [40:43<24:55,  3.28s/it]                                                   60%|██████    | 684/1140 [40:43<24:55,  3.28s/it] 60%|██████    | 685/1140 [40:47<24:54,  3.29s/it]                                                   60%|██████    | 685/1140 [40:47<24:54,  3.29s/it] 60%|██████    | 686/1140 [40:50<25:21,  3.35s/it]                                                   60%|██████    | 686/1140 [40:50<25:21,  3.35s/it] 60%|██████    | 687/1140 [40:54<25:49,  3.42s/it]                                                   60%|██████    | 687/1140 [40:54<25:49,  3.42s/it] 60%|██████    | 688/1140 [40:57<25:06,  3.33s/it]                                                   60%|██████    | 688/1140 [40:57<25:06,  3.33s/it] 60%|██████    | 689/1140 [40:59<22:26,  2.99s/it]                                                   60%|██████    | 689/1140 [40:59<22:26,  2.99s/it] 61%|██████    | 690/1140 [41:01<20:28,  2.73s/it]                                                   61%|██████    | 690/1140 [41:01<20:28,  2.73s/it] 61%|██████    | 691/1140 [41:03<19:03,  2.55s/it]                                                   61%|██████    | 691/1140 [41:03<19:03,  2.55s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 61%|██████    | 692/1140 [41:35<1:23:33, 11.19s/it]                                                     61%|██████    | 692/1140 [41:35<1:23:33, 11.19s/it] 61%|██████    | 693/1140 [41:38<1:05:54,  8.85s/it]                                                     61%|██████    | 693/1140 [41:38<1:05:54,  8.85s/it] 61%|██████    | 694/1140 [41:41<53:23,  7.18s/it]                                                     61%|██████    | 694/1140 [41:41<53:23,  7.18s/it] 61%|██████    | 695/1140 [41:45<44:46,  6.04s/it]                                                   61%|██████    | 695/1140 [41:45<44:46,  6.04s/it] 61%|██████    | 696/1140 [41:48<38:22,  5.19s/it]                                                   61%|██████    | 696/1140 [41:48<38:22,  5.19s/it] 61%|██████    | 697/1140 [41:51<33:59,  4.60s/it]                                                   61%|██████    | 697/1140 [41:51<33:59,  4.60s/it] 61%|██████    | 698/1140 [41:54<30:58,  4.20s/it]                                                   61%|██████    | 698/1140 [41:54<30:58,  4.20s/it] 61%|██████▏   | 699/1140 [41:58<28:48,  3.92s/it]                                                   61%|██████▏   | 699/1140 [41:58<28:48,  3.92s/it] 61%|██████▏   | 700/1140 [42:01<27:43,  3.78s/it]                                                   61%|██████▏   | 700/1140 [42:01<27:43,  3.78s/it] 61%|██████▏   | 701/1140 [42:05<26:58,  3.69s/it]                                                   61%|██████▏   | 701/1140 [42:05<26:58,  3.69s/it] 62%|██████▏   | 702/1140 [42:08<25:59,  3.56s/it]                                                   62%|██████▏   | 702/1140 [42:08<25:59,  3.56s/it] 62%|██████▏   | 703/1140 [42:11<25:16,  3.47s/it]                                                   62%|██████▏   | 703/1140 [42:11<25:16,  3.47s/it] 62%|██████▏   | 704/1140 [42:14<24:38,  3.39s/it]                                                   62%|██████▏   | 704/1140 [42:14<24:38,  3.39s/it] 62%|██████▏   | 705/1140 [42:18<24:52,  3.43s/it]                                                   62%|██████▏   | 705/1140 [42:18<24:52,  3.43s/it] 62%|██████▏   | 706/1140 [42:21<23:59,  3.32s/it]                                                   62%|██████▏   | 706/1140 [42:21<23:59,  3.32s/it] 62%|██████▏   | 707/1140 [42:25<24:38,  3.41s/it]                                                   62%|██████▏   | 707/1140 [42:25<24:38,  3.41s/it] 62%|██████▏   | 708/1140 [42:28<24:27,  3.40s/it]                                                   62%|██████▏   | 708/1140 [42:28<24:27,  3.40s/it] 62%|██████▏   | 709/1140 [42:31<24:10,  3.36s/it]                                                   62%|██████▏   | 709/1140 [42:31<24:10,  3.36s/it] 62%|██████▏   | 710/1140 [42:35<24:11,  3.38s/it]                                                   62%|██████▏   | 710/1140 [42:35<24:11,  3.38s/it] 62%|██████▏   | 711/1140 [42:38<23:39,  3.31s/it]                                                   62%|██████▏   | 711/1140 [42:38<23:39,  3.31s/it] 62%|██████▏   | 712/1140 [42:41<23:22,  3.28s/it]                                                   62%|██████▏   | 712/1140 [42:41<23:22,  3.28s/it] 63%|██████▎   | 713/1140 [42:44<23:02,  3.24s/it]                                                   63%|██████▎   | 713/1140 [42:44<23:02,  3.24s/it] 63%|██████▎   | 714/1140 [42:47<22:46,  3.21s/it]                                                   63%|██████▎   | 714/1140 [42:47<22:46,  3.21s/it] 63%|██████▎   | 715/1140 [42:50<22:39,  3.20s/it]                                                   63%|██████▎   | 715/1140 [42:50<22:39,  3.20s/it] 63%|██████▎   | 716/1140 [42:54<23:31,  3.33s/it]                                                   63%|██████▎   | 716/1140 [42:54<23:31,  3.33s/it] 63%|██████▎   | 717/1140 [42:57<23:33,  3.34s/it]                                                   63%|██████▎   | 717/1140 [42:57<23:33,  3.34s/it] 63%|██████▎   | 718/1140 [43:01<23:36,  3.36s/it]                                                   63%|██████▎   | 718/1140 [43:01<23:36,  3.36s/it] 63%|██████▎   | 719/1140 [43:04<23:50,  3.40s/it]                                                   63%|██████▎   | 719/1140 [43:04<23:50,  3.40s/it] 63%|██████▎   | 720/1140 [43:07<22:57,  3.28s/it]                                                   63%|██████▎   | 720/1140 [43:07<22:57,  3.28s/it] 63%|██████▎   | 721/1140 [43:10<22:39,  3.24s/it]                                                   63%|██████▎   | 721/1140 [43:11<22:39,  3.24s/it] 63%|██████▎   | 722/1140 [43:14<22:37,  3.25s/it]                                                   63%|██████▎   | 722/1140 [43:14<22:37,  3.25s/it] 63%|██████▎   | 723/1140 [43:17<22:12,  3.19s/it]                                                   63%|██████▎   | 723/1140 [43:17<22:12,  3.19s/it] 64%|██████▎   | 724/1140 [43:20<21:50,  3.15s/it]                                                   64%|██████▎   | 724/1140 [43:20<21:50,  3.15s/it] 64%|██████▎   | 725/1140 [43:23<21:46,  3.15s/it]                                                   64%|██████▎   | 725/1140 [43:23<21:46,  3.15s/it] 64%|██████▎   | 726/1140 [43:26<21:57,  3.18s/it]                                                   64%|██████▎   | 726/1140 [43:26<21:57,  3.18s/it] 64%|██████▍   | 727/1140 [43:29<21:31,  3.13s/it]                                                   64%|██████▍   | 727/1140 [43:29<21:31,  3.13s/it] 64%|██████▍   | 728/1140 [43:33<21:47,  3.17s/it]                                                   64%|██████▍   | 728/1140 [43:33<21:47,  3.17s/it] 64%|██████▍   | 729/1140 [43:35<21:17,  3.11s/it]                                                   64%|██████▍   | 729/1140 [43:35<21:17,  3.11s/it] 64%|██████▍   | 730/1140 [43:39<21:31,  3.15s/it]                                                   64%|██████▍   | 730/1140 [43:39<21:31,  3.15s/it] 64%|██████▍   | 731/1140 [43:42<21:20,  3.13s/it]                                                   64%|██████▍   | 731/1140 [43:42<21:20,  3.13s/it] 64%|██████▍   | 732/1140 [43:45<20:57,  3.08s/it]                                                   64%|██████▍   | 732/1140 [43:45<20:57,  3.08s/it] 64%|██████▍   | 733/1140 [43:48<20:23,  3.01s/it]                                                   64%|██████▍   | 733/1140 [43:48<20:23,  3.01s/it] 64%|██████▍   | 734/1140 [43:51<20:11,  2.98s/it]                                                   64%|██████▍   | 734/1140 [43:51<20:11,  2.98s/it] 64%|██████▍   | 735/1140 [43:54<20:06,  2.98s/it]                                                   64%|██████▍   | 735/1140 [43:54<20:06,  2.98s/it] 65%|██████▍   | 736/1140 [43:57<20:06,  2.99s/it]                                                   65%|██████▍   | 736/1140 [43:57<20:06,  2.99s/it] 65%|██████▍   | 737/1140 [43:59<19:59,  2.98s/it]                                                   65%|██████▍   | 737/1140 [43:59<19:59,  2.98s/it] 65%|██████▍   | 738/1140 [44:03<20:10,  3.01s/it]                                                   65%|██████▍   | 738/1140 [44:03<20:10,  3.01s/it] 65%|██████▍   | 739/1140 [44:05<19:56,  2.98s/it]                                                   65%|██████▍   | 739/1140 [44:06<19:56,  2.98s/it] 65%|██████▍   | 740/1140 [44:09<19:56,  2.99s/it]                                                   65%|██████▍   | 740/1140 [44:09<19:56,  2.99s/it] 65%|██████▌   | 741/1140 [44:12<19:59,  3.01s/it]                                                   65%|██████▌   | 741/1140 [44:12<19:59,  3.01s/it] 65%|██████▌   | 742/1140 [44:15<19:51,  2.99s/it]                                                   65%|██████▌   | 742/1140 [44:15<19:51,  2.99s/it] 65%|██████▌   | 743/1140 [44:17<19:44,  2.98s/it]                                                   65%|██████▌   | 743/1140 [44:17<19:44,  2.98s/it] 65%|██████▌   | 744/1140 [44:20<19:34,  2.96s/it]                                                   65%|██████▌   | 744/1140 [44:20<19:34,  2.96s/it] 65%|██████▌   | 745/1140 [44:23<19:23,  2.95s/it]                                                   65%|██████▌   | 745/1140 [44:23<19:23,  2.95s/it] 65%|██████▌   | 746/1140 [44:26<19:27,  2.96s/it]                                                   65%|██████▌   | 746/1140 [44:26<19:27,  2.96s/it] 66%|██████▌   | 747/1140 [44:29<19:28,  2.97s/it]                                                   66%|██████▌   | 747/1140 [44:29<19:28,  2.97s/it] 66%|██████▌   | 748/1140 [44:32<19:40,  3.01s/it]                                                   66%|██████▌   | 748/1140 [44:32<19:40,  3.01s/it] 66%|██████▌   | 749/1140 [44:36<19:52,  3.05s/it]                                                   66%|██████▌   | 749/1140 [44:36<19:52,  3.05s/it] 66%|██████▌   | 750/1140 [44:39<20:39,  3.18s/it]                                                   66%|██████▌   | 750/1140 [44:39<20:39,  3.18s/it] 66%|██████▌   | 751/1140 [44:42<20:28,  3.16s/it]                                                   66%|██████▌   | 751/1140 [44:42<20:28,  3.16s/it] 66%|██████▌   | 752/1140 [44:45<20:28,  3.17s/it]                                                   66%|██████▌   | 752/1140 [44:45<20:28,  3.17s/it] 66%|██████▌   | 753/1140 [44:49<20:49,  3.23s/it]                                                   66%|██████▌   | 753/1140 [44:49<20:49,  3.23s/it] 66%|██████▌   | 754/1140 [44:52<20:53,  3.25s/it]                                                   66%|██████▌   | 754/1140 [44:52<20:53,  3.25s/it] 66%|██████▌   | 755/1140 [44:56<22:24,  3.49s/it]                                                   66%|██████▌   | 755/1140 [44:56<22:24,  3.49s/it] 66%|██████▋   | 756/1140 [44:59<22:03,  3.45s/it]                                                   66%|██████▋   | 756/1140 [44:59<22:03,  3.45s/it] 66%|██████▋   | 757/1140 [45:03<21:40,  3.40s/it]                                                   66%|██████▋   | 757/1140 [45:03<21:40,  3.40s/it] 66%|██████▋   | 758/1140 [45:06<21:17,  3.34s/it]                                                   66%|██████▋   | 758/1140 [45:06<21:17,  3.34s/it] 67%|██████▋   | 759/1140 [45:09<20:52,  3.29s/it]                                                   67%|██████▋   | 759/1140 [45:09<20:52,  3.29s/it] 67%|██████▋   | 760/1140 [45:12<20:43,  3.27s/it]                                                   67%|██████▋   | 760/1140 [45:12<20:43,  3.27s/it] 67%|██████▋   | 761/1140 [45:15<20:29,  3.24s/it]                                                   67%|██████▋   | 761/1140 [45:15<20:29,  3.24s/it] 67%|██████▋   | 762/1140 [45:18<19:58,  3.17s/it]                                                   67%|██████▋   | 762/1140 [45:18<19:58,  3.17s/it] 67%|██████▋   | 763/1140 [45:21<19:40,  3.13s/it]                                                   67%|██████▋   | 763/1140 [45:21<19:40,  3.13s/it] 67%|██████▋   | 764/1140 [45:24<19:20,  3.09s/it]                                                   67%|██████▋   | 764/1140 [45:24<19:20,  3.09s/it] 67%|██████▋   | 765/1140 [45:27<18:42,  2.99s/it]                                                   67%|██████▋   | 765/1140 [45:27<18:42,  2.99s/it] 67%|██████▋   | 766/1140 [45:29<17:01,  2.73s/it]                                                   67%|██████▋   | 766/1140 [45:29<17:01,  2.73s/it] 67%|██████▋   | 767/1140 [45:32<15:54,  2.56s/it]                                                   67%|██████▋   | 767/1140 [45:32<15:54,  2.56s/it] 67%|██████▋   | 768/1140 [45:34<15:05,  2.44s/it]                                                   67%|██████▋   | 768/1140 [45:34<15:05,  2.44s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 67%|██████▋   | 769/1140 [46:04<1:06:41, 10.79s/it]                                                     67%|██████▋   | 769/1140 [46:04<1:06:41, 10.79s/it] 68%|██████▊   | 770/1140 [46:07<52:49,  8.57s/it]                                                     68%|██████▊   | 770/1140 [46:07<52:49,  8.57s/it] 68%|██████▊   | 771/1140 [46:11<43:10,  7.02s/it]                                                   68%|██████▊   | 771/1140 [46:11<43:10,  7.02s/it] 68%|██████▊   | 772/1140 [46:14<36:04,  5.88s/it]                                                   68%|██████▊   | 772/1140 [46:14<36:04,  5.88s/it] 68%|██████▊   | 773/1140 [46:17<30:57,  5.06s/it]                                                   68%|██████▊   | 773/1140 [46:17<30:57,  5.06s/it] 68%|██████▊   | 774/1140 [46:20<27:30,  4.51s/it]                                                   68%|██████▊   | 774/1140 [46:20<27:30,  4.51s/it] 68%|██████▊   | 775/1140 [46:24<25:02,  4.12s/it]                                                   68%|██████▊   | 775/1140 [46:24<25:02,  4.12s/it] 68%|██████▊   | 776/1140 [46:27<23:21,  3.85s/it]                                                   68%|██████▊   | 776/1140 [46:27<23:21,  3.85s/it] 68%|██████▊   | 777/1140 [46:30<22:19,  3.69s/it]                                                   68%|██████▊   | 777/1140 [46:30<22:19,  3.69s/it] 68%|██████▊   | 778/1140 [46:33<21:39,  3.59s/it]                                                   68%|██████▊   | 778/1140 [46:33<21:39,  3.59s/it] 68%|██████▊   | 779/1140 [46:37<20:53,  3.47s/it]                                                   68%|██████▊   | 779/1140 [46:37<20:53,  3.47s/it] 68%|██████▊   | 780/1140 [46:40<20:08,  3.36s/it]                                                   68%|██████▊   | 780/1140 [46:40<20:08,  3.36s/it] 69%|██████▊   | 781/1140 [46:43<20:21,  3.40s/it]                                                   69%|██████▊   | 781/1140 [46:43<20:21,  3.40s/it] 69%|██████▊   | 782/1140 [46:46<19:44,  3.31s/it]                                                   69%|██████▊   | 782/1140 [46:46<19:44,  3.31s/it] 69%|██████▊   | 783/1140 [46:50<19:49,  3.33s/it]                                                   69%|██████▊   | 783/1140 [46:50<19:49,  3.33s/it] 69%|██████▉   | 784/1140 [46:53<19:55,  3.36s/it]                                                   69%|██████▉   | 784/1140 [46:53<19:55,  3.36s/it] 69%|██████▉   | 785/1140 [46:56<19:51,  3.35s/it]                                                   69%|██████▉   | 785/1140 [46:56<19:51,  3.35s/it] 69%|██████▉   | 786/1140 [47:00<19:36,  3.32s/it]                                                   69%|██████▉   | 786/1140 [47:00<19:36,  3.32s/it] 69%|██████▉   | 787/1140 [47:03<19:10,  3.26s/it]                                                   69%|██████▉   | 787/1140 [47:03<19:10,  3.26s/it] 69%|██████▉   | 788/1140 [47:06<18:57,  3.23s/it]                                                   69%|██████▉   | 788/1140 [47:06<18:57,  3.23s/it] 69%|██████▉   | 789/1140 [47:09<18:34,  3.18s/it]                                                   69%|██████▉   | 789/1140 [47:09<18:34,  3.18s/it] 69%|██████▉   | 790/1140 [47:12<18:24,  3.16s/it]                                                   69%|██████▉   | 790/1140 [47:12<18:24,  3.16s/it] 69%|██████▉   | 791/1140 [47:15<18:25,  3.17s/it]                                                   69%|██████▉   | 791/1140 [47:15<18:25,  3.17s/it] 69%|██████▉   | 792/1140 [47:18<18:15,  3.15s/it]                                                   69%|██████▉   | 792/1140 [47:18<18:15,  3.15s/it] 70%|██████▉   | 793/1140 [47:22<18:24,  3.18s/it]                                                   70%|██████▉   | 793/1140 [47:22<18:24,  3.18s/it] 70%|██████▉   | 794/1140 [47:25<18:10,  3.15s/it]                                                   70%|██████▉   | 794/1140 [47:25<18:10,  3.15s/it] 70%|██████▉   | 795/1140 [47:28<18:03,  3.14s/it]                                                   70%|██████▉   | 795/1140 [47:28<18:03,  3.14s/it] 70%|██████▉   | 796/1140 [47:31<18:14,  3.18s/it]                                                   70%|██████▉   | 796/1140 [47:31<18:14,  3.18s/it] 70%|██████▉   | 797/1140 [47:34<18:14,  3.19s/it]                                                   70%|██████▉   | 797/1140 [47:34<18:14,  3.19s/it] 70%|███████   | 798/1140 [47:38<18:02,  3.17s/it]                                                   70%|███████   | 798/1140 [47:38<18:02,  3.17s/it] 70%|███████   | 799/1140 [47:41<17:57,  3.16s/it]                                                   70%|███████   | 799/1140 [47:41<17:57,  3.16s/it] 70%|███████   | 800/1140 [47:44<17:52,  3.16s/it]                                                   70%|███████   | 800/1140 [47:44<17:52,  3.16s/it] 70%|███████   | 801/1140 [47:47<18:08,  3.21s/it]                                                   70%|███████   | 801/1140 [47:47<18:08,  3.21s/it] 70%|███████   | 802/1140 [47:50<17:47,  3.16s/it]                                                   70%|███████   | 802/1140 [47:50<17:47,  3.16s/it] 70%|███████   | 803/1140 [47:53<18:01,  3.21s/it]                                                   70%|███████   | 803/1140 [47:54<18:01,  3.21s/it] 71%|███████   | 804/1140 [47:57<18:06,  3.23s/it]                                                   71%|███████   | 804/1140 [47:57<18:06,  3.23s/it] 71%|███████   | 805/1140 [48:00<18:26,  3.30s/it]                                                   71%|███████   | 805/1140 [48:00<18:26,  3.30s/it] 71%|███████   | 806/1140 [48:03<18:14,  3.28s/it]                                                   71%|███████   | 806/1140 [48:03<18:14,  3.28s/it] 71%|███████   | 807/1140 [48:07<18:09,  3.27s/it]                                                   71%|███████   | 807/1140 [48:07<18:09,  3.27s/it] 71%|███████   | 808/1140 [48:10<18:11,  3.29s/it]                                                   71%|███████   | 808/1140 [48:10<18:11,  3.29s/it] 71%|███████   | 809/1140 [48:13<18:05,  3.28s/it]                                                   71%|███████   | 809/1140 [48:13<18:05,  3.28s/it] 71%|███████   | 810/1140 [48:17<18:03,  3.28s/it]                                                   71%|███████   | 810/1140 [48:17<18:03,  3.28s/it] 71%|███████   | 811/1140 [48:20<17:55,  3.27s/it]                                                   71%|███████   | 811/1140 [48:20<17:55,  3.27s/it] 71%|███████   | 812/1140 [48:23<17:40,  3.23s/it]                                                   71%|███████   | 812/1140 [48:23<17:40,  3.23s/it] 71%|███████▏  | 813/1140 [48:26<17:33,  3.22s/it]                                                   71%|███████▏  | 813/1140 [48:26<17:33,  3.22s/it] 71%|███████▏  | 814/1140 [48:29<17:36,  3.24s/it]                                                   71%|███████▏  | 814/1140 [48:29<17:36,  3.24s/it] 71%|███████▏  | 815/1140 [48:33<17:57,  3.31s/it]                                                   71%|███████▏  | 815/1140 [48:33<17:57,  3.31s/it] 72%|███████▏  | 816/1140 [48:36<17:39,  3.27s/it]                                                   72%|███████▏  | 816/1140 [48:36<17:39,  3.27s/it] 72%|███████▏  | 817/1140 [48:39<17:31,  3.26s/it]                                                   72%|███████▏  | 817/1140 [48:39<17:31,  3.26s/it] 72%|███████▏  | 818/1140 [48:42<17:14,  3.21s/it]                                                   72%|███████▏  | 818/1140 [48:42<17:14,  3.21s/it] 72%|███████▏  | 819/1140 [48:46<17:28,  3.26s/it]                                                   72%|███████▏  | 819/1140 [48:46<17:28,  3.26s/it] 72%|███████▏  | 820/1140 [48:49<17:21,  3.26s/it]                                                   72%|███████▏  | 820/1140 [48:49<17:21,  3.26s/it] 72%|███████▏  | 821/1140 [48:53<17:42,  3.33s/it]                                                   72%|███████▏  | 821/1140 [48:53<17:42,  3.33s/it] 72%|███████▏  | 822/1140 [48:56<17:50,  3.37s/it]                                                   72%|███████▏  | 822/1140 [48:56<17:50,  3.37s/it] 72%|███████▏  | 823/1140 [48:59<17:22,  3.29s/it]                                                   72%|███████▏  | 823/1140 [48:59<17:22,  3.29s/it] 72%|███████▏  | 824/1140 [49:03<17:25,  3.31s/it]                                                   72%|███████▏  | 824/1140 [49:03<17:25,  3.31s/it] 72%|███████▏  | 825/1140 [49:06<17:14,  3.29s/it]                                                   72%|███████▏  | 825/1140 [49:06<17:14,  3.29s/it] 72%|███████▏  | 826/1140 [49:09<17:10,  3.28s/it]                                                   72%|███████▏  | 826/1140 [49:09<17:10,  3.28s/it] 73%|███████▎  | 827/1140 [49:12<16:58,  3.25s/it]                                                   73%|███████▎  | 827/1140 [49:12<16:58,  3.25s/it] 73%|███████▎  | 828/1140 [49:15<16:44,  3.22s/it]                                                   73%|███████▎  | 828/1140 [49:15<16:44,  3.22s/it] 73%|███████▎  | 829/1140 [49:19<16:48,  3.24s/it]                                                   73%|███████▎  | 829/1140 [49:19<16:48,  3.24s/it] 73%|███████▎  | 830/1140 [49:22<17:03,  3.30s/it]                                                   73%|███████▎  | 830/1140 [49:22<17:03,  3.30s/it] 73%|███████▎  | 831/1140 [49:25<17:04,  3.32s/it]                                                   73%|███████▎  | 831/1140 [49:25<17:04,  3.32s/it] 73%|███████▎  | 832/1140 [49:29<17:01,  3.32s/it]                                                   73%|███████▎  | 832/1140 [49:29<17:01,  3.32s/it] 73%|███████▎  | 833/1140 [49:32<17:18,  3.38s/it]                                                   73%|███████▎  | 833/1140 [49:32<17:18,  3.38s/it] 73%|███████▎  | 834/1140 [49:36<17:03,  3.34s/it]                                                   73%|███████▎  | 834/1140 [49:36<17:03,  3.34s/it] 73%|███████▎  | 835/1140 [49:39<16:59,  3.34s/it]                                                   73%|███████▎  | 835/1140 [49:39<16:59,  3.34s/it] 73%|███████▎  | 836/1140 [49:42<16:49,  3.32s/it]                                                   73%|███████▎  | 836/1140 [49:42<16:49,  3.32s/it] 73%|███████▎  | 837/1140 [49:45<16:14,  3.22s/it]                                                   73%|███████▎  | 837/1140 [49:45<16:14,  3.22s/it] 74%|███████▎  | 838/1140 [49:48<15:55,  3.16s/it]                                                   74%|███████▎  | 838/1140 [49:48<15:55,  3.16s/it] 74%|███████▎  | 839/1140 [49:51<15:46,  3.14s/it]                                                   74%|███████▎  | 839/1140 [49:51<15:46,  3.14s/it] 74%|███████▎  | 840/1140 [49:55<16:07,  3.22s/it]                                                   74%|███████▎  | 840/1140 [49:55<16:07,  3.22s/it] 74%|███████▍  | 841/1140 [49:58<16:10,  3.25s/it]                                                   74%|███████▍  | 841/1140 [49:58<16:10,  3.25s/it] 74%|███████▍  | 842/1140 [50:01<15:39,  3.15s/it]                                                   74%|███████▍  | 842/1140 [50:01<15:39,  3.15s/it] 74%|███████▍  | 843/1140 [50:03<14:32,  2.94s/it]                                                   74%|███████▍  | 843/1140 [50:03<14:32,  2.94s/it] 74%|███████▍  | 844/1140 [50:06<13:28,  2.73s/it]                                                   74%|███████▍  | 844/1140 [50:06<13:28,  2.73s/it] 74%|███████▍  | 845/1140 [50:08<12:44,  2.59s/it]                                                   74%|███████▍  | 845/1140 [50:08<12:44,  2.59s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 74%|███████▍  | 846/1140 [50:39<54:21, 11.09s/it]                                                   74%|███████▍  | 846/1140 [50:39<54:21, 11.09s/it] 74%|███████▍  | 847/1140 [50:42<42:54,  8.79s/it]                                                   74%|███████▍  | 847/1140 [50:42<42:54,  8.79s/it] 74%|███████▍  | 848/1140 [50:46<34:57,  7.18s/it]                                                   74%|███████▍  | 848/1140 [50:46<34:57,  7.18s/it] 74%|███████▍  | 849/1140 [50:49<29:17,  6.04s/it]                                                   74%|███████▍  | 849/1140 [50:49<29:17,  6.04s/it] 75%|███████▍  | 850/1140 [50:52<25:21,  5.25s/it]                                                   75%|███████▍  | 850/1140 [50:52<25:21,  5.25s/it] 75%|███████▍  | 851/1140 [50:56<22:44,  4.72s/it]                                                   75%|███████▍  | 851/1140 [50:56<22:44,  4.72s/it] 75%|███████▍  | 852/1140 [50:59<20:58,  4.37s/it]                                                   75%|███████▍  | 852/1140 [50:59<20:58,  4.37s/it] 75%|███████▍  | 853/1140 [51:03<19:34,  4.09s/it]                                                   75%|███████▍  | 853/1140 [51:03<19:34,  4.09s/it] 75%|███████▍  | 854/1140 [51:06<18:31,  3.89s/it]                                                   75%|███████▍  | 854/1140 [51:06<18:31,  3.89s/it] 75%|███████▌  | 855/1140 [51:10<17:38,  3.71s/it]                                                   75%|███████▌  | 855/1140 [51:10<17:38,  3.71s/it] 75%|███████▌  | 856/1140 [51:13<16:57,  3.58s/it]                                                   75%|███████▌  | 856/1140 [51:13<16:57,  3.58s/it] 75%|███████▌  | 857/1140 [51:16<16:30,  3.50s/it]                                                   75%|███████▌  | 857/1140 [51:16<16:30,  3.50s/it] 75%|███████▌  | 858/1140 [51:19<16:05,  3.42s/it]                                                   75%|███████▌  | 858/1140 [51:19<16:05,  3.42s/it] 75%|███████▌  | 859/1140 [51:23<15:57,  3.41s/it]                                                   75%|███████▌  | 859/1140 [51:23<15:57,  3.41s/it] 75%|███████▌  | 860/1140 [51:26<15:33,  3.33s/it]                                                   75%|███████▌  | 860/1140 [51:26<15:33,  3.33s/it] 76%|███████▌  | 861/1140 [51:29<15:30,  3.34s/it]                                                   76%|███████▌  | 861/1140 [51:29<15:30,  3.34s/it] 76%|███████▌  | 862/1140 [51:32<15:13,  3.29s/it]                                                   76%|███████▌  | 862/1140 [51:32<15:13,  3.29s/it] 76%|███████▌  | 863/1140 [51:36<14:59,  3.25s/it]                                                   76%|███████▌  | 863/1140 [51:36<14:59,  3.25s/it] 76%|███████▌  | 864/1140 [51:39<14:46,  3.21s/it]                                                   76%|███████▌  | 864/1140 [51:39<14:46,  3.21s/it] 76%|███████▌  | 865/1140 [51:42<14:45,  3.22s/it]                                                   76%|███████▌  | 865/1140 [51:42<14:45,  3.22s/it] 76%|███████▌  | 866/1140 [51:45<14:25,  3.16s/it]                                                   76%|███████▌  | 866/1140 [51:45<14:25,  3.16s/it] 76%|███████▌  | 867/1140 [51:48<14:37,  3.21s/it]                                                   76%|███████▌  | 867/1140 [51:48<14:37,  3.21s/it] 76%|███████▌  | 868/1140 [51:52<14:49,  3.27s/it]                                                   76%|███████▌  | 868/1140 [51:52<14:49,  3.27s/it] 76%|███████▌  | 869/1140 [51:55<14:41,  3.25s/it]                                                   76%|███████▌  | 869/1140 [51:55<14:41,  3.25s/it] 76%|███████▋  | 870/1140 [51:58<14:31,  3.23s/it]                                                   76%|███████▋  | 870/1140 [51:58<14:31,  3.23s/it] 76%|███████▋  | 871/1140 [52:02<14:42,  3.28s/it]                                                   76%|███████▋  | 871/1140 [52:02<14:42,  3.28s/it] 76%|███████▋  | 872/1140 [52:05<14:23,  3.22s/it]                                                   76%|███████▋  | 872/1140 [52:05<14:23,  3.22s/it] 77%|███████▋  | 873/1140 [52:08<14:28,  3.25s/it]                                                   77%|███████▋  | 873/1140 [52:08<14:28,  3.25s/it] 77%|███████▋  | 874/1140 [52:11<14:12,  3.21s/it]                                                   77%|███████▋  | 874/1140 [52:11<14:12,  3.21s/it] 77%|███████▋  | 875/1140 [52:14<14:01,  3.18s/it]                                                   77%|███████▋  | 875/1140 [52:14<14:01,  3.18s/it] 77%|███████▋  | 876/1140 [52:17<14:11,  3.23s/it]                                                   77%|███████▋  | 876/1140 [52:17<14:11,  3.23s/it] 77%|███████▋  | 877/1140 [52:21<14:06,  3.22s/it]                                                   77%|███████▋  | 877/1140 [52:21<14:06,  3.22s/it] 77%|███████▋  | 878/1140 [52:24<14:08,  3.24s/it]                                                   77%|███████▋  | 878/1140 [52:24<14:08,  3.24s/it] 77%|███████▋  | 879/1140 [52:27<14:05,  3.24s/it]                                                   77%|███████▋  | 879/1140 [52:27<14:05,  3.24s/it] 77%|███████▋  | 880/1140 [52:30<13:58,  3.22s/it]                                                   77%|███████▋  | 880/1140 [52:30<13:58,  3.22s/it] 77%|███████▋  | 881/1140 [52:34<14:01,  3.25s/it]                                                   77%|███████▋  | 881/1140 [52:34<14:01,  3.25s/it] 77%|███████▋  | 882/1140 [52:37<13:48,  3.21s/it]                                                   77%|███████▋  | 882/1140 [52:37<13:48,  3.21s/it] 77%|███████▋  | 883/1140 [52:40<14:01,  3.27s/it]                                                   77%|███████▋  | 883/1140 [52:40<14:01,  3.27s/it] 78%|███████▊  | 884/1140 [52:44<14:00,  3.28s/it]                                                   78%|███████▊  | 884/1140 [52:44<14:00,  3.28s/it] 78%|███████▊  | 885/1140 [52:47<14:02,  3.30s/it]                                                   78%|███████▊  | 885/1140 [52:47<14:02,  3.30s/it] 78%|███████▊  | 886/1140 [52:50<13:48,  3.26s/it]                                                   78%|███████▊  | 886/1140 [52:50<13:48,  3.26s/it] 78%|███████▊  | 887/1140 [52:54<13:59,  3.32s/it]                                                   78%|███████▊  | 887/1140 [52:54<13:59,  3.32s/it] 78%|███████▊  | 888/1140 [52:57<13:54,  3.31s/it]                                                   78%|███████▊  | 888/1140 [52:57<13:54,  3.31s/it] 78%|███████▊  | 889/1140 [53:00<13:25,  3.21s/it]                                                   78%|███████▊  | 889/1140 [53:00<13:25,  3.21s/it] 78%|███████▊  | 890/1140 [53:03<13:28,  3.23s/it]                                                   78%|███████▊  | 890/1140 [53:03<13:28,  3.23s/it] 78%|███████▊  | 891/1140 [53:06<13:30,  3.26s/it]                                                   78%|███████▊  | 891/1140 [53:06<13:30,  3.26s/it] 78%|███████▊  | 892/1140 [53:10<13:18,  3.22s/it]                                                   78%|███████▊  | 892/1140 [53:10<13:18,  3.22s/it] 78%|███████▊  | 893/1140 [53:13<13:37,  3.31s/it]                                                   78%|███████▊  | 893/1140 [53:13<13:37,  3.31s/it] 78%|███████▊  | 894/1140 [53:16<13:23,  3.27s/it]                                                   78%|███████▊  | 894/1140 [53:16<13:23,  3.27s/it] 79%|███████▊  | 895/1140 [53:19<13:11,  3.23s/it]                                                   79%|███████▊  | 895/1140 [53:19<13:11,  3.23s/it] 79%|███████▊  | 896/1140 [53:23<13:34,  3.34s/it]                                                   79%|███████▊  | 896/1140 [53:23<13:34,  3.34s/it] 79%|███████▊  | 897/1140 [53:26<13:22,  3.30s/it]                                                   79%|███████▊  | 897/1140 [53:26<13:22,  3.30s/it] 79%|███████▉  | 898/1140 [53:29<13:18,  3.30s/it]                                                   79%|███████▉  | 898/1140 [53:29<13:18,  3.30s/it] 79%|███████▉  | 899/1140 [53:33<13:02,  3.24s/it]                                                   79%|███████▉  | 899/1140 [53:33<13:02,  3.24s/it] 79%|███████▉  | 900/1140 [53:36<13:09,  3.29s/it]                                                   79%|███████▉  | 900/1140 [53:36<13:09,  3.29s/it] 79%|███████▉  | 901/1140 [53:39<13:04,  3.28s/it]                                                   79%|███████▉  | 901/1140 [53:39<13:04,  3.28s/it] 79%|███████▉  | 902/1140 [53:43<13:05,  3.30s/it]                                                   79%|███████▉  | 902/1140 [53:43<13:05,  3.30s/it] 79%|███████▉  | 903/1140 [53:46<13:01,  3.30s/it]                                                   79%|███████▉  | 903/1140 [53:46<13:01,  3.30s/it] 79%|███████▉  | 904/1140 [53:49<13:00,  3.31s/it]                                                   79%|███████▉  | 904/1140 [53:49<13:00,  3.31s/it] 79%|███████▉  | 905/1140 [53:52<12:42,  3.25s/it]                                                   79%|███████▉  | 905/1140 [53:52<12:42,  3.25s/it] 79%|███████▉  | 906/1140 [53:56<12:45,  3.27s/it]                                                   79%|███████▉  | 906/1140 [53:56<12:45,  3.27s/it] 80%|███████▉  | 907/1140 [53:59<12:51,  3.31s/it]                                                   80%|███████▉  | 907/1140 [53:59<12:51,  3.31s/it] 80%|███████▉  | 908/1140 [54:02<12:35,  3.26s/it]                                                   80%|███████▉  | 908/1140 [54:02<12:35,  3.26s/it] 80%|███████▉  | 909/1140 [54:06<12:39,  3.29s/it]                                                   80%|███████▉  | 909/1140 [54:06<12:39,  3.29s/it] 80%|███████▉  | 910/1140 [54:09<12:29,  3.26s/it]                                                   80%|███████▉  | 910/1140 [54:09<12:29,  3.26s/it] 80%|███████▉  | 911/1140 [54:12<12:09,  3.19s/it]                                                   80%|███████▉  | 911/1140 [54:12<12:09,  3.19s/it] 80%|████████  | 912/1140 [54:15<12:13,  3.22s/it]                                                   80%|████████  | 912/1140 [54:15<12:13,  3.22s/it] 80%|████████  | 913/1140 [54:18<12:05,  3.20s/it]                                                   80%|████████  | 913/1140 [54:18<12:05,  3.20s/it] 80%|████████  | 914/1140 [54:21<11:51,  3.15s/it]                                                   80%|████████  | 914/1140 [54:21<11:51,  3.15s/it] 80%|████████  | 915/1140 [54:24<11:34,  3.08s/it]                                                   80%|████████  | 915/1140 [54:24<11:34,  3.08s/it] 80%|████████  | 916/1140 [54:27<11:32,  3.09s/it]                                                   80%|████████  | 916/1140 [54:27<11:32,  3.09s/it] 80%|████████  | 917/1140 [54:30<11:29,  3.09s/it]                                                   80%|████████  | 917/1140 [54:30<11:29,  3.09s/it] 81%|████████  | 918/1140 [54:34<11:37,  3.14s/it]                                                   81%|████████  | 918/1140 [54:34<11:37,  3.14s/it] 81%|████████  | 919/1140 [54:36<11:12,  3.04s/it]                                                   81%|████████  | 919/1140 [54:36<11:12,  3.04s/it] 81%|████████  | 920/1140 [54:39<10:18,  2.81s/it]                                                   81%|████████  | 920/1140 [54:39<10:18,  2.81s/it] 81%|████████  | 921/1140 [54:42<10:20,  2.83s/it]                                                   81%|████████  | 921/1140 [54:42<10:20,  2.83s/it] 81%|████████  | 922/1140 [54:44<10:10,  2.80s/it]                                                   81%|████████  | 922/1140 [54:44<10:10,  2.80s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 81%|████████  | 923/1140 [55:17<42:40, 11.80s/it]                                                   81%|████████  | 923/1140 [55:17<42:40, 11.80s/it] 81%|████████  | 924/1140 [55:21<33:26,  9.29s/it]                                                   81%|████████  | 924/1140 [55:21<33:26,  9.29s/it] 81%|████████  | 925/1140 [55:24<26:43,  7.46s/it]                                                   81%|████████  | 925/1140 [55:24<26:43,  7.46s/it] 81%|████████  | 926/1140 [55:27<22:08,  6.21s/it]                                                   81%|████████  | 926/1140 [55:27<22:08,  6.21s/it] 81%|████████▏ | 927/1140 [55:30<19:01,  5.36s/it]                                                   81%|████████▏ | 927/1140 [55:30<19:01,  5.36s/it] 81%|████████▏ | 928/1140 [55:34<16:43,  4.73s/it]                                                   81%|████████▏ | 928/1140 [55:34<16:43,  4.73s/it] 81%|████████▏ | 929/1140 [55:37<15:09,  4.31s/it]                                                   81%|████████▏ | 929/1140 [55:37<15:09,  4.31s/it] 82%|████████▏ | 930/1140 [55:40<14:07,  4.04s/it]                                                   82%|████████▏ | 930/1140 [55:40<14:07,  4.04s/it] 82%|████████▏ | 931/1140 [55:44<13:33,  3.89s/it]                                                   82%|████████▏ | 931/1140 [55:44<13:33,  3.89s/it] 82%|████████▏ | 932/1140 [55:47<12:35,  3.63s/it]                                                   82%|████████▏ | 932/1140 [55:47<12:35,  3.63s/it] 82%|████████▏ | 933/1140 [55:50<12:02,  3.49s/it]                                                   82%|████████▏ | 933/1140 [55:50<12:02,  3.49s/it] 82%|████████▏ | 934/1140 [55:53<11:29,  3.35s/it]                                                   82%|████████▏ | 934/1140 [55:53<11:29,  3.35s/it] 82%|████████▏ | 935/1140 [55:56<11:19,  3.31s/it]                                                   82%|████████▏ | 935/1140 [55:56<11:19,  3.31s/it] 82%|████████▏ | 936/1140 [55:59<10:55,  3.21s/it]                                                   82%|████████▏ | 936/1140 [55:59<10:55,  3.21s/it] 82%|████████▏ | 937/1140 [56:02<10:43,  3.17s/it]                                                   82%|████████▏ | 937/1140 [56:02<10:43,  3.17s/it] 82%|████████▏ | 938/1140 [56:05<10:34,  3.14s/it]                                                   82%|████████▏ | 938/1140 [56:05<10:34,  3.14s/it] 82%|████████▏ | 939/1140 [56:09<10:41,  3.19s/it]                                                   82%|████████▏ | 939/1140 [56:09<10:41,  3.19s/it] 82%|████████▏ | 940/1140 [56:12<10:38,  3.19s/it]                                                   82%|████████▏ | 940/1140 [56:12<10:38,  3.19s/it] 83%|████████▎ | 941/1140 [56:15<10:46,  3.25s/it]                                                   83%|████████▎ | 941/1140 [56:15<10:46,  3.25s/it] 83%|████████▎ | 942/1140 [56:19<10:40,  3.23s/it]                                                   83%|████████▎ | 942/1140 [56:19<10:40,  3.23s/it] 83%|████████▎ | 943/1140 [56:22<10:34,  3.22s/it]                                                   83%|████████▎ | 943/1140 [56:22<10:34,  3.22s/it] 83%|████████▎ | 944/1140 [56:25<10:40,  3.27s/it]                                                   83%|████████▎ | 944/1140 [56:25<10:40,  3.27s/it] 83%|████████▎ | 945/1140 [56:28<10:21,  3.19s/it]                                                   83%|████████▎ | 945/1140 [56:28<10:21,  3.19s/it] 83%|████████▎ | 946/1140 [56:31<10:23,  3.22s/it]                                                   83%|████████▎ | 946/1140 [56:31<10:23,  3.22s/it] 83%|████████▎ | 947/1140 [56:35<10:26,  3.25s/it]                                                   83%|████████▎ | 947/1140 [56:35<10:26,  3.25s/it] 83%|████████▎ | 948/1140 [56:38<10:32,  3.29s/it]                                                   83%|████████▎ | 948/1140 [56:38<10:32,  3.29s/it] 83%|████████▎ | 949/1140 [56:42<10:35,  3.33s/it]                                                   83%|████████▎ | 949/1140 [56:42<10:35,  3.33s/it] 83%|████████▎ | 950/1140 [56:45<10:18,  3.26s/it]                                                   83%|████████▎ | 950/1140 [56:45<10:18,  3.26s/it] 83%|████████▎ | 951/1140 [56:48<10:28,  3.32s/it]                                                   83%|████████▎ | 951/1140 [56:48<10:28,  3.32s/it] 84%|████████▎ | 952/1140 [56:51<10:18,  3.29s/it]                                                   84%|████████▎ | 952/1140 [56:51<10:18,  3.29s/it] 84%|████████▎ | 953/1140 [56:55<10:30,  3.37s/it]                                                   84%|████████▎ | 953/1140 [56:55<10:30,  3.37s/it] 84%|████████▎ | 954/1140 [56:58<10:10,  3.28s/it]                                                   84%|████████▎ | 954/1140 [56:58<10:10,  3.28s/it] 84%|████████▍ | 955/1140 [57:01<10:06,  3.28s/it]                                                   84%|████████▍ | 955/1140 [57:01<10:06,  3.28s/it] 84%|████████▍ | 956/1140 [57:04<09:59,  3.26s/it]                                                   84%|████████▍ | 956/1140 [57:04<09:59,  3.26s/it] 84%|████████▍ | 957/1140 [57:08<10:03,  3.30s/it]                                                   84%|████████▍ | 957/1140 [57:08<10:03,  3.30s/it] 84%|████████▍ | 958/1140 [57:11<09:44,  3.21s/it]                                                   84%|████████▍ | 958/1140 [57:11<09:44,  3.21s/it] 84%|████████▍ | 959/1140 [57:14<09:38,  3.20s/it]                                                   84%|████████▍ | 959/1140 [57:14<09:38,  3.20s/it] 84%|████████▍ | 960/1140 [57:17<09:35,  3.20s/it]                                                   84%|████████▍ | 960/1140 [57:17<09:35,  3.20s/it] 84%|████████▍ | 961/1140 [57:21<09:39,  3.24s/it]                                                   84%|████████▍ | 961/1140 [57:21<09:39,  3.24s/it] 84%|████████▍ | 962/1140 [57:23<09:21,  3.15s/it]                                                   84%|████████▍ | 962/1140 [57:23<09:21,  3.15s/it] 84%|████████▍ | 963/1140 [57:27<09:14,  3.13s/it]                                                   84%|████████▍ | 963/1140 [57:27<09:14,  3.13s/it] 85%|████████▍ | 964/1140 [57:30<09:12,  3.14s/it]                                                   85%|████████▍ | 964/1140 [57:30<09:12,  3.14s/it] 85%|████████▍ | 965/1140 [57:33<09:21,  3.21s/it]                                                   85%|████████▍ | 965/1140 [57:33<09:21,  3.21s/it] 85%|████████▍ | 966/1140 [57:37<09:28,  3.27s/it]                                                   85%|████████▍ | 966/1140 [57:37<09:28,  3.27s/it] 85%|████████▍ | 967/1140 [57:40<09:14,  3.20s/it]                                                   85%|████████▍ | 967/1140 [57:40<09:14,  3.20s/it] 85%|████████▍ | 968/1140 [57:43<09:02,  3.16s/it]                                                   85%|████████▍ | 968/1140 [57:43<09:02,  3.16s/it] 85%|████████▌ | 969/1140 [57:46<09:10,  3.22s/it]                                                   85%|████████▌ | 969/1140 [57:46<09:10,  3.22s/it] 85%|████████▌ | 970/1140 [57:49<09:05,  3.21s/it]                                                   85%|████████▌ | 970/1140 [57:49<09:05,  3.21s/it] 85%|████████▌ | 971/1140 [57:53<09:11,  3.26s/it]                                                   85%|████████▌ | 971/1140 [57:53<09:11,  3.26s/it] 85%|████████▌ | 972/1140 [57:56<09:01,  3.23s/it]                                                   85%|████████▌ | 972/1140 [57:56<09:01,  3.23s/it] 85%|████████▌ | 973/1140 [57:59<08:51,  3.18s/it]                                                   85%|████████▌ | 973/1140 [57:59<08:51,  3.18s/it] 85%|████████▌ | 974/1140 [58:02<08:53,  3.21s/it]                                                   85%|████████▌ | 974/1140 [58:02<08:53,  3.21s/it] 86%|████████▌ | 975/1140 [58:05<08:48,  3.20s/it]                                                   86%|████████▌ | 975/1140 [58:05<08:48,  3.20s/it] 86%|████████▌ | 976/1140 [58:09<08:54,  3.26s/it]                                                   86%|████████▌ | 976/1140 [58:09<08:54,  3.26s/it] 86%|████████▌ | 977/1140 [58:12<08:56,  3.29s/it]                                                   86%|████████▌ | 977/1140 [58:12<08:56,  3.29s/it] 86%|████████▌ | 978/1140 [58:15<09:00,  3.34s/it]                                                   86%|████████▌ | 978/1140 [58:15<09:00,  3.34s/it] 86%|████████▌ | 979/1140 [58:19<08:59,  3.35s/it]                                                   86%|████████▌ | 979/1140 [58:19<08:59,  3.35s/it] 86%|████████▌ | 980/1140 [58:22<08:57,  3.36s/it]                                                   86%|████████▌ | 980/1140 [58:22<08:57,  3.36s/it] 86%|████████▌ | 981/1140 [58:26<08:52,  3.35s/it]                                                   86%|████████▌ | 981/1140 [58:26<08:52,  3.35s/it] 86%|████████▌ | 982/1140 [58:29<08:46,  3.33s/it]                                                   86%|████████▌ | 982/1140 [58:29<08:46,  3.33s/it] 86%|████████▌ | 983/1140 [58:32<08:42,  3.33s/it]                                                   86%|████████▌ | 983/1140 [58:32<08:42,  3.33s/it] 86%|████████▋ | 984/1140 [58:35<08:32,  3.29s/it]                                                   86%|████████▋ | 984/1140 [58:35<08:32,  3.29s/it] 86%|████████▋ | 985/1140 [58:38<08:22,  3.24s/it]                                                   86%|████████▋ | 985/1140 [58:38<08:22,  3.24s/it] 86%|████████▋ | 986/1140 [58:42<08:23,  3.27s/it]                                                   86%|████████▋ | 986/1140 [58:42<08:23,  3.27s/it] 87%|████████▋ | 987/1140 [58:45<08:18,  3.26s/it]                                                   87%|████████▋ | 987/1140 [58:45<08:18,  3.26s/it] 87%|████████▋ | 988/1140 [58:49<08:26,  3.33s/it]                                                   87%|████████▋ | 988/1140 [58:49<08:26,  3.33s/it] 87%|████████▋ | 989/1140 [58:52<08:17,  3.29s/it]                                                   87%|████████▋ | 989/1140 [58:52<08:17,  3.29s/it] 87%|████████▋ | 990/1140 [58:55<08:29,  3.40s/it]                                                   87%|████████▋ | 990/1140 [58:55<08:29,  3.40s/it] 87%|████████▋ | 991/1140 [58:59<08:22,  3.37s/it]                                                   87%|████████▋ | 991/1140 [58:59<08:22,  3.37s/it] 87%|████████▋ | 992/1140 [59:02<08:16,  3.36s/it]                                                   87%|████████▋ | 992/1140 [59:02<08:16,  3.36s/it] 87%|████████▋ | 993/1140 [59:05<08:09,  3.33s/it]                                                   87%|████████▋ | 993/1140 [59:05<08:09,  3.33s/it] 87%|████████▋ | 994/1140 [59:09<08:05,  3.33s/it]                                                   87%|████████▋ | 994/1140 [59:09<08:05,  3.33s/it] 87%|████████▋ | 995/1140 [59:12<08:01,  3.32s/it]                                                   87%|████████▋ | 995/1140 [59:12<08:01,  3.32s/it] 87%|████████▋ | 996/1140 [59:15<07:35,  3.17s/it]                                                   87%|████████▋ | 996/1140 [59:15<07:35,  3.17s/it] 87%|████████▋ | 997/1140 [59:17<06:54,  2.90s/it]                                                   87%|████████▋ | 997/1140 [59:17<06:54,  2.90s/it] 88%|████████▊ | 998/1140 [59:19<06:24,  2.71s/it]                                                   88%|████████▊ | 998/1140 [59:19<06:24,  2.71s/it] 88%|████████▊ | 999/1140 [59:22<06:09,  2.62s/it]                                                   88%|████████▊ | 999/1140 [59:22<06:09,  2.62s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 88%|████████▊ | 1000/1140 [59:54<26:35, 11.40s/it]                                                    88%|████████▊ | 1000/1140 [59:54<26:35, 11.40s/it] 88%|████████▊ | 1001/1140 [59:57<20:53,  9.02s/it]                                                    88%|████████▊ | 1001/1140 [59:57<20:53,  9.02s/it] 88%|████████▊ | 1002/1140 [1:00:00<16:50,  7.33s/it]                                                      88%|████████▊ | 1002/1140 [1:00:00<16:50,  7.33s/it] 88%|████████▊ | 1003/1140 [1:00:04<13:57,  6.11s/it]                                                      88%|████████▊ | 1003/1140 [1:00:04<13:57,  6.11s/it] 88%|████████▊ | 1004/1140 [1:00:07<11:54,  5.25s/it]                                                      88%|████████▊ | 1004/1140 [1:00:07<11:54,  5.25s/it] 88%|████████▊ | 1005/1140 [1:00:10<10:32,  4.69s/it]                                                      88%|████████▊ | 1005/1140 [1:00:10<10:32,  4.69s/it] 88%|████████▊ | 1006/1140 [1:00:14<09:32,  4.27s/it]                                                      88%|████████▊ | 1006/1140 [1:00:14<09:32,  4.27s/it] 88%|████████▊ | 1007/1140 [1:00:17<08:50,  3.99s/it]                                                      88%|████████▊ | 1007/1140 [1:00:17<08:50,  3.99s/it] 88%|████████▊ | 1008/1140 [1:00:20<08:24,  3.82s/it]                                                      88%|████████▊ | 1008/1140 [1:00:20<08:24,  3.82s/it] 89%|████████▊ | 1009/1140 [1:00:24<07:56,  3.64s/it]                                                      89%|████████▊ | 1009/1140 [1:00:24<07:56,  3.64s/it] 89%|████████▊ | 1010/1140 [1:00:27<07:37,  3.52s/it]                                                      89%|████████▊ | 1010/1140 [1:00:27<07:37,  3.52s/it] 89%|████████▊ | 1011/1140 [1:00:30<07:27,  3.47s/it]                                                      89%|████████▊ | 1011/1140 [1:00:30<07:27,  3.47s/it] 89%|████████▉ | 1012/1140 [1:00:33<07:10,  3.36s/it]                                                      89%|████████▉ | 1012/1140 [1:00:33<07:10,  3.36s/it] 89%|████████▉ | 1013/1140 [1:00:37<07:08,  3.37s/it]                                                      89%|████████▉ | 1013/1140 [1:00:37<07:08,  3.37s/it] 89%|████████▉ | 1014/1140 [1:00:40<06:55,  3.30s/it]                                                      89%|████████▉ | 1014/1140 [1:00:40<06:55,  3.30s/it] 89%|████████▉ | 1015/1140 [1:00:43<06:47,  3.26s/it]                                                      89%|████████▉ | 1015/1140 [1:00:43<06:47,  3.26s/it] 89%|████████▉ | 1016/1140 [1:00:46<06:37,  3.21s/it]                                                      89%|████████▉ | 1016/1140 [1:00:46<06:37,  3.21s/it] 89%|████████▉ | 1017/1140 [1:00:49<06:41,  3.26s/it]                                                      89%|████████▉ | 1017/1140 [1:00:49<06:41,  3.26s/it] 89%|████████▉ | 1018/1140 [1:00:53<06:40,  3.28s/it]                                                      89%|████████▉ | 1018/1140 [1:00:53<06:40,  3.28s/it] 89%|████████▉ | 1019/1140 [1:00:56<06:41,  3.32s/it]                                                      89%|████████▉ | 1019/1140 [1:00:56<06:41,  3.32s/it] 89%|████████▉ | 1020/1140 [1:00:59<06:36,  3.31s/it]                                                      89%|████████▉ | 1020/1140 [1:00:59<06:36,  3.31s/it] 90%|████████▉ | 1021/1140 [1:01:03<06:35,  3.32s/it]                                                      90%|████████▉ | 1021/1140 [1:01:03<06:35,  3.32s/it] 90%|████████▉ | 1022/1140 [1:01:06<06:25,  3.27s/it]                                                      90%|████████▉ | 1022/1140 [1:01:06<06:25,  3.27s/it] 90%|████████▉ | 1023/1140 [1:01:09<06:23,  3.28s/it]                                                      90%|████████▉ | 1023/1140 [1:01:09<06:23,  3.28s/it] 90%|████████▉ | 1024/1140 [1:01:12<06:17,  3.26s/it]                                                      90%|████████▉ | 1024/1140 [1:01:12<06:17,  3.26s/it] 90%|████████▉ | 1025/1140 [1:01:16<06:13,  3.25s/it]                                                      90%|████████▉ | 1025/1140 [1:01:16<06:13,  3.25s/it] 90%|█████████ | 1026/1140 [1:01:19<06:03,  3.19s/it]                                                      90%|█████████ | 1026/1140 [1:01:19<06:03,  3.19s/it] 90%|█████████ | 1027/1140 [1:01:22<05:55,  3.15s/it]                                                      90%|█████████ | 1027/1140 [1:01:22<05:55,  3.15s/it] 90%|█████████ | 1028/1140 [1:01:25<05:43,  3.07s/it]                                                      90%|█████████ | 1028/1140 [1:01:25<05:43,  3.07s/it] 90%|█████████ | 1029/1140 [1:01:28<05:39,  3.06s/it]                                                      90%|█████████ | 1029/1140 [1:01:28<05:39,  3.06s/it] 90%|█████████ | 1030/1140 [1:01:31<05:33,  3.03s/it]                                                      90%|█████████ | 1030/1140 [1:01:31<05:33,  3.03s/it] 90%|█████████ | 1031/1140 [1:01:34<05:41,  3.14s/it]                                                      90%|█████████ | 1031/1140 [1:01:34<05:41,  3.14s/it] 91%|█████████ | 1032/1140 [1:01:37<05:39,  3.14s/it]                                                      91%|█████████ | 1032/1140 [1:01:37<05:39,  3.14s/it] 91%|█████████ | 1033/1140 [1:01:40<05:41,  3.19s/it]                                                      91%|█████████ | 1033/1140 [1:01:40<05:41,  3.19s/it] 91%|█████████ | 1034/1140 [1:01:44<05:42,  3.24s/it]                                                      91%|█████████ | 1034/1140 [1:01:44<05:42,  3.24s/it] 91%|█████████ | 1035/1140 [1:01:47<05:42,  3.26s/it]                                                      91%|█████████ | 1035/1140 [1:01:47<05:42,  3.26s/it] 91%|█████████ | 1036/1140 [1:01:51<05:43,  3.30s/it]                                                      91%|█████████ | 1036/1140 [1:01:51<05:43,  3.30s/it] 91%|█████████ | 1037/1140 [1:01:54<05:32,  3.23s/it]                                                      91%|█████████ | 1037/1140 [1:01:54<05:32,  3.23s/it] 91%|█████████ | 1038/1140 [1:01:57<05:29,  3.23s/it]                                                      91%|█████████ | 1038/1140 [1:01:57<05:29,  3.23s/it] 91%|█████████ | 1039/1140 [1:02:00<05:31,  3.28s/it]                                                      91%|█████████ | 1039/1140 [1:02:00<05:31,  3.28s/it] 91%|█████████ | 1040/1140 [1:02:03<05:25,  3.25s/it]                                                      91%|█████████ | 1040/1140 [1:02:03<05:25,  3.25s/it] 91%|█████████▏| 1041/1140 [1:02:07<05:24,  3.28s/it]                                                      91%|█████████▏| 1041/1140 [1:02:07<05:24,  3.28s/it] 91%|█████████▏| 1042/1140 [1:02:10<05:17,  3.24s/it]                                                      91%|█████████▏| 1042/1140 [1:02:10<05:17,  3.24s/it] 91%|█████████▏| 1043/1140 [1:02:13<05:11,  3.21s/it]                                                      91%|█████████▏| 1043/1140 [1:02:13<05:11,  3.21s/it] 92%|█████████▏| 1044/1140 [1:02:16<05:11,  3.25s/it]                                                      92%|█████████▏| 1044/1140 [1:02:16<05:11,  3.25s/it] 92%|█████████▏| 1045/1140 [1:02:20<05:11,  3.28s/it]                                                      92%|█████████▏| 1045/1140 [1:02:20<05:11,  3.28s/it] 92%|█████████▏| 1046/1140 [1:02:23<05:09,  3.29s/it]                                                      92%|█████████▏| 1046/1140 [1:02:23<05:09,  3.29s/it] 92%|█████████▏| 1047/1140 [1:02:26<05:02,  3.26s/it]                                                      92%|█████████▏| 1047/1140 [1:02:26<05:02,  3.26s/it] 92%|█████████▏| 1048/1140 [1:02:30<05:00,  3.27s/it]                                                      92%|█████████▏| 1048/1140 [1:02:30<05:00,  3.27s/it] 92%|█████████▏| 1049/1140 [1:02:33<04:59,  3.29s/it]                                                      92%|█████████▏| 1049/1140 [1:02:33<04:59,  3.29s/it] 92%|█████████▏| 1050/1140 [1:02:36<04:53,  3.26s/it]                                                      92%|█████████▏| 1050/1140 [1:02:36<04:53,  3.26s/it] 92%|█████████▏| 1051/1140 [1:02:39<04:54,  3.30s/it]                                                      92%|█████████▏| 1051/1140 [1:02:39<04:54,  3.30s/it] 92%|█████████▏| 1052/1140 [1:02:43<04:55,  3.35s/it]                                                      92%|█████████▏| 1052/1140 [1:02:43<04:55,  3.35s/it] 92%|█████████▏| 1053/1140 [1:02:46<04:43,  3.26s/it]                                                      92%|█████████▏| 1053/1140 [1:02:46<04:43,  3.26s/it] 92%|█████████▏| 1054/1140 [1:02:49<04:41,  3.27s/it]                                                      92%|█████████▏| 1054/1140 [1:02:49<04:41,  3.27s/it] 93%|█████████▎| 1055/1140 [1:02:53<04:42,  3.32s/it]                                                      93%|█████████▎| 1055/1140 [1:02:53<04:42,  3.32s/it] 93%|█████████▎| 1056/1140 [1:02:56<04:44,  3.39s/it]                                                      93%|█████████▎| 1056/1140 [1:02:56<04:44,  3.39s/it] 93%|█████████▎| 1057/1140 [1:03:00<04:40,  3.38s/it]                                                      93%|█████████▎| 1057/1140 [1:03:00<04:40,  3.38s/it] 93%|█████████▎| 1058/1140 [1:03:03<04:35,  3.35s/it]                                                      93%|█████████▎| 1058/1140 [1:03:03<04:35,  3.35s/it] 93%|█████████▎| 1059/1140 [1:03:06<04:29,  3.33s/it]                                                      93%|█████████▎| 1059/1140 [1:03:06<04:29,  3.33s/it] 93%|█████████▎| 1060/1140 [1:03:10<04:26,  3.33s/it]                                                      93%|█████████▎| 1060/1140 [1:03:10<04:26,  3.33s/it] 93%|█████████▎| 1061/1140 [1:03:13<04:19,  3.29s/it]                                                      93%|█████████▎| 1061/1140 [1:03:13<04:19,  3.29s/it] 93%|█████████▎| 1062/1140 [1:03:16<04:12,  3.24s/it]                                                      93%|█████████▎| 1062/1140 [1:03:16<04:12,  3.24s/it] 93%|█████████▎| 1063/1140 [1:03:19<04:11,  3.26s/it]                                                      93%|█████████▎| 1063/1140 [1:03:19<04:11,  3.26s/it] 93%|█████████▎| 1064/1140 [1:03:22<04:04,  3.22s/it]                                                      93%|█████████▎| 1064/1140 [1:03:22<04:04,  3.22s/it] 93%|█████████▎| 1065/1140 [1:03:25<04:00,  3.20s/it]                                                      93%|█████████▎| 1065/1140 [1:03:25<04:00,  3.20s/it] 94%|█████████▎| 1066/1140 [1:03:29<04:03,  3.28s/it]                                                      94%|█████████▎| 1066/1140 [1:03:29<04:03,  3.28s/it] 94%|█████████▎| 1067/1140 [1:03:32<03:54,  3.21s/it]                                                      94%|█████████▎| 1067/1140 [1:03:32<03:54,  3.21s/it] 94%|█████████▎| 1068/1140 [1:03:35<03:48,  3.17s/it]                                                      94%|█████████▎| 1068/1140 [1:03:35<03:48,  3.17s/it] 94%|█████████▍| 1069/1140 [1:03:38<03:42,  3.14s/it]                                                      94%|█████████▍| 1069/1140 [1:03:38<03:42,  3.14s/it] 94%|█████████▍| 1070/1140 [1:03:41<03:42,  3.18s/it]                                                      94%|█████████▍| 1070/1140 [1:03:41<03:42,  3.18s/it] 94%|█████████▍| 1071/1140 [1:03:44<03:37,  3.15s/it]                                                      94%|█████████▍| 1071/1140 [1:03:44<03:37,  3.15s/it] 94%|█████████▍| 1072/1140 [1:03:48<03:31,  3.12s/it]                                                      94%|█████████▍| 1072/1140 [1:03:48<03:31,  3.12s/it] 94%|█████████▍| 1073/1140 [1:03:50<03:16,  2.93s/it]                                                      94%|█████████▍| 1073/1140 [1:03:50<03:16,  2.93s/it] 94%|█████████▍| 1074/1140 [1:03:52<02:57,  2.69s/it]                                                      94%|█████████▍| 1074/1140 [1:03:52<02:57,  2.69s/it] 94%|█████████▍| 1075/1140 [1:03:54<02:44,  2.53s/it]                                                      94%|█████████▍| 1075/1140 [1:03:54<02:44,  2.53s/it] 94%|█████████▍| 1076/1140 [1:03:56<02:34,  2.41s/it]                                                      94%|█████████▍| 1076/1140 [1:03:56<02:34,  2.41s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 15 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 94%|█████████▍| 1077/1140 [1:04:29<12:03, 11.48s/it]                                                      94%|█████████▍| 1077/1140 [1:04:29<12:03, 11.48s/it] 95%|█████████▍| 1078/1140 [1:04:32<09:16,  8.98s/it]                                                      95%|█████████▍| 1078/1140 [1:04:32<09:16,  8.98s/it] 95%|█████████▍| 1079/1140 [1:04:35<07:23,  7.27s/it]                                                      95%|█████████▍| 1079/1140 [1:04:35<07:23,  7.27s/it] 95%|█████████▍| 1080/1140 [1:04:39<06:01,  6.03s/it]                                                      95%|█████████▍| 1080/1140 [1:04:39<06:01,  6.03s/it] 95%|█████████▍| 1081/1140 [1:04:42<05:05,  5.18s/it]                                                      95%|█████████▍| 1081/1140 [1:04:42<05:05,  5.18s/it] 95%|█████████▍| 1082/1140 [1:04:45<04:29,  4.65s/it]                                                      95%|█████████▍| 1082/1140 [1:04:45<04:29,  4.65s/it] 95%|█████████▌| 1083/1140 [1:04:49<04:03,  4.27s/it]                                                      95%|█████████▌| 1083/1140 [1:04:49<04:03,  4.27s/it] 95%|█████████▌| 1084/1140 [1:04:52<03:39,  3.91s/it]                                                      95%|█████████▌| 1084/1140 [1:04:52<03:39,  3.91s/it] 95%|█████████▌| 1085/1140 [1:04:55<03:31,  3.84s/it]                                                      95%|█████████▌| 1085/1140 [1:04:55<03:31,  3.84s/it] 95%|█████████▌| 1086/1140 [1:04:59<03:18,  3.68s/it]                                                      95%|█████████▌| 1086/1140 [1:04:59<03:18,  3.68s/it] 95%|█████████▌| 1087/1140 [1:05:02<03:06,  3.52s/it]                                                      95%|█████████▌| 1087/1140 [1:05:02<03:06,  3.52s/it] 95%|█████████▌| 1088/1140 [1:05:05<03:01,  3.49s/it]                                                      95%|█████████▌| 1088/1140 [1:05:05<03:01,  3.49s/it] 96%|█████████▌| 1089/1140 [1:05:08<02:54,  3.41s/it]                                                      96%|█████████▌| 1089/1140 [1:05:08<02:54,  3.41s/it] 96%|█████████▌| 1090/1140 [1:05:12<02:50,  3.40s/it]                                                      96%|█████████▌| 1090/1140 [1:05:12<02:50,  3.40s/it] 96%|█████████▌| 1091/1140 [1:05:15<02:44,  3.36s/it]                                                      96%|█████████▌| 1091/1140 [1:05:15<02:44,  3.36s/it] 96%|█████████▌| 1092/1140 [1:05:19<02:42,  3.38s/it]                                                      96%|█████████▌| 1092/1140 [1:05:19<02:42,  3.38s/it] 96%|█████████▌| 1093/1140 [1:05:22<02:38,  3.37s/it]                                                      96%|█████████▌| 1093/1140 [1:05:22<02:38,  3.37s/it] 96%|█████████▌| 1094/1140 [1:05:25<02:33,  3.34s/it]                                                      96%|█████████▌| 1094/1140 [1:05:25<02:33,  3.34s/it] 96%|█████████▌| 1095/1140 [1:05:28<02:30,  3.34s/it]                                                      96%|█████████▌| 1095/1140 [1:05:28<02:30,  3.34s/it] 96%|█████████▌| 1096/1140 [1:05:32<02:24,  3.27s/it]                                                      96%|█████████▌| 1096/1140 [1:05:32<02:24,  3.27s/it] 96%|█████████▌| 1097/1140 [1:05:35<02:23,  3.33s/it]                                                      96%|█████████▌| 1097/1140 [1:05:35<02:23,  3.33s/it] 96%|█████████▋| 1098/1140 [1:05:38<02:17,  3.28s/it]                                                      96%|█████████▋| 1098/1140 [1:05:38<02:17,  3.28s/it] 96%|█████████▋| 1099/1140 [1:05:42<02:14,  3.28s/it]                                                      96%|█████████▋| 1099/1140 [1:05:42<02:14,  3.28s/it] 96%|█████████▋| 1100/1140 [1:05:45<02:12,  3.32s/it]                                                      96%|█████████▋| 1100/1140 [1:05:45<02:12,  3.32s/it] 97%|█████████▋| 1101/1140 [1:05:49<02:13,  3.42s/it]                                                      97%|█████████▋| 1101/1140 [1:05:49<02:13,  3.42s/it] 97%|█████████▋| 1102/1140 [1:05:52<02:07,  3.35s/it]                                                      97%|█████████▋| 1102/1140 [1:05:52<02:07,  3.35s/it] 97%|█████████▋| 1103/1140 [1:05:55<02:01,  3.28s/it]                                                      97%|█████████▋| 1103/1140 [1:05:55<02:01,  3.28s/it] 97%|█████████▋| 1104/1140 [1:05:58<01:57,  3.27s/it]                                                      97%|█████████▋| 1104/1140 [1:05:58<01:57,  3.27s/it] 97%|█████████▋| 1105/1140 [1:06:01<01:53,  3.25s/it]                                                      97%|█████████▋| 1105/1140 [1:06:01<01:53,  3.25s/it] 97%|█████████▋| 1106/1140 [1:06:04<01:49,  3.22s/it]                                                      97%|█████████▋| 1106/1140 [1:06:04<01:49,  3.22s/it] 97%|█████████▋| 1107/1140 [1:06:08<01:46,  3.21s/it]                                                      97%|█████████▋| 1107/1140 [1:06:08<01:46,  3.21s/it] 97%|█████████▋| 1108/1140 [1:06:11<01:43,  3.24s/it]                                                      97%|█████████▋| 1108/1140 [1:06:11<01:43,  3.24s/it] 97%|█████████▋| 1109/1140 [1:06:14<01:41,  3.27s/it]                                                      97%|█████████▋| 1109/1140 [1:06:14<01:41,  3.27s/it] 97%|█████████▋| 1110/1140 [1:06:18<01:37,  3.26s/it]                                                      97%|█████████▋| 1110/1140 [1:06:18<01:37,  3.26s/it] 97%|█████████▋| 1111/1140 [1:06:21<01:36,  3.32s/it]                                                      97%|█████████▋| 1111/1140 [1:06:21<01:36,  3.32s/it] 98%|█████████▊| 1112/1140 [1:06:24<01:32,  3.31s/it]                                                      98%|█████████▊| 1112/1140 [1:06:24<01:32,  3.31s/it] 98%|█████████▊| 1113/1140 [1:06:28<01:28,  3.29s/it]                                                      98%|█████████▊| 1113/1140 [1:06:28<01:28,  3.29s/it] 98%|█████████▊| 1114/1140 [1:06:31<01:25,  3.28s/it]                                                      98%|█████████▊| 1114/1140 [1:06:31<01:25,  3.28s/it] 98%|█████████▊| 1115/1140 [1:06:34<01:23,  3.32s/it]                                                      98%|█████████▊| 1115/1140 [1:06:34<01:23,  3.32s/it] 98%|█████████▊| 1116/1140 [1:06:38<01:19,  3.33s/it]                                                      98%|█████████▊| 1116/1140 [1:06:38<01:19,  3.33s/it] 98%|█████████▊| 1117/1140 [1:06:41<01:17,  3.38s/it]                                                      98%|█████████▊| 1117/1140 [1:06:41<01:17,  3.38s/it] 98%|█████████▊| 1118/1140 [1:06:44<01:14,  3.39s/it]                                                      98%|█████████▊| 1118/1140 [1:06:45<01:14,  3.39s/it] 98%|█████████▊| 1119/1140 [1:06:47<01:08,  3.26s/it]                                                      98%|█████████▊| 1119/1140 [1:06:47<01:08,  3.26s/it] 98%|█████████▊| 1120/1140 [1:06:51<01:05,  3.27s/it]                                                      98%|█████████▊| 1120/1140 [1:06:51<01:05,  3.27s/it] 98%|█████████▊| 1121/1140 [1:06:54<01:04,  3.38s/it]                                                      98%|█████████▊| 1121/1140 [1:06:54<01:04,  3.38s/it] 98%|█████████▊| 1122/1140 [1:06:58<00:59,  3.30s/it]                                                      98%|█████████▊| 1122/1140 [1:06:58<00:59,  3.30s/it] 99%|█████████▊| 1123/1140 [1:07:01<00:56,  3.30s/it]                                                      99%|█████████▊| 1123/1140 [1:07:01<00:56,  3.30s/it] 99%|█████████▊| 1124/1140 [1:07:04<00:51,  3.21s/it]                                                      99%|█████████▊| 1124/1140 [1:07:04<00:51,  3.21s/it] 99%|█████████▊| 1125/1140 [1:07:07<00:47,  3.18s/it]                                                      99%|█████████▊| 1125/1140 [1:07:07<00:47,  3.18s/it] 99%|█████████▉| 1126/1140 [1:07:10<00:43,  3.14s/it]                                                      99%|█████████▉| 1126/1140 [1:07:10<00:43,  3.14s/it] 99%|█████████▉| 1127/1140 [1:07:13<00:40,  3.14s/it]                                                      99%|█████████▉| 1127/1140 [1:07:13<00:40,  3.14s/it] 99%|█████████▉| 1128/1140 [1:07:16<00:37,  3.16s/it]                                                      99%|█████████▉| 1128/1140 [1:07:16<00:37,  3.16s/it] 99%|█████████▉| 1129/1140 [1:07:20<00:35,  3.23s/it]                                                      99%|█████████▉| 1129/1140 [1:07:20<00:35,  3.23s/it] 99%|█████████▉| 1130/1140 [1:07:23<00:33,  3.32s/it]                                                      99%|█████████▉| 1130/1140 [1:07:23<00:33,  3.32s/it] 99%|█████████▉| 1131/1140 [1:07:27<00:30,  3.36s/it]                                                      99%|█████████▉| 1131/1140 [1:07:27<00:30,  3.36s/it] 99%|█████████▉| 1132/1140 [1:07:30<00:26,  3.31s/it]                                                      99%|█████████▉| 1132/1140 [1:07:30<00:26,  3.31s/it] 99%|█████████▉| 1133/1140 [1:07:33<00:23,  3.32s/it]                                                      99%|█████████▉| 1133/1140 [1:07:33<00:23,  3.32s/it] 99%|█████████▉| 1134/1140 [1:07:36<00:19,  3.27s/it]                                                      99%|█████████▉| 1134/1140 [1:07:36<00:19,  3.27s/it]100%|█████████▉| 1135/1140 [1:07:40<00:16,  3.25s/it]                                                     100%|█████████▉| 1135/1140 [1:07:40<00:16,  3.25s/it]100%|█████████▉| 1136/1140 [1:07:43<00:13,  3.26s/it]                                                     100%|█████████▉| 1136/1140 [1:07:43<00:13,  3.26s/it]100%|█████████▉| 1137/1140 [1:07:46<00:09,  3.32s/it]                                                     100%|█████████▉| 1137/1140 [1:07:46<00:09,  3.32s/it]100%|█████████▉| 1138/1140 [1:07:49<00:06,  3.27s/it]                                                     100%|█████████▉| 1138/1140 [1:07:49<00:06,  3.27s/it]100%|█████████▉| 1139/1140 [1:07:53<00:03,  3.25s/it]                                                     100%|█████████▉| 1139/1140 [1:07:53<00:03,  3.25s/it]100%|██████████| 1140/1140 [1:07:56<00:00,  3.23s/it]                                                     100%|██████████| 1140/1140 [1:07:56<00:00,  3.23s/it]/home/ltl2113/miniconda3/envs/tinyllava/lib/python3.10/site-packages/torch/nn/modules/module.py:1877: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
                                                     100%|██████████| 1140/1140 [1:08:20<00:00,  3.23s/it]100%|██████████| 1140/1140 [1:08:20<00:00,  3.60s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.122 MB uploadedwandb: | 0.010 MB of 0.122 MB uploadedwandb: / 0.122 MB of 0.122 MB uploadedwandb: - 0.122 MB of 0.122 MB uploadedwandb: 
wandb: Run history:
wandb:                    train/epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:              train/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:            train/learning_rate ▄▇██████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁
wandb:                     train/loss ▇▇▄▅▆▅▇▄▁▇▆▅▅▅▆█▅▄▇▆▆▅▅▃▆▅▇▄▂▄▄▄▅▇▅▇▆▄▆▅
wandb:               train/total_flos ▁
wandb:               train/train_loss ▁
wandb:            train/train_runtime ▁
wandb: train/train_samples_per_second ▁
wandb:   train/train_steps_per_second ▁
wandb: 
wandb: Run summary:
wandb:                    train/epoch 14.83
wandb:              train/global_step 1140
wandb:            train/learning_rate 0.0
wandb:                     train/loss 3.2812
wandb:               train/total_flos 5.548402501799117e+16
wandb:               train/train_loss 3.35199
wandb:            train/train_runtime 4106.8059
wandb: train/train_samples_per_second 35.922
wandb:   train/train_steps_per_second 0.278
wandb: 
wandb: 🚀 View run tiny-llava-base-pretrain-scratch/ltl2113/LLaVA-Med/TinyLLaVABench/checkpoints/Tinny_llava_Norm_SG2_FULL/checkpoint-1326-siglip-so400m-patch14-384 at: https://wandb.ai/llavamed/huggingface/runs/2suw1crz
wandb: ️⚡ View job at https://wandb.ai/llavamed/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE1MjEyNzg1Ng==/version_details/v6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240407_044936-2suw1crz/logs
